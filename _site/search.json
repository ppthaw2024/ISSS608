[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 Coursework",
    "section": "",
    "text": "Hello and \n\nI’m Phoo, an aspiring Business Analyst with a passion for turning data into meaningful insights and stories.\nThis is my Visual Analytics and Applications showcase, where I document and share my coursework and projects for this module.\nHere, you’ll see how I apply data analytics techniques to explore data, draw meaningful insights, and reveal hidden trends that tell a bigger story. 📊✨\nTake a look around and enjoy the journey through data! 😊"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "In this webpage, you will find my learning journey and deliverables of ISSS608 Visual Analytics and Applications whereby I share my Hands-on Exercise, Projects and so on."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "",
    "text": "Loading tidyverse onto r environment by using the code chunk below.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#getting-started",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "",
    "text": "Loading tidyverse onto r environment by using the code chunk below.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#importing-data",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "Importing data",
    "text": "Importing data\nCode chunk below uses read_csv() of readr to import REALIS2019.csv into r environment as a tbille data.frame.\n\nrealis2019 &lt;- read_csv(\"data/REALIS2019.csv\")\n\n\n#|eval: FALSE\npopdata_fat &lt;- read_csv(\"data/PopData2019_fat.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#pivoting-data",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#pivoting-data",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "Pivoting data",
    "text": "Pivoting data\n\n#|eval: FALSE\npopdata_long &lt;- popdata_fat %&gt;%\n  pivot_longer(c(3:21),\n              names_to = \"Age Group\",\n              values_to = \"Population\")\n\n\n#|eval: FALSE\nwrite_rds(popdata_long, \"rds/popdata_long.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#working-with-dplyr",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#working-with-dplyr",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "Working with dplyr",
    "text": "Working with dplyr\n\nrealis2019_selected &lt;- realis2019 %&gt;%\n  select(`Project Name`,\n        `Transacted Price ($)`,\n        `Type of Sale`,\n        `Unit Price ($ psm)`,\n        `Property Type`)\nrealis2019_selected\n\n# A tibble: 19,515 × 5\n   `Project Name`     `Transacted Price ($)` `Type of Sale` `Unit Price ($ psm)`\n   &lt;chr&gt;                               &lt;dbl&gt; &lt;chr&gt;                         &lt;dbl&gt;\n 1 PEIRCE VIEW                        840000 Resale                         7434\n 2 FLORIDA PARK                      3040000 Resale                         9737\n 3 BULLION PARK                       860000 Resale                        11467\n 4 CASTLE GREEN                      1000000 Resale                         9346\n 5 HAPPY ESTATE                      7000000 Resale                        10183\n 6 TEACHER'S HOUSING…                2880000 Resale                        12659\n 7 THE PANORAMA                      1510000 Resale                        16064\n 8 THE PANORAMA                       710000 Resale                        16905\n 9 CHIP THYE GARDEN                  2800000 Resale                        13500\n10 TEACHER'S HOUSING…                2300000 Resale                         9935\n# ℹ 19,505 more rows\n# ℹ 1 more variable: `Property Type` &lt;chr&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#working-with-filter-of-dplyr.",
    "href": "Hands-on_Ex/Hands-on_Ex00/Hands-on_Ex00.html#working-with-filter-of-dplyr.",
    "title": "Hands-on Exercise 00: working with tidyverse",
    "section": "Working with filter() of dplyr.",
    "text": "Working with filter() of dplyr.\n\nrealis2019_filtered &lt;- realis2019_selected %&gt;%\n  filter(`Property Type` ==\"Condominium\" |\n          `Property Type`== \"Apartment\") %&gt;%\n  filter(`Type of Sale` == \"New Sale\") %&gt;%\n  filter(`Unit Price ($ psm)` &lt;= 13000)\n\n\nPutting all together\n\nrealis2019_end &lt;- realis2019 %&gt;%\n  select(`Project Name`,\n        `Transacted Price ($)`,\n        `Type of Sale`,\n        `Unit Price ($ psm)`,\n        `Property Type`) %&gt;%\n  filter(`Property Type` ==\"Condominium\" |\n          `Property Type`== \"Apartment\") %&gt;%\n  filter(`Type of Sale` == \"New Sale\") %&gt;%\n  filter(`Unit Price ($ psm)` &lt;= 13000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "",
    "text": "In this chapter, you will learn the basic principles and essential components of ggplot2. At the same time, you will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter you will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#installling-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#installling-and-loading-the-required-libraries",
    "title": "Hands_on_Ex01",
    "section": "1.2 Installling and loading the required libraries",
    "text": "1.2 Installling and loading the required libraries"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#importing-data",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#importing-data",
    "title": "Hands_on_Ex01",
    "section": "1.2.1 Importing data",
    "text": "1.2.1 Importing data\n\nlibrary(readr) # Load the readr library\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.3 Introducing ggplot",
    "text": "1.3 Introducing ggplot\nggplot2 is an R package for declaratively creating data-driven graph based on The Grammer of Graphics\n\n\n1.3.1 R Graphics VS ggplot\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#r-graphics-vs-ggplot",
    "title": "Hands_on_Ex01",
    "section": "1.3.1 R Graphics VS ggplot",
    "text": "1.3.1 R Graphics VS ggplot\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.4 Grammar of Graphics",
    "text": "1.4 Grammar of Graphics\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\n\n1.4.1 A Layered Grammar of Graphics\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "title": "Hands_on_Ex01",
    "section": "1.4.1 A Layered Grammar of Graphics",
    "text": "1.4.1 A Layered Grammar of Graphics"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.5 Essential Grammatical Elements in ggplot2: data",
    "text": "1.5 Essential Grammatical Elements in ggplot2: data\nLet us call the ggplot() function using the code chunk on the right.\n\nggplot(data=exam_data)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "1.6 Essential Grammatical Elements in ggplot2: Aesthetic mappings\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call.\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data, \n       aes(x= MATHS))"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.7 Essential Grammatical Elements in ggplot2: geom",
    "text": "1.7 Essential Grammatical Elements in ggplot2: geom\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_bar",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.7.1 Geometric Objects: geom_bar",
    "text": "1.7.1 Geometric Objects: geom_bar\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_dotplot",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.7.2 Geometric Objects: geom_dotplot",
    "text": "1.7.2 Geometric Objects: geom_dotplot\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n1.7.3 Geometric Objects: geom_histogram()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n1.7.4 Modifying a geometric object by changing geom()\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n1.7.5 Modifying a geometric object by changing aes()\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n1.7.6 Geometric Objects: geom-density()\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n1.7.7 Geometric Objects: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\n\n\nNotched plot instead of boxplot\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n1.7.8 Geometric Objects: geom_violin\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n1.7.9 Geometric Objects: geom_point()\ngeom_point() is especially useful for creating scatterplot. The code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n1.7.10 geom objects can be combined\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#the-code-chunk-below-performs-the-following-two-steps",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#the-code-chunk-below-performs-the-following-two-steps",
    "title": "Hands_on_Ex01",
    "section": "The code chunk below performs the following two steps:",
    "text": "The code chunk below performs the following two steps:\n#scale_y_continuous() is used to turn off the y-axis, and #binwidth argument is used to change the binwidth to 2.5.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_histogram",
    "title": "Hands_on_Ex01",
    "section": "1.7.3 Geometric Objects: geom_histogram()",
    "text": "1.7.3 Geometric Objects: geom_histogram()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-geom",
    "title": "Hands_on_Ex01",
    "section": "1.7.4 Modifying a geometric object by changing geom()",
    "text": "1.7.4 Modifying a geometric object by changing geom()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#modifying-a-geometric-object-by-changing-aes",
    "title": "Hands_on_Ex01",
    "section": "1.7.5 Modifying a geometric object by changing aes()",
    "text": "1.7.5 Modifying a geometric object by changing aes()\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom-density",
    "title": "Hands_on_Ex01",
    "section": "1.7.6 Geometric Objects: geom-density()",
    "text": "1.7.6 Geometric Objects: geom-density()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#the-code-chunk-below-plots-two-kernel-density-lines-by-using-colour-or-fill-arguments-of-aes",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#the-code-chunk-below-plots-two-kernel-density-lines-by-using-colour-or-fill-arguments-of-aes",
    "title": "Hands_on_Ex01",
    "section": "The code chunk below plots two kernel density lines by using colour or fill arguments of aes()",
    "text": "The code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_boxplot",
    "title": "Hands_on_Ex01",
    "section": "1.7.7 Geometric Objects: geom_boxplot",
    "text": "1.7.7 Geometric Objects: geom_boxplot\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_violin",
    "title": "Hands_on_Ex01",
    "section": "1.7.8 Geometric Objects: geom_violin",
    "text": "1.7.8 Geometric Objects: geom_violin\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geometric-objects-geom_point",
    "title": "Hands_on_Ex01",
    "section": "1.7.9 Geometric Objects: geom_point()",
    "text": "1.7.9 Geometric Objects: geom_point()\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geom-objects-can-be-combined",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#geom-objects-can-be-combined",
    "title": "Hands_on_Ex01",
    "section": "1.7.10 geom objects can be combined",
    "text": "1.7.10 geom objects can be combined\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.8 Essential Grammatical Elements in ggplot2: stat",
    "text": "1.8 Essential Grammatical Elements in ggplot2: stat\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n1.8.1 Working with stat()\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n1.8.2 Working with stat - the stat_summary() method\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n1.8.3 Working with stat - the geom() method\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\n1.8.4 Adding a best fit curve on a scatterplot?\nThe scatterplot shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\n\n\n\n\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-stat",
    "title": "Hands_on_Ex01",
    "section": "1.8.1 Working with stat()",
    "text": "1.8.1 Working with stat()\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-stat---the-stat_summary-method",
    "title": "Hands_on_Ex01",
    "section": "1.8.2 Working with stat - the stat_summary() method",
    "text": "1.8.2 Working with stat - the stat_summary() method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun = \"mean\",         \n               colour =\"red\",        \n               size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-stat---the-geom-method",
    "title": "Hands_on_Ex01",
    "section": "1.8.3 Working with stat - the geom() method",
    "text": "1.8.3 Working with stat - the geom() method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#adding-a-best-fit-curve-on-a-scatterplot",
    "title": "Hands_on_Ex01",
    "section": "1.8.4 Adding a best fit curve on a scatterplot?",
    "text": "1.8.4 Adding a best fit curve on a scatterplot?\n#In the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n#The default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.9 Essential Grammatical Elements in ggplot2: Facets",
    "text": "1.9 Essential Grammatical Elements in ggplot2: Facets\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n1.9.1 Working with facet_wrap()\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n1.9.2 facet_grid() function\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-facet_wrap",
    "title": "Hands_on_Ex01",
    "section": "1.9.1 Working with facet_wrap()",
    "text": "1.9.1 Working with facet_wrap()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#facet_grid-function",
    "title": "Hands_on_Ex01",
    "section": "1.9.2 facet_grid() function",
    "text": "1.9.2 facet_grid() function\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.10 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "1.10 Essential Grammatical Elements in ggplot2: Coordinates\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n- [`coord_cartesian()`]: the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out). - [`coord_flip()`]: a cartesian system with the x and y flipped. - [`coord_fixed()`]: a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot). - [`coord_quickmap()`]: a coordinate system that approximates a good aspect ratio for maps.\n\n1.10.1 Working with Coordinate\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-coordinate",
    "title": "Hands_on_Ex01",
    "section": "1.10.1 Working with Coordinate",
    "text": "1.10.1 Working with Coordinate\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#changing-the-y--and-x-axis-range",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.10.2 Changing the y- and x-axis range",
    "text": "1.10.2 Changing the y- and x-axis range\nThe scatterplot below is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5)\n\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.11 Essential Grammatical Elements in ggplot2: themes",
    "text": "1.11 Essential Grammatical Elements in ggplot2: themes\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n1.11.1 Working with theme\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#working-with-theme",
    "title": "Hands_on_Ex01",
    "section": "1.11.1 Working with theme",
    "text": "1.11.1 Working with theme\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\n#A horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\n#A horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "Introducing ggplot extensions for creating more elegant and effective statistical graphics.\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-fundamentals",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-fundamentals",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Introducing ggplot extensions for creating more elegant and effective statistical graphics.\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "2.2 Getting started",
    "text": "2.2 Getting started\n\nInstalling and loading the required libraries\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\n\n\n2.2.2 Importing data\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nlibrary(readr) # Load the readr library\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "2.3 Beyond ggplot2 Annotation: ggrepel",
    "text": "2.3 Beyond ggplot2 Annotation: ggrepel\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nlibrary(ggplot2)\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right.\n\nWe simple replace  geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n2.3.1 Working with ggrepel\n\nlibrary(ggrepel)\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "",
    "text": "In this chapter, you will learn the basic principles and essential components of ggplot2. At the same time, you will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter you will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.2 Getting Started",
    "text": "1.2 Getting Started\n\n1.2.1 Installing and loading the required libraries\n\npacman::p_load(tidyverse)\n\n\n\n1.2.2 Importing data\n\nlibrary(readr) # Load the readr library\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands_on_Ex01/Hands_on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 01: A Layered Grammer of Graphics: ggplot2 methods",
    "section": "1.12 Reference",
    "text": "1.12 Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "Introducing ggplot extensions for creating more elegant and effective statistical graphics.\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "2.4 Beyond ggplot2 Themes",
    "text": "2.4 Beyond ggplot2 Themes\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n2.4.1 Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\nlibrary(ggthemes)\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n2.4.2 Working with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nlibrary(hrbrthemes)\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\nlibrary(hrbrthemes)\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(base_family = \"sans\",                        axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "2.5 Beyond Single Graph",
    "text": "2.5 Beyond Single Graph\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs. First, let me create three statistical graphics by using the code chunk below.\n\nlibrary(ggplot2)\n\np1 &lt;- ggplot(data = exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100,\n                 color = \"grey25\", \n                 fill = \"grey90\") + \n  coord_cartesian(xlim = c(0, 100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\nprint(p1)\n\n\n\n\n\n\n\n\nNext\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\nprint(p2)\n\n\n\n\n\n\n\n\nLastly, we will draw a scatterplot for English score versus Maths score by as shown below\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nprint(p3)\n\n\n\n\n\n\n\n\n\n2.5.1 Creating Composite Graphics: pathwork methods\nIn this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n2.5.2 Combining two ggplot2 graphs\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\nlibrary(patchwork)\np1 + p2\n\n\n\n\n\n\n\n\n\n\n2.5.3 Combining three gglplot2 graphs\nWe can plot more complex composite by using appropriate operators. For example, the compostie figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\nlibrary(patchwork)\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\n\n\n2.5.4 Creating a composite figure with tag\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\nlibrary(patchwork)\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\n2.5.5 Creating figure with insert\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n\n\n\n\n2.5.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 02: Beyond ggplot2 Fundamentals",
    "section": "2.6 Reference",
    "text": "2.6 Reference\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#learning-outcome",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "3.3 Importing Data",
    "text": "3.3 Importing Data\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nlibrary(readr) # Load the readr library\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "3.4 Interactive Data Visualisation - ggiraph methods",
    "text": "3.4 Interactive Data Visualisation - ggiraph methods\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\n\n3.4.1 Tooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts.\nFirst, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "3.5 Interactivity",
    "text": "3.5 Interactivity\nBy hovering the mouse pointer on a data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n3.5.1 Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#section",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#section",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "3.6",
    "text": "3.6"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "3.6 Interactivity",
    "text": "3.6 Interactivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n3.6.1 Customising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\n\n\n\n\n\n3.6.2 Displaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n3.6.3 Hover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n3.6.4 Styling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n3.6.5 Combining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n3.6.6 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n3.6.7 Coordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "3.7 Interactive Data Visualisation - plotly methods!",
    "text": "3.7 Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.7.1 Creating an interactive scatter plot: plot_ly() method\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\n3.7.2 Working with visual variable: plot_ly() method\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n\n3.7.4 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "3.8 Interactive Data Visualisation - crosstalk methods!",
    "text": "3.8 Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.8.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n3.8.2 Linked brushing: crosstalk method\nCode chunk below is used to implement the coordinated brushing shown above.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "3.9 Reference",
    "text": "3.9 Reference\n\n3.9.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.9.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started-1",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "4.2 Getting Started",
    "text": "4.2 Getting Started\n\n4.2.1 Loading the R packages\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n4.2.2 Importing the data\n\nlibrary(readr) # Load the readr library\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\nlibrary(readr) # Load the readr library\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "4.3 Animated Data Visualisation: gganimate methods",
    "text": "4.3 Animated Data Visualisation: gganimate methods\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n4.3.1 Building a static population bubble plot\nBasic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n4.3.2 Building the animated bubble plot\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nlibrary(ggplot2)\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 03: Interactivity in Visual Analytics: Principles and Methods",
    "section": "4.4 Animated Data Visualisation: plotly",
    "text": "4.4 Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n4.4.1 Building an animated bubble plot: ggplotly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +  \n  geom_point(alpha = 0.7, show.legend = FALSE) +  \n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg) %&gt;% \n  animation_opts(transition = 100)  \n\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +  \n  geom_point(alpha = 0.7, show.legend = FALSE) +  \n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') +\n  theme(legend.position = 'none')\n\n\nggplotly(gg) %&gt;% \n  animation_opts(transition = 100)  \n\n\n\n\n\n\n\n4.4.2 Building an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "In_class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In_class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class_Ex04",
    "section": "",
    "text": "pacman:: p_load(haven, SmartEDA, tidyverse, tidymodels,ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nChanging x and y can make horizontal or vertical boxplot\n\nggplot(data = exam_data,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n   geom_boxplot()\n\n\n\n\n\n\n\n\nThe order of scale_x_continuous and scale_y_discrete work for horizontal box plot. should change according for vertical\n\nggplot(data =exam_data, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nRaincloud plot 9.4.3, dotted points determine the height of the ridges\nstat_halfeyes , stat_dots\n\nggplot(data= exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\nUnequal variance, use Welch test"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html",
    "href": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html",
    "title": "Take_Home Exercise 1",
    "section": "",
    "text": "The maritime sector is one of the most critical components of global trade, contributing significantly to economic growth and sustainability. Understanding ship performance, fuel efficiency, and operational cost factors are essential for improving decision-making and minimizing environmental impact.\nAn international media company that publishes weekly content on digital platforms is planning to release articles on “Ship Performance in the Gulf of Guinea”.\nAs the role of the graphical editor of the media company, I am going to prepare data visualization for the article.\n\n\n\nIn this exercise, Exploratory Data Analysis (EDA) methods and ggplot functions are used to explore:\n\nthe distribution of Ship performance in efficiency, operational cost, speed, fuel consumption, and revenue generation.\nthe relationship between these performances with draft, cargo weight, weather, engine type, ship type, seasonal impact and etc.\n\n\n\n\n\n\n\nThe following R packages using the pacman::p_load() function are loaded.\n\ntidyverse: Core collection of R packages designed for data science\nhaven: To read in data formats such as SAS and SPSS\nggrepel: to provides geoms for ggplot2 to repel overlapping text labels\nggthemes: to use additional themes for ggplot2\npatchwork: to prepare composite figure created using ggplot2\nggridges: to plot ridgeline plots\nggdist: for visualizations of distributions and uncertainty\nscales: provides the internal scaling infrastructure used by ggplot2\n\n\npacman::p_load(tidyverse, haven,\n               ggrepel, ggthemes,\n               ggridges, ggdist,\n               patchwork, scales)\n\n\n\n\n\n\n\nThe dataset used in the exercise is in CSV format, retrieved from Kaggle.comhttps://www.kaggle.com/datasets/jeleeladekunlefijabi/ship-performance-clustering-dataset\nThe code chunk below import the dataset using read_csv() function of the haven package.\n\nlibrary(readr) \nmarine &lt;- read_csv(\"data/Ship_Performance_Dataset.csv\")\n\n\n\n\nUsing the glimpse() function, we see that the dataset consists of 2,736 rows and 18 columns. It also shows the column names, column type, and the first few entries of each column.\n\nglimpse(marine)\n\nRows: 2,736\nColumns: 18\n$ Date                    &lt;date&gt; 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               &lt;chr&gt; \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              &lt;chr&gt; \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             &lt;chr&gt; \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Maintenance_Status      &lt;chr&gt; \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Draft_meters            &lt;dbl&gt; 14.132284, 14.653083, 7.199261, 11.789063, 9.7…\n$ Weather_Condition       &lt;chr&gt; \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Cargo_Weight_tons       &lt;dbl&gt; 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Turnaround_Time_hours   &lt;dbl&gt; 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Seasonal_Impact_Score   &lt;dbl&gt; 1.4156533, 0.8856478, 1.4058132, 1.3707043, 0.…\n$ Weekly_Voyage_Count     &lt;dbl&gt; 1, 6, 9, 1, 8, 7, 3, 6, 8, 2, 9, 4, 3, 7, 7, 3…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n\n\n\n\n\nUsing the duplicated function, we see that there are no duplicate entries in the data.\n\nmarine[duplicated(marine),]\n\n# A tibble: 0 × 18\n# ℹ 18 variables: Date &lt;date&gt;, Ship_Type &lt;chr&gt;, Route_Type &lt;chr&gt;,\n#   Engine_Type &lt;chr&gt;, Maintenance_Status &lt;chr&gt;, Speed_Over_Ground_knots &lt;dbl&gt;,\n#   Engine_Power_kW &lt;dbl&gt;, Distance_Traveled_nm &lt;dbl&gt;, Draft_meters &lt;dbl&gt;,\n#   Weather_Condition &lt;chr&gt;, Cargo_Weight_tons &lt;dbl&gt;,\n#   Operational_Cost_USD &lt;dbl&gt;, Revenue_per_Voyage_USD &lt;dbl&gt;,\n#   Turnaround_Time_hours &lt;dbl&gt;, Efficiency_nm_per_kWh &lt;dbl&gt;,\n#   Seasonal_Impact_Score &lt;dbl&gt;, Weekly_Voyage_Count &lt;dbl&gt;, …\n\n\n\n\n\nNumerical Variables are selected to identify\nThe colSums() function in the base package is used to check for missing values in marine. There are no missing values in the tibble data frame.\n\ncolSums(is.na(marine))\n\n                   Date               Ship_Type              Route_Type \n                      0                       0                       0 \n            Engine_Type      Maintenance_Status Speed_Over_Ground_knots \n                      0                       0                       0 \n        Engine_Power_kW    Distance_Traveled_nm            Draft_meters \n                      0                       0                       0 \n      Weather_Condition       Cargo_Weight_tons    Operational_Cost_USD \n                      0                       0                       0 \n Revenue_per_Voyage_USD   Turnaround_Time_hours   Efficiency_nm_per_kWh \n                      0                       0                       0 \n  Seasonal_Impact_Score     Weekly_Voyage_Count Average_Load_Percentage \n                      0                       0                       0 \n\n\n\n\n\nNumerical variables are selected to perform correlation analysis. All the variables looks fine.\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(reshape2)\n\n# Select only numeric variables\nnumeric_vars &lt;- marine %&gt;% select(where(is.numeric))\n\n# Compute correlation matrix\ncor_matrix &lt;- cor(numeric_vars, use = \"complete.obs\")\n\n# Melt correlation matrix for better visualization\ncor_data &lt;- melt(cor_matrix)\n\n# Improved heatmap-style correlation matrix\nggplot(data = cor_data, aes(x=Var1, y=Var2, fill=value)) + \n  geom_tile(color = \"white\") + \n  geom_text(aes(label = round(value, 2)), color = \"black\", size = 3) + \n  scale_fill_gradient2(low = \"#E46726\", mid = \"white\", high = \"#6D9EC1\", midpoint = 0) +\n  labs(title = \"Correlation Matrix of Marine Dataset\",\n       x = \"\", y = \"\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nOf 18 columns, the following 12 are preliminary selected to answer the analytical questions. The Code Book from Kaggle provides detailed description of the variables and I have referred to it..\n\n\n\n\n\n\n\n\nVariable Name\nDescription\nType of Variable\n\n\n\n\nShip_Type\nType of ship\n(Fish Carrier, Container Ship, Tanker, Bulk Carrier)\nCategorical\n\n\nRoute_Type\nShipping route type\n(Coastal, Short-haul, Long-haul, Transoceanic)\nCategorical\n\n\nEngine_Type\nType of engine\n(None, Diesel, Heavy Fuel Oil (HFO), Steam Turbine)\nCategorical\n\n\nWeather_Condition\nMaintenance condition of the ship\n(None, Calm, Moderate ,Rough)\nCategorical\n\n\nMaintenance_Status\nPrevailing weather conditions during voyages\n(None, Good, Fair, Critical)\nCategorical\n\n\nSpeed_Over_Ground_knots\nAverage speed of the ship over water\nNumerical\n\n\nEngine_Power_kW\nEngine power output\nNumerical\n\n\nDistance_Traveled_nm\nTotal distance traveled by the ship\nNumerical\n\n\nOperational_Cost_USD\nTotal operational cost per voyage\nNumerical\n\n\nRevenue_per_Voyage_USD\nRevenue generated per voyage\nNumerical\n\n\nEfficiency_nm_per_kWh\nEnergy efficiency calculated in nautical miles per kilowatt-hour\nNumerical\n\n\nAverage_Load_Percentage\nAverage load of the ship calculated in percentage\nNumerical\n\n\n\n\nmarine_filtered &lt;- marine %&gt;%\n  select(Ship_Type, Route_Type,Engine_Type,Weather_Condition,Maintenance_Status,Speed_Over_Ground_knots,\n        Engine_Power_kW, Distance_Traveled_nm,Operational_Cost_USD,Revenue_per_Voyage_USD,Efficiency_nm_per_kWh,\n        Average_Load_Percentage)\n\nglimpse(marine_filtered)\n\nRows: 2,736\nColumns: 12\n$ Ship_Type               &lt;chr&gt; \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              &lt;chr&gt; \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             &lt;chr&gt; \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Weather_Condition       &lt;chr&gt; \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Maintenance_Status      &lt;chr&gt; \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n\n\n\n\n\n\n\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(ggridges)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(viridis)\nlibrary(patchwork)\n\n# Convert data to long format for visualization\nmarine_long &lt;- marine %&gt;%\n  pivot_longer(\n    cols = c(\"Speed_Over_Ground_knots\", \"Engine_Power_kW\", \"Distance_Traveled_nm\", \n             \"Operational_Cost_USD\", \"Revenue_per_Voyage_USD\", \"Efficiency_nm_per_kWh\", \n             \"Average_Load_Percentage\"),\n    names_to = \"Variable\",\n    values_to = \"Value\"\n  )\n\n# Apply log transformation for better scaling\nmarine_long &lt;- marine_long %&gt;%\n  mutate(Value = ifelse(Value &gt; 0, log10(Value), NA))  # Log transformation\n\n# Improved Ridge Plot (Better visualization of distributions)\nmarine_ridgeplot &lt;- ggplot(marine_long, aes(x = Value, y = Variable, fill = Variable)) +\n  geom_density_ridges(alpha = 0.7, quantile_lines = TRUE, \n                      quantile_fun = function(y, ...) quantile(y, probs = 0.5, na.rm = TRUE)) +\n  scale_x_continuous(name = \"Log-Transformed Values\", labels = scales::comma) +\n  scale_fill_viridis_d() +\n  labs(title = \"Distributions of Key Numerical Variables in Marine Dataset\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.title.y = element_blank())\n\n# Improved Boxplot (Detecting outliers with better scaling)\nmarine_boxplot &lt;- ggplot(marine_long, aes(x = Variable, y = Value, fill = Variable)) +\n  geom_boxplot(outlier.colour = \"red\", outlier.shape = 16, alpha = 0.8) +\n  coord_flip() +  \n  scale_fill_viridis_d() +\n  labs(title = \"Boxplots of Key Numerical Variables in Marine Dataset\",\n       subtitle = \"Red dots indicate potential outliers\",\n       x = \"\", y = \"Log-Transformed Values\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.title.y = element_blank())\n\n# Combine Ridge Plot and Boxplot\nmarine_ridgeplot / marine_boxplot\n\n\n\n\n\n\n\n\nInsights\n\nThe data has been log-transformed, which suggests the original values had a skewed distribution (likely right-skewed).\nEfficiency_nm_per_kWh” and “Distance_Traveled_nm” have multiple red dots, indicating several outliers.\n“Revenue_per_Voyage_USD” and “Operational_Cost_USD” also have notable outliers, possibly reflecting extreme voyages or cost fluctuations.\n\n\n\n\n\n# Convert categorical variables into long format\nmarine_long &lt;- marine %&gt;%\n  select(Ship_Type, Route_Type, Engine_Type, Weather_Condition, Maintenance_Status) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Category\", values_to = \"Value\")\n\n# Create horizontal bar charts with different colors for categories\nggplot(marine_long, aes(y = Value, fill = Category)) +\n  geom_bar(color = \"black\") +  # Black outline for bars\n  facet_wrap(~Category, scales = \"free_y\") +  # Facet by category\n  labs(title = \"Categorical Variable Distributions\", x = \"Count\", y = \"Categories\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 10))  \n\n\n\n\n\n\n\n\nInsights\n\nThe most common engine types are Heavy Fuel Oil (HFO) and Diesel, suggesting that most ships operate on these fuel sources.\nMost ships are in Good or Fair maintenance condition, with fewer classified as Critical.\nLong-haul and Coastal routes also have a significant presence.\nBulk Carrier, Container Ship, and Fish Carrier are the most common ship types in the dataset.\nSince most ships operate in calm or moderate weather, it could suggest that voyages are planned around favorable conditions.\n\n\n\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# Create the faceted density plot (Speed Over Ground Distribution by Engine Power)\nspeed_densityplot &lt;- ggplot(data = marine, aes(x = Speed_Over_Ground_knots, fill = Engine_Type)) +    \n  geom_density(alpha = 0.3) + \n  facet_wrap(~ Engine_Type, scales = \"free_y\", nrow = 2) +  \n  labs(x = \"Speed Over Ground (knots)\", y = \"Density\", \n       title = \"Speed Distribution Across Engine Types\",\n       subtitle = \"Density plot of Speed Over Ground, colored by Engine Type\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set1\") +\n  theme(legend.position = \"none\", \n        plot.title = element_text(face = \"bold\", size = 12), \n        plot.subtitle = element_text(size = 8), \n        axis.title.y = element_text(size = 8), \n        axis.title.x = element_text(size = 8))\n\n# Create the boxplot for Speed Over Ground by Engine Type\nspeed_boxplot &lt;- ggplot(marine, aes(x = Engine_Type, y = Speed_Over_Ground_knots, fill = Engine_Type)) +\n  geom_boxplot(position = position_dodge(0.8)) +\n  theme_minimal() +\n  labs(y = \"Speed Over Ground (knots)\", subtitle = \"Box plots of Speed Over Ground by Engine Type\") +\n  theme(axis.title.x = element_blank(), \n        legend.title = element_text(face = \"bold\", size = 8), \n        plot.subtitle = element_text(size = 8), \n        axis.title.y = element_text(size = 8)) +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n# Combine the plots\nspeed_densityplot + speed_boxplot\n\n\n\n\n\n\n\n\nInsights\n\nDiesel and Heavy Fuel Oil (HFO) engines have unimodal distributions, meaning ships with these engines tend to operate at a consistent range of speeds.\nSteam Turbine: The bimodal distribution (two peaks) suggests two common speed ranges. This could indicate different operating modes, such as low-speed cruising and high-speed transit.\nThe median speed is similar across all engine types, around 17-18 knots. This suggests that regardless of engine type, ships tend to operate within a consistent speed range.\n\n\n\n\n\nBox PlotCode\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n# Function to create boxplots\nplot_efficiency_boxplot &lt;- function(var) {\n  ggplot(marine, aes(x = .data[[var]], y = Efficiency_nm_per_kWh, fill = .data[[var]])) +\n    geom_boxplot(outlier.colour = \"red\", outlier.shape = 16, alpha = 0.7) +\n    theme_minimal() +\n    labs(y = \"Efficiency (nm per kWh)\", x = var, \n         subtitle = paste(\"Boxplot of Efficiency across\", var)) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme(axis.title.x = element_text(face = \"bold\", size = 10),\n          legend.position = \"none\",\n          plot.subtitle = element_text(size = 10),\n          axis.title.y = element_text(size = 10)) +\n    coord_flip()\n}\n\n# Generate boxplots\nboxplot_ship &lt;- plot_efficiency_boxplot(\"Ship_Type\")\nboxplot_engine &lt;- plot_efficiency_boxplot(\"Engine_Type\")\nboxplot_route &lt;- plot_efficiency_boxplot(\"Route_Type\")\n\n# Display all boxplots together\nboxplot_ship / boxplot_engine / boxplot_route\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n# Function to create boxplots\nplot_efficiency_boxplot &lt;- function(var) {\n  ggplot(marine, aes(x = .data[[var]], y = Efficiency_nm_per_kWh, fill = .data[[var]])) +\n    geom_boxplot(outlier.colour = \"red\", outlier.shape = 16, alpha = 0.7) +\n    theme_minimal() +\n    labs(y = \"Efficiency (nm per kWh)\", x = var, \n         subtitle = paste(\"Boxplot of Efficiency across\", var)) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme(axis.title.x = element_text(face = \"bold\", size = 10),\n          legend.position = \"none\",\n          plot.subtitle = element_text(size = 10),\n          axis.title.y = element_text(size = 10)) +\n    coord_flip()\n}\n\n# Generate boxplots\nboxplot_ship &lt;- plot_efficiency_boxplot(\"Ship_Type\")\nboxplot_engine &lt;- plot_efficiency_boxplot(\"Engine_Type\")\nboxplot_route &lt;- plot_efficiency_boxplot(\"Route_Type\")\n\n# Display all boxplots together\nboxplot_ship / boxplot_engine / boxplot_route\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#| fig-width: 12\n#| fig-height: 10\n# Convert Efficiency into categories for heatmap visualization\nmarine &lt;- marine %&gt;%\n  mutate(\n    Efficiency_Category = factor(case_when(\n      Efficiency_nm_per_kWh &gt;= quantile(Efficiency_nm_per_kWh, 0.75, na.rm = TRUE) ~ \"High\",\n      Efficiency_nm_per_kWh &gt;= quantile(Efficiency_nm_per_kWh, 0.25, na.rm = TRUE) ~ \"Moderate\",\n      TRUE ~ \"Low\"\n    ), levels = c(\"Low\", \"Moderate\", \"High\"))\n  )\n\n# Calculate proportions across efficiency levels by category\nefficiency_proportions &lt;- marine %&gt;%\n  gather(key = \"Efficiency_Level\", value = \"Value\", Efficiency_Category) %&gt;%\n  count(Ship_Type, Engine_Type, Route_Type, Efficiency_Level, Value) %&gt;%\n  group_by(Ship_Type, Engine_Type, Route_Type, Efficiency_Level) %&gt;%\n  mutate(Proportion = n / sum(n),\n         Value = factor(Value, levels = c(\"Low\", \"Moderate\", \"High\"))) %&gt;%\n  ungroup()\n\n# Function to create heatmaps\nplot_efficiency_heatmap &lt;- function(var) {\n  ggplot(efficiency_proportions, aes(x = .data[[var]], y = Value, fill = Proportion)) +\n    geom_tile() +\n    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n    facet_wrap(~ Efficiency_Level, scales = \"free_x\") +\n    labs(x = var,\n         y = \"Efficiency Level\",\n         fill = \"Proportion\",\n         subtitle = paste(\"Heatmap of Efficiency in\", var)) +\n    theme_minimal() +\n    theme(panel.background = element_rect(fill = \"white\", colour = NA),\n          axis.text.x = element_text(size = 8, angle = 45), \n          axis.text.y = element_text(size = 8),\n          axis.title.x = element_text(size = 8),\n          axis.title.y = element_text(size = 8), \n          legend.text = element_text(size = 8),\n          legend.title = element_text(size = 8),\n          plot.subtitle = element_text(size = 8))\n}\n\n# Generate heatmaps\nefficiency_heatmap_ship &lt;- plot_efficiency_heatmap(\"Ship_Type\")\nefficiency_heatmap_engine &lt;- plot_efficiency_heatmap(\"Engine_Type\")\nefficiency_heatmap_route &lt;- plot_efficiency_heatmap(\"Route_Type\")\n\n# Display all heatmaps together\nefficiency_heatmap_ship + efficiency_heatmap_engine + efficiency_heatmap_route\n\n\n\n\n\n\n\n\nInsights\n\nModerate efficiency dominates across all categories, suggesting that most ships operate within standard efficiency ranges.\nBulk Carriers, Container Ships, Diesel, and HFO engines tend to be more efficient.\nFish Carriers, Steam Turbines, and Coastal Routes show greater efficiency variability, suggesting they are more sensitive to operational factors.\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(ggridges)\nlibrary(patchwork)\n\n# Compute Profitability\nmarine &lt;- marine %&gt;%\n  mutate(Profitability_USD = Revenue_per_Voyage_USD - Operational_Cost_USD)\n\n# Ridgeline Plot of Profitability by Ship Type\nprofitability_ridgeline &lt;- ggplot(marine, aes(x = Profitability_USD, y = Ship_Type, fill = 0.5 - abs(0.5 - stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\", direction = -1) +\n  labs(x = \"Profitability (USD)\", y = \"Ship Type\", \n       title = \"Profitability Distribution by Ship Type\",\n       subtitle = \"Ridgeline plot comparing density distributions\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", \n        plot.title = element_text(face = \"bold\", size = 12), \n        plot.subtitle = element_text(size = 10),\n        axis.title.y = element_text(size = 10), \n        axis.title.x = element_text(size = 10))\n\n# Display Ridgeline Plot\nprint(profitability_ridgeline)\n\n\n\n\n\n\n\n\nInsights\n\nMost ship types operate near break-even profitability, with some variation in earnings.\n\nBulk Carriers and Container Ships show more stable profitability trends.\n\nTanker ships have a wider range of profitability, potentially reflecting volatile fuel costs and market conditions.\n\n\n\n\n\n# Load required libraries\nlibrary(treemap)\nlibrary(dplyr)\n\n\n\n# Summarize data: Total revenue & average load percentage per Ship Type & Route Type\ntreemap_data &lt;- marine %&gt;%\n  group_by(Ship_Type, Route_Type) %&gt;%\n  summarise(\n    Total_Revenue = sum(Revenue_per_Voyage_USD, na.rm = TRUE),\n    Avg_Load = mean(Average_Load_Percentage, na.rm = TRUE)\n  ) %&gt;%\n  ungroup()\n\n# Generate treemap with color based on Ship_Type\ntm &lt;- treemap(treemap_data,\n        index = c(\"Ship_Type\", \"Route_Type\"),  # Hierarchical structure\n        vSize = \"Total_Revenue\",  # Size based on total revenue\n        vColor = \"Ship_Type\",  # Color by ship type (categorical)\n        type = \"categorical\",  # Use categorical color scheme\n        palette = \"Set3\",  # More distinct colors for ship types\n        title = \"Revenue Contribution by Ship Type and Route\",\n        title.legend = \"Ship Type\"\n)\n\n\n\n\n\n\n\n\n\nInsights\nBulk Carriers (green) and Container Ships (yellow) have the largest sections, indicating they generate the most revenue.\nWithin these ship types, Long-haul and Coastal routes contribute significantly.\nTransoceanic routes for Bulk Carriers are also substantial.\n\n\n\n\n\nFrom the analysis of ship performance, efficiency, profitability, and revenue distribution, the following key implications emerge:\n\nMost voyages occur under stable weather conditions, and route type significantly impacts operational choices.\nThe choice of engine type influences speed consistency, with Steam Turbines being more variable and Diesel/HFO engines maintaining steady performance.\nProfitability is highly dependent on ship type and operational costs. Container Ships and Bulk Carriers show consistent profits, while Tankers face more financial risk due to market volatility.\nShipping companies should prioritize investments in Bulk Carriers and Container Ships while optimizing Long-haul and Coastal routes. Short-haul voyages might need alternative revenue models or pricing strategies."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#overview",
    "href": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#overview",
    "title": "Take_Home Exercise 1",
    "section": "",
    "text": "The maritime sector is one of the most critical components of global trade, contributing significantly to economic growth and sustainability. Understanding ship performance, fuel efficiency, and operational cost factors are essential for improving decision-making and minimizing environmental impact.\nAn international media company that publishes weekly content on digital platforms is planning to release articles on “Ship Performance in the Gulf of Guinea”.\nAs the role of the graphical editor of the media company, I am going to prepare data visualization for the article.\n\n\n\nIn this exercise, Exploratory Data Analysis (EDA) methods and ggplot functions are used to explore:\n\nthe distribution of Ship performance in efficiency, operational cost, speed, fuel consumption, and revenue generation.\nthe relationship between these performances with draft, cargo weight, weather, engine type, ship type, seasonal impact and etc."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#getting-started",
    "title": "Take_Home Exercise 1",
    "section": "",
    "text": "The following R packages using the pacman::p_load() function are loaded.\n\ntidyverse: Core collection of R packages designed for data science\nhaven: To read in data formats such as SAS and SPSS\nggrepel: to provides geoms for ggplot2 to repel overlapping text labels\nggthemes: to use additional themes for ggplot2\npatchwork: to prepare composite figure created using ggplot2\nggridges: to plot ridgeline plots\nggdist: for visualizations of distributions and uncertainty\nscales: provides the internal scaling infrastructure used by ggplot2\n\n\npacman::p_load(tidyverse, haven,\n               ggrepel, ggthemes,\n               ggridges, ggdist,\n               patchwork, scales)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#data-wrangling",
    "title": "Take_Home Exercise 1",
    "section": "",
    "text": "The dataset used in the exercise is in CSV format, retrieved from Kaggle.comhttps://www.kaggle.com/datasets/jeleeladekunlefijabi/ship-performance-clustering-dataset\nThe code chunk below import the dataset using read_csv() function of the haven package.\n\nlibrary(readr) \nmarine &lt;- read_csv(\"data/Ship_Performance_Dataset.csv\")\n\n\n\n\nUsing the glimpse() function, we see that the dataset consists of 2,736 rows and 18 columns. It also shows the column names, column type, and the first few entries of each column.\n\nglimpse(marine)\n\nRows: 2,736\nColumns: 18\n$ Date                    &lt;date&gt; 2023-06-04, 2023-06-11, 2023-06-18, 2023-06-2…\n$ Ship_Type               &lt;chr&gt; \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              &lt;chr&gt; \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             &lt;chr&gt; \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Maintenance_Status      &lt;chr&gt; \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Draft_meters            &lt;dbl&gt; 14.132284, 14.653083, 7.199261, 11.789063, 9.7…\n$ Weather_Condition       &lt;chr&gt; \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Cargo_Weight_tons       &lt;dbl&gt; 1959.0179, 162.3947, 178.0409, 1737.3853, 260.…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Turnaround_Time_hours   &lt;dbl&gt; 25.86708, 63.24820, 49.41815, 22.40911, 64.158…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Seasonal_Impact_Score   &lt;dbl&gt; 1.4156533, 0.8856478, 1.4058132, 1.3707043, 0.…\n$ Weekly_Voyage_Count     &lt;dbl&gt; 1, 6, 9, 1, 8, 7, 3, 6, 8, 2, 9, 4, 3, 7, 7, 3…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…\n\n\n\n\n\nUsing the duplicated function, we see that there are no duplicate entries in the data.\n\nmarine[duplicated(marine),]\n\n# A tibble: 0 × 18\n# ℹ 18 variables: Date &lt;date&gt;, Ship_Type &lt;chr&gt;, Route_Type &lt;chr&gt;,\n#   Engine_Type &lt;chr&gt;, Maintenance_Status &lt;chr&gt;, Speed_Over_Ground_knots &lt;dbl&gt;,\n#   Engine_Power_kW &lt;dbl&gt;, Distance_Traveled_nm &lt;dbl&gt;, Draft_meters &lt;dbl&gt;,\n#   Weather_Condition &lt;chr&gt;, Cargo_Weight_tons &lt;dbl&gt;,\n#   Operational_Cost_USD &lt;dbl&gt;, Revenue_per_Voyage_USD &lt;dbl&gt;,\n#   Turnaround_Time_hours &lt;dbl&gt;, Efficiency_nm_per_kWh &lt;dbl&gt;,\n#   Seasonal_Impact_Score &lt;dbl&gt;, Weekly_Voyage_Count &lt;dbl&gt;, …\n\n\n\n\n\nNumerical Variables are selected to identify\nThe colSums() function in the base package is used to check for missing values in marine. There are no missing values in the tibble data frame.\n\ncolSums(is.na(marine))\n\n                   Date               Ship_Type              Route_Type \n                      0                       0                       0 \n            Engine_Type      Maintenance_Status Speed_Over_Ground_knots \n                      0                       0                       0 \n        Engine_Power_kW    Distance_Traveled_nm            Draft_meters \n                      0                       0                       0 \n      Weather_Condition       Cargo_Weight_tons    Operational_Cost_USD \n                      0                       0                       0 \n Revenue_per_Voyage_USD   Turnaround_Time_hours   Efficiency_nm_per_kWh \n                      0                       0                       0 \n  Seasonal_Impact_Score     Weekly_Voyage_Count Average_Load_Percentage \n                      0                       0                       0 \n\n\n\n\n\nNumerical variables are selected to perform correlation analysis. All the variables looks fine.\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(reshape2)\n\n# Select only numeric variables\nnumeric_vars &lt;- marine %&gt;% select(where(is.numeric))\n\n# Compute correlation matrix\ncor_matrix &lt;- cor(numeric_vars, use = \"complete.obs\")\n\n# Melt correlation matrix for better visualization\ncor_data &lt;- melt(cor_matrix)\n\n# Improved heatmap-style correlation matrix\nggplot(data = cor_data, aes(x=Var1, y=Var2, fill=value)) + \n  geom_tile(color = \"white\") + \n  geom_text(aes(label = round(value, 2)), color = \"black\", size = 3) + \n  scale_fill_gradient2(low = \"#E46726\", mid = \"white\", high = \"#6D9EC1\", midpoint = 0) +\n  labs(title = \"Correlation Matrix of Marine Dataset\",\n       x = \"\", y = \"\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\nOf 18 columns, the following 12 are preliminary selected to answer the analytical questions. The Code Book from Kaggle provides detailed description of the variables and I have referred to it..\n\n\n\n\n\n\n\n\nVariable Name\nDescription\nType of Variable\n\n\n\n\nShip_Type\nType of ship\n(Fish Carrier, Container Ship, Tanker, Bulk Carrier)\nCategorical\n\n\nRoute_Type\nShipping route type\n(Coastal, Short-haul, Long-haul, Transoceanic)\nCategorical\n\n\nEngine_Type\nType of engine\n(None, Diesel, Heavy Fuel Oil (HFO), Steam Turbine)\nCategorical\n\n\nWeather_Condition\nMaintenance condition of the ship\n(None, Calm, Moderate ,Rough)\nCategorical\n\n\nMaintenance_Status\nPrevailing weather conditions during voyages\n(None, Good, Fair, Critical)\nCategorical\n\n\nSpeed_Over_Ground_knots\nAverage speed of the ship over water\nNumerical\n\n\nEngine_Power_kW\nEngine power output\nNumerical\n\n\nDistance_Traveled_nm\nTotal distance traveled by the ship\nNumerical\n\n\nOperational_Cost_USD\nTotal operational cost per voyage\nNumerical\n\n\nRevenue_per_Voyage_USD\nRevenue generated per voyage\nNumerical\n\n\nEfficiency_nm_per_kWh\nEnergy efficiency calculated in nautical miles per kilowatt-hour\nNumerical\n\n\nAverage_Load_Percentage\nAverage load of the ship calculated in percentage\nNumerical\n\n\n\n\nmarine_filtered &lt;- marine %&gt;%\n  select(Ship_Type, Route_Type,Engine_Type,Weather_Condition,Maintenance_Status,Speed_Over_Ground_knots,\n        Engine_Power_kW, Distance_Traveled_nm,Operational_Cost_USD,Revenue_per_Voyage_USD,Efficiency_nm_per_kWh,\n        Average_Load_Percentage)\n\nglimpse(marine_filtered)\n\nRows: 2,736\nColumns: 12\n$ Ship_Type               &lt;chr&gt; \"Container Ship\", \"Fish Carrier\", \"Container S…\n$ Route_Type              &lt;chr&gt; \"None\", \"Short-haul\", \"Long-haul\", \"Transocean…\n$ Engine_Type             &lt;chr&gt; \"Heavy Fuel Oil (HFO)\", \"Steam Turbine\", \"Dies…\n$ Weather_Condition       &lt;chr&gt; \"Moderate\", \"Rough\", \"Moderate\", \"Moderate\", \"…\n$ Maintenance_Status      &lt;chr&gt; \"Critical\", \"Good\", \"Fair\", \"Fair\", \"Fair\", \"F…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 12.59756, 10.38758, 20.74975, 21.05510, 13.742…\n$ Engine_Power_kW         &lt;dbl&gt; 2062.9840, 1796.0574, 1648.5567, 915.2618, 108…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1030.9436, 1060.4864, 658.8741, 1126.8225, 144…\n$ Operational_Cost_USD    &lt;dbl&gt; 483832.35, 483388.00, 448543.40, 261349.61, 28…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 292183.27, 883765.79, 394018.75, 87551.38, 676…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 1.4551789, 0.2903614, 0.4995945, 0.7029057, 1.…\n$ Average_Load_Percentage &lt;dbl&gt; 93.76925, 93.89537, 96.21824, 66.19370, 80.008…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#exploratory-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#exploratory-data-analysis",
    "title": "Take_Home Exercise 1",
    "section": "",
    "text": "# Load necessary libraries\nlibrary(ggplot2)\nlibrary(ggridges)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(viridis)\nlibrary(patchwork)\n\n# Convert data to long format for visualization\nmarine_long &lt;- marine %&gt;%\n  pivot_longer(\n    cols = c(\"Speed_Over_Ground_knots\", \"Engine_Power_kW\", \"Distance_Traveled_nm\", \n             \"Operational_Cost_USD\", \"Revenue_per_Voyage_USD\", \"Efficiency_nm_per_kWh\", \n             \"Average_Load_Percentage\"),\n    names_to = \"Variable\",\n    values_to = \"Value\"\n  )\n\n# Apply log transformation for better scaling\nmarine_long &lt;- marine_long %&gt;%\n  mutate(Value = ifelse(Value &gt; 0, log10(Value), NA))  # Log transformation\n\n# Improved Ridge Plot (Better visualization of distributions)\nmarine_ridgeplot &lt;- ggplot(marine_long, aes(x = Value, y = Variable, fill = Variable)) +\n  geom_density_ridges(alpha = 0.7, quantile_lines = TRUE, \n                      quantile_fun = function(y, ...) quantile(y, probs = 0.5, na.rm = TRUE)) +\n  scale_x_continuous(name = \"Log-Transformed Values\", labels = scales::comma) +\n  scale_fill_viridis_d() +\n  labs(title = \"Distributions of Key Numerical Variables in Marine Dataset\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.title.y = element_blank())\n\n# Improved Boxplot (Detecting outliers with better scaling)\nmarine_boxplot &lt;- ggplot(marine_long, aes(x = Variable, y = Value, fill = Variable)) +\n  geom_boxplot(outlier.colour = \"red\", outlier.shape = 16, alpha = 0.8) +\n  coord_flip() +  \n  scale_fill_viridis_d() +\n  labs(title = \"Boxplots of Key Numerical Variables in Marine Dataset\",\n       subtitle = \"Red dots indicate potential outliers\",\n       x = \"\", y = \"Log-Transformed Values\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", axis.title.y = element_blank())\n\n# Combine Ridge Plot and Boxplot\nmarine_ridgeplot / marine_boxplot\n\n\n\n\n\n\n\n\nInsights\n\nThe data has been log-transformed, which suggests the original values had a skewed distribution (likely right-skewed).\nEfficiency_nm_per_kWh” and “Distance_Traveled_nm” have multiple red dots, indicating several outliers.\n“Revenue_per_Voyage_USD” and “Operational_Cost_USD” also have notable outliers, possibly reflecting extreme voyages or cost fluctuations.\n\n\n\n\n\n# Convert categorical variables into long format\nmarine_long &lt;- marine %&gt;%\n  select(Ship_Type, Route_Type, Engine_Type, Weather_Condition, Maintenance_Status) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Category\", values_to = \"Value\")\n\n# Create horizontal bar charts with different colors for categories\nggplot(marine_long, aes(y = Value, fill = Category)) +\n  geom_bar(color = \"black\") +  # Black outline for bars\n  facet_wrap(~Category, scales = \"free_y\") +  # Facet by category\n  labs(title = \"Categorical Variable Distributions\", x = \"Count\", y = \"Categories\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 10))  \n\n\n\n\n\n\n\n\nInsights\n\nThe most common engine types are Heavy Fuel Oil (HFO) and Diesel, suggesting that most ships operate on these fuel sources.\nMost ships are in Good or Fair maintenance condition, with fewer classified as Critical.\nLong-haul and Coastal routes also have a significant presence.\nBulk Carrier, Container Ship, and Fish Carrier are the most common ship types in the dataset.\nSince most ships operate in calm or moderate weather, it could suggest that voyages are planned around favorable conditions.\n\n\n\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# Create the faceted density plot (Speed Over Ground Distribution by Engine Power)\nspeed_densityplot &lt;- ggplot(data = marine, aes(x = Speed_Over_Ground_knots, fill = Engine_Type)) +    \n  geom_density(alpha = 0.3) + \n  facet_wrap(~ Engine_Type, scales = \"free_y\", nrow = 2) +  \n  labs(x = \"Speed Over Ground (knots)\", y = \"Density\", \n       title = \"Speed Distribution Across Engine Types\",\n       subtitle = \"Density plot of Speed Over Ground, colored by Engine Type\") +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Set1\") +\n  theme(legend.position = \"none\", \n        plot.title = element_text(face = \"bold\", size = 12), \n        plot.subtitle = element_text(size = 8), \n        axis.title.y = element_text(size = 8), \n        axis.title.x = element_text(size = 8))\n\n# Create the boxplot for Speed Over Ground by Engine Type\nspeed_boxplot &lt;- ggplot(marine, aes(x = Engine_Type, y = Speed_Over_Ground_knots, fill = Engine_Type)) +\n  geom_boxplot(position = position_dodge(0.8)) +\n  theme_minimal() +\n  labs(y = \"Speed Over Ground (knots)\", subtitle = \"Box plots of Speed Over Ground by Engine Type\") +\n  theme(axis.title.x = element_blank(), \n        legend.title = element_text(face = \"bold\", size = 8), \n        plot.subtitle = element_text(size = 8), \n        axis.title.y = element_text(size = 8)) +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n# Combine the plots\nspeed_densityplot + speed_boxplot\n\n\n\n\n\n\n\n\nInsights\n\nDiesel and Heavy Fuel Oil (HFO) engines have unimodal distributions, meaning ships with these engines tend to operate at a consistent range of speeds.\nSteam Turbine: The bimodal distribution (two peaks) suggests two common speed ranges. This could indicate different operating modes, such as low-speed cruising and high-speed transit.\nThe median speed is similar across all engine types, around 17-18 knots. This suggests that regardless of engine type, ships tend to operate within a consistent speed range.\n\n\n\n\n\nBox PlotCode\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n# Function to create boxplots\nplot_efficiency_boxplot &lt;- function(var) {\n  ggplot(marine, aes(x = .data[[var]], y = Efficiency_nm_per_kWh, fill = .data[[var]])) +\n    geom_boxplot(outlier.colour = \"red\", outlier.shape = 16, alpha = 0.7) +\n    theme_minimal() +\n    labs(y = \"Efficiency (nm per kWh)\", x = var, \n         subtitle = paste(\"Boxplot of Efficiency across\", var)) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme(axis.title.x = element_text(face = \"bold\", size = 10),\n          legend.position = \"none\",\n          plot.subtitle = element_text(size = 10),\n          axis.title.y = element_text(size = 10)) +\n    coord_flip()\n}\n\n# Generate boxplots\nboxplot_ship &lt;- plot_efficiency_boxplot(\"Ship_Type\")\nboxplot_engine &lt;- plot_efficiency_boxplot(\"Engine_Type\")\nboxplot_route &lt;- plot_efficiency_boxplot(\"Route_Type\")\n\n# Display all boxplots together\nboxplot_ship / boxplot_engine / boxplot_route\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n# Function to create boxplots\nplot_efficiency_boxplot &lt;- function(var) {\n  ggplot(marine, aes(x = .data[[var]], y = Efficiency_nm_per_kWh, fill = .data[[var]])) +\n    geom_boxplot(outlier.colour = \"red\", outlier.shape = 16, alpha = 0.7) +\n    theme_minimal() +\n    labs(y = \"Efficiency (nm per kWh)\", x = var, \n         subtitle = paste(\"Boxplot of Efficiency across\", var)) +\n    scale_fill_brewer(palette = \"Set2\") +\n    theme(axis.title.x = element_text(face = \"bold\", size = 10),\n          legend.position = \"none\",\n          plot.subtitle = element_text(size = 10),\n          axis.title.y = element_text(size = 10)) +\n    coord_flip()\n}\n\n# Generate boxplots\nboxplot_ship &lt;- plot_efficiency_boxplot(\"Ship_Type\")\nboxplot_engine &lt;- plot_efficiency_boxplot(\"Engine_Type\")\nboxplot_route &lt;- plot_efficiency_boxplot(\"Route_Type\")\n\n# Display all boxplots together\nboxplot_ship / boxplot_engine / boxplot_route\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#| fig-width: 12\n#| fig-height: 10\n# Convert Efficiency into categories for heatmap visualization\nmarine &lt;- marine %&gt;%\n  mutate(\n    Efficiency_Category = factor(case_when(\n      Efficiency_nm_per_kWh &gt;= quantile(Efficiency_nm_per_kWh, 0.75, na.rm = TRUE) ~ \"High\",\n      Efficiency_nm_per_kWh &gt;= quantile(Efficiency_nm_per_kWh, 0.25, na.rm = TRUE) ~ \"Moderate\",\n      TRUE ~ \"Low\"\n    ), levels = c(\"Low\", \"Moderate\", \"High\"))\n  )\n\n# Calculate proportions across efficiency levels by category\nefficiency_proportions &lt;- marine %&gt;%\n  gather(key = \"Efficiency_Level\", value = \"Value\", Efficiency_Category) %&gt;%\n  count(Ship_Type, Engine_Type, Route_Type, Efficiency_Level, Value) %&gt;%\n  group_by(Ship_Type, Engine_Type, Route_Type, Efficiency_Level) %&gt;%\n  mutate(Proportion = n / sum(n),\n         Value = factor(Value, levels = c(\"Low\", \"Moderate\", \"High\"))) %&gt;%\n  ungroup()\n\n# Function to create heatmaps\nplot_efficiency_heatmap &lt;- function(var) {\n  ggplot(efficiency_proportions, aes(x = .data[[var]], y = Value, fill = Proportion)) +\n    geom_tile() +\n    scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n    facet_wrap(~ Efficiency_Level, scales = \"free_x\") +\n    labs(x = var,\n         y = \"Efficiency Level\",\n         fill = \"Proportion\",\n         subtitle = paste(\"Heatmap of Efficiency in\", var)) +\n    theme_minimal() +\n    theme(panel.background = element_rect(fill = \"white\", colour = NA),\n          axis.text.x = element_text(size = 8, angle = 45), \n          axis.text.y = element_text(size = 8),\n          axis.title.x = element_text(size = 8),\n          axis.title.y = element_text(size = 8), \n          legend.text = element_text(size = 8),\n          legend.title = element_text(size = 8),\n          plot.subtitle = element_text(size = 8))\n}\n\n# Generate heatmaps\nefficiency_heatmap_ship &lt;- plot_efficiency_heatmap(\"Ship_Type\")\nefficiency_heatmap_engine &lt;- plot_efficiency_heatmap(\"Engine_Type\")\nefficiency_heatmap_route &lt;- plot_efficiency_heatmap(\"Route_Type\")\n\n# Display all heatmaps together\nefficiency_heatmap_ship + efficiency_heatmap_engine + efficiency_heatmap_route\n\n\n\n\n\n\n\n\nInsights\n\nModerate efficiency dominates across all categories, suggesting that most ships operate within standard efficiency ranges.\nBulk Carriers, Container Ships, Diesel, and HFO engines tend to be more efficient.\nFish Carriers, Steam Turbines, and Coastal Routes show greater efficiency variability, suggesting they are more sensitive to operational factors.\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(ggridges)\nlibrary(patchwork)\n\n# Compute Profitability\nmarine &lt;- marine %&gt;%\n  mutate(Profitability_USD = Revenue_per_Voyage_USD - Operational_Cost_USD)\n\n# Ridgeline Plot of Profitability by Ship Type\nprofitability_ridgeline &lt;- ggplot(marine, aes(x = Profitability_USD, y = Ship_Type, fill = 0.5 - abs(0.5 - stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\", direction = -1) +\n  labs(x = \"Profitability (USD)\", y = \"Ship Type\", \n       title = \"Profitability Distribution by Ship Type\",\n       subtitle = \"Ridgeline plot comparing density distributions\") +\n  theme_minimal() +\n  theme(legend.position = \"none\", \n        plot.title = element_text(face = \"bold\", size = 12), \n        plot.subtitle = element_text(size = 10),\n        axis.title.y = element_text(size = 10), \n        axis.title.x = element_text(size = 10))\n\n# Display Ridgeline Plot\nprint(profitability_ridgeline)\n\n\n\n\n\n\n\n\nInsights\n\nMost ship types operate near break-even profitability, with some variation in earnings.\n\nBulk Carriers and Container Ships show more stable profitability trends.\n\nTanker ships have a wider range of profitability, potentially reflecting volatile fuel costs and market conditions.\n\n\n\n\n\n# Load required libraries\nlibrary(treemap)\nlibrary(dplyr)\n\n\n\n# Summarize data: Total revenue & average load percentage per Ship Type & Route Type\ntreemap_data &lt;- marine %&gt;%\n  group_by(Ship_Type, Route_Type) %&gt;%\n  summarise(\n    Total_Revenue = sum(Revenue_per_Voyage_USD, na.rm = TRUE),\n    Avg_Load = mean(Average_Load_Percentage, na.rm = TRUE)\n  ) %&gt;%\n  ungroup()\n\n# Generate treemap with color based on Ship_Type\ntm &lt;- treemap(treemap_data,\n        index = c(\"Ship_Type\", \"Route_Type\"),  # Hierarchical structure\n        vSize = \"Total_Revenue\",  # Size based on total revenue\n        vColor = \"Ship_Type\",  # Color by ship type (categorical)\n        type = \"categorical\",  # Use categorical color scheme\n        palette = \"Set3\",  # More distinct colors for ship types\n        title = \"Revenue Contribution by Ship Type and Route\",\n        title.legend = \"Ship Type\"\n)\n\n\n\n\n\n\n\n\n\nInsights\nBulk Carriers (green) and Container Ships (yellow) have the largest sections, indicating they generate the most revenue.\nWithin these ship types, Long-haul and Coastal routes contribute significantly.\nTransoceanic routes for Bulk Carriers are also substantial."
  },
  {
    "objectID": "In_class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In_class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class_Ex05",
    "section": "",
    "text": "Getting Started\n\npacman:: p_load(tidyverse,readxl,SmartEDA,easystats,gtsummary,ggstatsplot)\n\nImporting Data\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\"data\")\n\n\nglimpse(car_resale)\n\nRows: 1,436\nColumns: 38\n$ Id               &lt;dbl&gt; 81, 1, 2, 3, 4, 5, 6, 7, 8, 44, 45, 46, 47, 49, 51, 6…\n$ Model            &lt;chr&gt; \"TOYOTA Corolla 1.6 5drs 1 4/5-Doors\", \"TOYOTA Coroll…\n$ Price            &lt;dbl&gt; 18950, 13500, 13750, 13950, 14950, 13750, 12950, 1690…\n$ Age_08_04        &lt;dbl&gt; 25, 23, 23, 24, 26, 30, 32, 27, 30, 27, 22, 23, 27, 2…\n$ Mfg_Month        &lt;dbl&gt; 8, 10, 10, 9, 7, 3, 1, 6, 3, 6, 11, 10, 6, 11, 11, 11…\n$ Mfg_Year         &lt;dbl&gt; 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002, 2002,…\n$ KM               &lt;dbl&gt; 20019, 46986, 72937, 41711, 48000, 38500, 61000, 9461…\n$ Quarterly_Tax    &lt;dbl&gt; 100, 210, 210, 210, 210, 210, 210, 210, 210, 234, 234…\n$ Weight           &lt;dbl&gt; 1180, 1165, 1165, 1165, 1165, 1170, 1170, 1245, 1245,…\n$ Guarantee_Period &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ HP_Bin           &lt;chr&gt; \"100-120\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100\", \"&lt; 100…\n$ CC_bin           &lt;chr&gt; \"1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", \"&gt;1600\", …\n$ Doors            &lt;dbl&gt; 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 3, 3,…\n$ Gears            &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,…\n$ Cylinders        &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ Fuel_Type        &lt;chr&gt; \"Petrol\", \"Diesel\", \"Diesel\", \"Diesel\", \"Diesel\", \"Di…\n$ Color            &lt;chr&gt; \"Blue\", \"Blue\", \"Silver\", \"Blue\", \"Black\", \"Black\", \"…\n$ Met_Color        &lt;dbl&gt; 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,…\n$ Automatic        &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mfr_Guarantee    &lt;dbl&gt; 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,…\n$ BOVAG_Guarantee  &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ ABS              &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_1         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airbag_2         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Airco            &lt;dbl&gt; 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Automatic_airco  &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,…\n$ Boardcomputer    &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ CD_Player        &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,…\n$ Central_Lock     &lt;dbl&gt; 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Powered_Windows  &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Power_Steering   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Radio            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Mistlamps        &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Sport_Model      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,…\n$ Backseat_Divider &lt;dbl&gt; 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Metallic_Rim     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Radio_cassette   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Tow_Bar          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\nlist(car_resale)\n\n[[1]]\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\nsummary(car_resale)\n\n       Id            Model               Price         Age_08_04    \n Min.   :   1.0   Length:1436        Min.   : 4350   Min.   : 1.00  \n 1st Qu.: 361.8   Class :character   1st Qu.: 8450   1st Qu.:44.00  \n Median : 721.5   Mode  :character   Median : 9900   Median :61.00  \n Mean   : 721.6                      Mean   :10731   Mean   :55.95  \n 3rd Qu.:1081.2                      3rd Qu.:11950   3rd Qu.:70.00  \n Max.   :1442.0                      Max.   :32500   Max.   :80.00  \n   Mfg_Month         Mfg_Year          KM         Quarterly_Tax   \n Min.   : 1.000   Min.   :1998   Min.   :     1   Min.   : 19.00  \n 1st Qu.: 3.000   1st Qu.:1998   1st Qu.: 43000   1st Qu.: 69.00  \n Median : 5.000   Median :1999   Median : 63390   Median : 85.00  \n Mean   : 5.549   Mean   :2000   Mean   : 68533   Mean   : 87.12  \n 3rd Qu.: 8.000   3rd Qu.:2001   3rd Qu.: 87021   3rd Qu.: 85.00  \n Max.   :12.000   Max.   :2004   Max.   :243000   Max.   :283.00  \n     Weight     Guarantee_Period    HP_Bin             CC_bin         \n Min.   :1000   Min.   : 3.000   Length:1436        Length:1436       \n 1st Qu.:1040   1st Qu.: 3.000   Class :character   Class :character  \n Median :1070   Median : 3.000   Mode  :character   Mode  :character  \n Mean   :1072   Mean   : 3.815                                        \n 3rd Qu.:1085   3rd Qu.: 3.000                                        \n Max.   :1615   Max.   :36.000                                        \n     Doors           Gears         Cylinders  Fuel_Type        \n Min.   :2.000   Min.   :3.000   Min.   :4   Length:1436       \n 1st Qu.:3.000   1st Qu.:5.000   1st Qu.:4   Class :character  \n Median :4.000   Median :5.000   Median :4   Mode  :character  \n Mean   :4.033   Mean   :5.026   Mean   :4                     \n 3rd Qu.:5.000   3rd Qu.:5.000   3rd Qu.:4                     \n Max.   :5.000   Max.   :6.000   Max.   :4                     \n    Color             Met_Color        Automatic       Mfr_Guarantee   \n Length:1436        Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n Class :character   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Mode  :character   Median :1.0000   Median :0.00000   Median :0.0000  \n                    Mean   :0.6748   Mean   :0.05571   Mean   :0.4095  \n                    3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n                    Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n BOVAG_Guarantee       ABS            Airbag_1         Airbag_2     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000  \n Mean   :0.8955   Mean   :0.8134   Mean   :0.9708   Mean   :0.7228  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n     Airco        Automatic_airco   Boardcomputer      CD_Player     \n Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.00000   Median :0.0000   Median :0.0000  \n Mean   :0.5084   Mean   :0.05641   Mean   :0.2946   Mean   :0.2187  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000  \n  Central_Lock    Powered_Windows Power_Steering       Radio       \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.000   Median :1.0000   Median :0.0000  \n Mean   :0.5801   Mean   :0.562   Mean   :0.9777   Mean   :0.1462  \n 3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n   Mistlamps      Sport_Model     Backseat_Divider  Metallic_Rim   \n Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :0.000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.257   Mean   :0.3001   Mean   :0.7702   Mean   :0.2047  \n 3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n Radio_cassette      Tow_Bar      \n Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000  \n Mean   :0.1455   Mean   :0.2779  \n 3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000  \n\n\nData Overview\n\ncar_resale %&gt;%\n   ExpData(type=1)\n\n                                          Descriptions     Value\n1                                   Sample size (nrow)      1436\n2                              No. of variables (ncol)        38\n3                    No. of numeric/interger variables        33\n4                              No. of factor variables         0\n5                                No. of text variables         5\n6                             No. of logical variables         0\n7                          No. of identifier variables         1\n8                                No. of date variables         0\n9             No. of zero variance variables (uniform)         1\n10               %. of variables having complete cases 100% (38)\n11   %. of variables having &gt;0% and &lt;50% missing cases    0% (0)\n12 %. of variables having &gt;=50% and &lt;90% missing cases    0% (0)\n13          %. of variables having &gt;=90% missing cases    0% (0)\n\n\n\ncar_resale %&gt;%\n  ExpData(type=2)\n\n   Index    Variable_Name Variable_Type Sample_n Missing_Count Per_of_Missing\n1      1               Id       numeric     1436             0              0\n2      2            Model     character     1436             0              0\n3      3            Price       numeric     1436             0              0\n4      4        Age_08_04       numeric     1436             0              0\n5      5        Mfg_Month       numeric     1436             0              0\n6      6         Mfg_Year       numeric     1436             0              0\n7      7               KM       numeric     1436             0              0\n8      8    Quarterly_Tax       numeric     1436             0              0\n9      9           Weight       numeric     1436             0              0\n10    10 Guarantee_Period       numeric     1436             0              0\n11    11           HP_Bin     character     1436             0              0\n12    12           CC_bin     character     1436             0              0\n13    13            Doors       numeric     1436             0              0\n14    14            Gears       numeric     1436             0              0\n15    15        Cylinders       numeric     1436             0              0\n16    16        Fuel_Type     character     1436             0              0\n17    17            Color     character     1436             0              0\n18    18        Met_Color       numeric     1436             0              0\n19    19        Automatic       numeric     1436             0              0\n20    20    Mfr_Guarantee       numeric     1436             0              0\n21    21  BOVAG_Guarantee       numeric     1436             0              0\n22    22              ABS       numeric     1436             0              0\n23    23         Airbag_1       numeric     1436             0              0\n24    24         Airbag_2       numeric     1436             0              0\n25    25            Airco       numeric     1436             0              0\n26    26  Automatic_airco       numeric     1436             0              0\n27    27    Boardcomputer       numeric     1436             0              0\n28    28        CD_Player       numeric     1436             0              0\n29    29     Central_Lock       numeric     1436             0              0\n30    30  Powered_Windows       numeric     1436             0              0\n31    31   Power_Steering       numeric     1436             0              0\n32    32            Radio       numeric     1436             0              0\n33    33        Mistlamps       numeric     1436             0              0\n34    34      Sport_Model       numeric     1436             0              0\n35    35 Backseat_Divider       numeric     1436             0              0\n36    36     Metallic_Rim       numeric     1436             0              0\n37    37   Radio_cassette       numeric     1436             0              0\n38    38          Tow_Bar       numeric     1436             0              0\n   No_of_distinct_values\n1                   1436\n2                    372\n3                    236\n4                     77\n5                     12\n6                      7\n7                   1263\n8                     13\n9                     59\n10                     9\n11                     3\n12                     3\n13                     4\n14                     4\n15                     1\n16                     3\n17                    10\n18                     2\n19                     2\n20                     2\n21                     2\n22                     2\n23                     2\n24                     2\n25                     2\n26                     2\n27                     2\n28                     2\n29                     2\n30                     2\n31                     2\n32                     2\n33                     2\n34                     2\n35                     2\n36                     2\n37                     2\n38                     2\n\n\n\ncols &lt;- c(\"Mfg_Month\" , \"HP_Bin\", \"CC_bin\", \"Doors\",  \"Gears\", \n\"Cylinders\", \"Fuel_Type\", \"Color\",\n          \"Met_Color\", \"Automatic\", \"Mfr_Guarantee\", \"BOVAG_Guarantee\",\n\"ABS\", \"Airbag_1\",\n      \"Airbag_2\", \"Airco\", \"Automatic_airco\", \"Boardcomputer\",\n\"CD_Player\",\n      \"Central_Lock\", \"Powered_Windows\",\"Power_Steering\", \"Radio\",\n\"Mistlamps\",\n      \"Sport_Model\", \"Backseat_Divider\", \"Metallic_Rim\",\n      \"Radio_cassette\", \"Tow_Bar\")\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       sheet = \"data\") %&gt;%\n  mutate(ID = as.character(Id)) %&gt;%\n  mutate_each_(funs(factor(.)),cols)\n\n\nsummary(car_resale)\n\n       Id            Model               Price         Age_08_04    \n Min.   :   1.0   Length:1436        Min.   : 4350   Min.   : 1.00  \n 1st Qu.: 361.8   Class :character   1st Qu.: 8450   1st Qu.:44.00  \n Median : 721.5   Mode  :character   Median : 9900   Median :61.00  \n Mean   : 721.6                      Mean   :10731   Mean   :55.95  \n 3rd Qu.:1081.2                      3rd Qu.:11950   3rd Qu.:70.00  \n Max.   :1442.0                      Max.   :32500   Max.   :80.00  \n                                                                    \n   Mfg_Month      Mfg_Year          KM         Quarterly_Tax        Weight    \n 1      :207   Min.   :1998   Min.   :     1   Min.   : 19.00   Min.   :1000  \n 4      :154   1st Qu.:1998   1st Qu.: 43000   1st Qu.: 69.00   1st Qu.:1040  \n 3      :138   Median :1999   Median : 63390   Median : 85.00   Median :1070  \n 2      :134   Mean   :2000   Mean   : 68533   Mean   : 87.12   Mean   :1072  \n 7      :133   3rd Qu.:2001   3rd Qu.: 87021   3rd Qu.: 85.00   3rd Qu.:1085  \n 6      :120   Max.   :2004   Max.   :243000   Max.   :283.00   Max.   :1615  \n (Other):550                                                                  \n Guarantee_Period     HP_Bin      CC_bin    Doors   Gears    Cylinders\n Min.   : 3.000   &lt; 100  :560   &lt;1600:416   2:  2   3:   2   4:1436   \n 1st Qu.: 3.000   &gt; 120  : 11   &gt;1600:166   3:622   4:   1            \n Median : 3.000   100-120:865   1600 :854   4:138   5:1390            \n Mean   : 3.815                             5:674   6:  43            \n 3rd Qu.: 3.000                                                       \n Max.   :36.000                                                       \n                                                                      \n  Fuel_Type        Color     Met_Color Automatic Mfr_Guarantee BOVAG_Guarantee\n CNG   :  17   Grey   :301   0:467     0:1356    0:848         0: 150         \n Diesel: 155   Blue   :283   1:969     1:  80    1:588         1:1286         \n Petrol:1264   Red    :278                                                    \n               Green  :220                                                    \n               Black  :191                                                    \n               Silver :122                                                    \n               (Other): 41                                                    \n ABS      Airbag_1 Airbag_2 Airco   Automatic_airco Boardcomputer CD_Player\n 0: 268   0:  42   0: 398   0:706   0:1355          0:1013        0:1122   \n 1:1168   1:1394   1:1038   1:730   1:  81          1: 423        1: 314   \n                                                                           \n                                                                           \n                                                                           \n                                                                           \n                                                                           \n Central_Lock Powered_Windows Power_Steering Radio    Mistlamps Sport_Model\n 0:603        0:629           0:  32         0:1226   0:1067    0:1005     \n 1:833        1:807           1:1404         1: 210   1: 369    1: 431     \n                                                                           \n                                                                           \n                                                                           \n                                                                           \n                                                                           \n Backseat_Divider Metallic_Rim Radio_cassette Tow_Bar       ID           \n 0: 330           0:1142       0:1227         0:1037   Length:1436       \n 1:1106           1: 294       1: 209         1: 399   Class :character  \n                                                       Mode  :character  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n\n\n\ncar_resale %&gt;%\n   ExpData(type=1)\n\n                                          Descriptions     Value\n1                                   Sample size (nrow)      1436\n2                              No. of variables (ncol)        39\n3                    No. of numeric/interger variables         8\n4                              No. of factor variables        29\n5                                No. of text variables         2\n6                             No. of logical variables         0\n7                          No. of identifier variables         2\n8                                No. of date variables         0\n9             No. of zero variance variables (uniform)         1\n10               %. of variables having complete cases 100% (39)\n11   %. of variables having &gt;0% and &lt;50% missing cases    0% (0)\n12 %. of variables having &gt;=50% and &lt;90% missing cases    0% (0)\n13          %. of variables having &gt;=90% missing cases    0% (0)\n\n\n\ncar_resale %&gt;%\n   ExpData(type=2)\n\n   Index    Variable_Name Variable_Type Sample_n Missing_Count Per_of_Missing\n1      1               Id       numeric     1436             0              0\n2      2            Model     character     1436             0              0\n3      3            Price       numeric     1436             0              0\n4      4        Age_08_04       numeric     1436             0              0\n5      5        Mfg_Month        factor     1436             0              0\n6      6         Mfg_Year       numeric     1436             0              0\n7      7               KM       numeric     1436             0              0\n8      8    Quarterly_Tax       numeric     1436             0              0\n9      9           Weight       numeric     1436             0              0\n10    10 Guarantee_Period       numeric     1436             0              0\n11    11           HP_Bin        factor     1436             0              0\n12    12           CC_bin        factor     1436             0              0\n13    13            Doors        factor     1436             0              0\n14    14            Gears        factor     1436             0              0\n15    15        Cylinders        factor     1436             0              0\n16    16        Fuel_Type        factor     1436             0              0\n17    17            Color        factor     1436             0              0\n18    18        Met_Color        factor     1436             0              0\n19    19        Automatic        factor     1436             0              0\n20    20    Mfr_Guarantee        factor     1436             0              0\n21    21  BOVAG_Guarantee        factor     1436             0              0\n22    22              ABS        factor     1436             0              0\n23    23         Airbag_1        factor     1436             0              0\n24    24         Airbag_2        factor     1436             0              0\n25    25            Airco        factor     1436             0              0\n26    26  Automatic_airco        factor     1436             0              0\n27    27    Boardcomputer        factor     1436             0              0\n28    28        CD_Player        factor     1436             0              0\n29    29     Central_Lock        factor     1436             0              0\n30    30  Powered_Windows        factor     1436             0              0\n31    31   Power_Steering        factor     1436             0              0\n32    32            Radio        factor     1436             0              0\n33    33        Mistlamps        factor     1436             0              0\n34    34      Sport_Model        factor     1436             0              0\n35    35 Backseat_Divider        factor     1436             0              0\n36    36     Metallic_Rim        factor     1436             0              0\n37    37   Radio_cassette        factor     1436             0              0\n38    38          Tow_Bar        factor     1436             0              0\n39    39               ID     character     1436             0              0\n   No_of_distinct_values\n1                   1436\n2                    372\n3                    236\n4                     77\n5                     12\n6                      7\n7                   1263\n8                     13\n9                     59\n10                     9\n11                     3\n12                     3\n13                     4\n14                     4\n15                     1\n16                     3\n17                    10\n18                     2\n19                     2\n20                     2\n21                     2\n22                     2\n23                     2\n24                     2\n25                     2\n26                     2\n27                     2\n28                     2\n29                     2\n30                     2\n31                     2\n32                     2\n33                     2\n34                     2\n35                     2\n36                     2\n37                     2\n38                     2\n39                  1436\n\n\nExplore Numerical Viz ()\n\ncar_resale %&gt;%\n  ExpNumViz(target=NULL,\n            nlim=10,\n            Page=c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncar_resale %&gt;%\n  ExpNumViz(target=\"Price\",\n            nlim=10,\n            Page=c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBar plots for all categorical variables\n\n  car_resale %&gt;%\n  ExpCatViz(target= NULL,\n            col =\"sky blue\",\n            clim=10,\n            margin=2,\n            Page=c(4,4),\n            sample=16)\n\n$`0`\n\n\n\n\n\n\n\n\n\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year +KM +\n               Weight + Guarantee_Period, \n  data=car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 +KM +\n               Weight + Guarantee_Period, \n  data=car_resale)\ncheck_normality(model1)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\n\ncheck_heteroscedasticity(model1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\nsummary(model)\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10426.3   -737.3     -6.4    739.1   6591.4 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -2.637e+06  2.618e+05 -10.072   &lt;2e-16 ***\nAge_08_04        -1.409e+01  1.081e+01  -1.304   0.1924    \nMfg_Year          1.315e+03  1.307e+02  10.064   &lt;2e-16 ***\nKM               -2.323e-02  1.163e-03 -19.969   &lt;2e-16 ***\nWeight            1.903e+01  8.129e-01  23.405   &lt;2e-16 ***\nGuarantee_Period  2.770e+01  1.219e+01   2.272   0.0232 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1366 on 1430 degrees of freedom\nMultiple R-squared:  0.8586,    Adjusted R-squared:  0.8581 \nF-statistic:  1737 on 5 and 1430 DF,  p-value: &lt; 2.2e-16\n\n\n\ntbl_regression(model1,\n               intercept=TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n-2,186\n-4,093, -278\n0.025\n\n\nAge_08_04\n-119\n-125, -114\n&lt;0.001\n\n\nKM\n-0.02\n-0.03, -0.02\n&lt;0.001\n\n\nWeight\n20\n18, 21\n&lt;0.001\n\n\nGuarantee_Period\n27\n2.1, 52\n0.034\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\ntbl_regression(model1,\n               intercept= TRUE) %&gt;%\n  add_glance_source_note(\n    label= list(sigma ~ \"\\U03C3\"),\n    include= c(r.squared, adj.r.squared,\n               AIC, statistic,\n               p.value,sigma)\n  )\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,186\n-4,093, -278\n0.025\n    Age_08_04\n-119\n-125, -114\n&lt;0.001\n    KM\n-0.02\n-0.03, -0.02\n&lt;0.001\n    Weight\n20\n18, 21\n&lt;0.001\n    Guarantee_Period\n27\n2.1, 52\n0.034\n  \n  \n    \n      R² = 0.849; Adjusted R² = 0.848; AIC = 24,915; Statistic = 2,005; p-value = &lt;0.001; σ = 1,413\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\np_model1 &lt;- parameters(model1)\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\nggcoefstats(model1,\n            output = \"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#summary-and-conclusion",
    "href": "Take-home_Ex/Take-home_Ex1/Take_home_Ex1.html#summary-and-conclusion",
    "title": "Take_Home Exercise 1",
    "section": "",
    "text": "From the analysis of ship performance, efficiency, profitability, and revenue distribution, the following key implications emerge:\n\nMost voyages occur under stable weather conditions, and route type significantly impacts operational choices.\nThe choice of engine type influences speed consistency, with Steam Turbines being more variable and Diesel/HFO engines maintaining steady performance.\nProfitability is highly dependent on ship type and operational costs. Container Ships and Bulk Carriers show consistent profits, while Tankers face more financial risk due to market volatility.\nShipping companies should prioritize investments in Bulk Carriers and Container Ships while optimizing Long-haul and Coastal routes. Short-haul voyages might need alternative revenue models or pricing strategies."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 07: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "plotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#learning-outcome",
    "title": "Hands-on Exercise 07: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "plotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#getting-started",
    "title": "Hands-on Exercise 07: Visualising and Analysing Time-oriented Data",
    "section": "7.2 Getting Started",
    "text": "7.2 Getting Started\n\npacman:: p_load(tidyverse,scales, viridis, lubridate, ggplot2 ,dplyr, ggthemes, gridExtra, readxl, knitr, data.table)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 07: Visualising and Analysing Time-oriented Data",
    "section": "7.4 Plotting Calendar Heatmap",
    "text": "7.4 Plotting Calendar Heatmap\n\n7.4.1 The Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n7.4.2 Importing the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"eventlog.csv\")\n\n\n\n7.4.3 Examining the data structure\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\n7.4.4 Data Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n7.4.5 Building the Calendar Heatmaps\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n7.4.6 Building Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\nStep 1: Deriving attack by country object\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 07: Visualising and Analysing Time-oriented Data",
    "section": "7.5 Plotting Cycle Plot",
    "text": "7.5 Plotting Cycle Plot\nLearning how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n7.5.1 Step 1: Data Import\n\nair &lt;- read_excel(\"arrivals_by_air.xlsx\")\n\n\n\n7.5.2 Step 2: Deriving month and year fields\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n7.5.3 Step 4: Extracting the target country\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n7.5.4 Step 5: Computing year average arrivals by month\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n7.5.5 Srep 6: Plotting the cycle plot\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#plotting-slopegraph",
    "title": "Hands-on Exercise 07: Visualising and Analysing Time-oriented Data",
    "section": "7.6 Plotting Slopegraph",
    "text": "7.6 Plotting Slopegraph\n\n7.6.1 Step 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"rice.csv\")\n\n\n\n7.6.2 Step 2: Plotting the slopegraph\n\nlibrary(CGPfunctions)\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Pwint Phoo Thaw\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 04: Visualising Distribution",
    "section": "",
    "text": "In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-outcome",
    "title": "Hands-on Exercise 04: Visualising Distribution",
    "section": "",
    "text": "In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "title": "Hands-on Exercise 04: Visualising Distribution",
    "section": "4.2 Getting Started",
    "text": "4.2 Getting Started\n\n4.2.1 Installing and loading the packages\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n4.2.2 Data import\n\nexam &lt;- read_csv(\"Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 04: Visualising Distribution",
    "section": "4.3 Visualising Distribution with Ridgeline Plot",
    "text": "4.3 Visualising Distribution with Ridgeline Plot\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\n\n4.3.1 Plotting ridgeline graph: ggridges method\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n4.3.2 Varying fill colors along the x axis\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n4.3.3 Mapping the probabilities directly onto colour\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n4.3.4 Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-on Exercise 04: Visualising Distribution",
    "section": "4.4 Visualising Distribution with Raincloud Plot",
    "text": "4.4 Visualising Distribution with Raincloud Plot\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\n\n4.4.1 Plotting a Half Eye graph\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\n4.4.2 Adding the boxplot with geom_boxplot()\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\n\n\n4.4.3 Adding the Dot Plots with stat_dots()\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\n\n\n4.4.4 Finishing touch\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\n\n\n\n\npacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"respopagsex2000to2018_tidy.csv\") \n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "",
    "text": "pacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "",
    "text": "For the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"respopagsex2000to2018_tidy.csv\") \n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "",
    "text": "#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-1",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.1 Overview",
    "text": "5.1 Overview\nCorrelation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-1",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.2 Installing and Launching R Packages",
    "text": "5.2 Installing and Launching R Packages\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.3 Importing and Preparing The Data Set",
    "text": "5.3 Importing and Preparing The Data Set\n\nwine &lt;- read_csv(\"wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.4 Building Correlation Matrix: pairs() method",
    "text": "5.4 Building Correlation Matrix: pairs() method\n\n5.4.1 Building a basic correlation matrix\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n5.4.2 Drawing the lower corner\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n5.4.3 Including with correlation coefficients\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.5 Visualising Correlation Matrix: ggcormat()",
    "text": "5.5 Visualising Correlation Matrix: ggcormat()\n\n5.5.1 The basic plot\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-multiple-plots",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.6 Building multiple plots",
    "text": "5.6 Building multiple plots\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.7 Visualising Correlation Matrix using corrplot Package",
    "text": "5.7 Visualising Correlation Matrix using corrplot Package\n\n5.7.1 Getting started with corrplot\n\nwine.cor &lt;- cor(wine[, 1:11])\n\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\n\n\n5.7.2 Working with visual geometrics\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\n\n\n5.7.3 Working with layout\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n5.7.4 Working with mixed layout\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n5.7.5 Combining corrgram with the significant test\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n5.7.6 Reorder a corrgram\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n5.7.7 Reordering a correlation matrix using hclust\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-2",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-2",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.1 Overview",
    "text": "5.1 Overview\nHeatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-2",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-2",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.2 Installing and Launching R Packages",
    "text": "5.2 Installing and Launching R Packages\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set-1",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.3 Importing and Preparing The Data Set",
    "text": "5.3 Importing and Preparing The Data Set\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n5.3.1 Importing the data set\n\nwh &lt;- read_csv(\"WHData-2018.csv\")\n\n\n\n5.3.3 Transforming the data frame into a matrix\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#static-heatmap",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.4 Static Heatmap",
    "text": "5.4 Static Heatmap\n\n5.4.1 heatmap() of R Stats\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.5 Creating Interactive Heatmap",
    "text": "5.5 Creating Interactive Heatmap\n\n5.5.1 Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\n\n5.5.2 Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n4.5.2.2 Normalising method\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n5.5.2.2 Normalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n5.5.2.3 Percentising method\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n4.5.3 Clustering algorithm\n\n\n4.5.4 Manual approach\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n4.5.5 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n5.5.6 Seriation\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n5.5.7 Working with colour palettes\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n5.5.8 The finishing touch\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-3",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-3",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.1 Overview",
    "text": "5.1 Overview\nParallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-3",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-3",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.2 Installing and Launching R Packages",
    "text": "5.2 Installing and Launching R Packages\n\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation-1",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.3 Data Preparation",
    "text": "5.3 Data Preparation\n\nwh &lt;- read_csv(\"WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.4 Plotting Static Parallel Coordinates Plot",
    "text": "5.4 Plotting Static Parallel Coordinates Plot\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\n\n5.4.2 Plotting a parallel coordinates with boxplot\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\n\n\n5.4.3 Parallel coordinates with facet\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\n\n\n5.4.4 Rotating x-axis text label\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\n\n5.4.5 Adjusting the rotated x-axis text label\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "5.5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\n\n5.5.2 Rotate axis label\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n5.5.3 Changing the colour scheme\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n5.5.4 Parallel coordinates plot with histogram\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-4",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-4",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.1 Overview",
    "text": "5.1 Overview"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-4",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-4",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.2 Installing and Launching R Packages",
    "text": "5.2 Installing and Launching R Packages\n\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-wrangling",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "6.3 Data Wrangling",
    "text": "6.3 Data Wrangling\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\nrealis2018 &lt;- read_csv(\"realis2018.csv\")\n\n\n5.3.3 Grouped summaries without the Pipe\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n6.3.4 Grouped summaries with the pipe\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-with-treemap-package",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.4 Designing Treemap with treemap Package",
    "text": "5.4 Designing Treemap with treemap Package\n\n5.4.1 Designing a static treemap\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n5.4.2 Using the basic arguments\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n5.4.3 Working with vColor and type arguments\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n5.4.4 Colours in treemap package\n\n\n5.4.5 The “value” type treemap\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n5.4.6 The “manual” type treemap\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n5.4.7 Treemap Layout\n\n\n5.4.8 Working with algorithm argument\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n5.4.9 Using sortID\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on Exercise 05: Visualising Distribution",
    "section": "5.5 Designing Treemap using treemapify Package",
    "text": "5.5 Designing Treemap using treemapify Package\n\n5.5.1 Designing a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n5.5.2 Defining hierarchy\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "In_class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In_class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class_Ex07: Visualising, Analysing and Forecasting Time-series Data: tidyverts methods",
    "section": "",
    "text": "pacman::p_load(tidyverse, tsibble, feasts, fable, seasonal)\n\n\n\n\nts_data &lt;- read_csv(\n  \"visitor_arrivals_by_air.csv\")\n\n\nts_data$`Month-Year` &lt;- dmy(\n  ts_data$`Month-Year`)\n\n\nts_data\n\n# A tibble: 144 × 34\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …\n\n\n\n\n\n\nts_data_ts &lt;- ts(ts_data)       \nhead(ts_data_ts)\n\n     Month-Year Republic of South Africa Canada   USA Bangladesh Brunei China\n[1,]      13879                     3680   6972 31155       6786   3729 79599\n[2,]      13910                     1662   6056 27738       6314   3070 82074\n[3,]      13939                     3394   6220 31349       7502   4805 72546\n[4,]      13970                     3337   4764 26376       7333   3096 76112\n[5,]      14000                     2089   4460 26788       7988   3586 64808\n[6,]      14031                     2515   3888 29725       8301   5284 55238\n     Hong Kong SAR (China) India Indonesia Japan South Korea Kuwait Malaysia\n[1,]                 17103 41639     62683 37673       27937    284    31352\n[2,]                 21089 37170     47834 35297       22633    241    35030\n[3,]                 23230 44815     64688 42575       22876    206    37629\n[4,]                 17688 49527     58074 26839       20634    193    37521\n[5,]                 19340 67754     57089 30814       22785    140    38044\n[6,]                 19152 57380     70118 31001       22575    354    40419\n     Myanmar Pakistan Philippines Saudi Arabia Sri Lanka Taiwan Thailand\n[1,]    5269     1395       18622          406      5289  13757    18370\n[2,]    4643     1027       21609          591      4767  13921    16400\n[3,]    6218     1635       28464          626      4988  11181    23387\n[4,]    7324     1232       30131          644      7639  11665    24469\n[5,]    5395     1306       30193          470      5125  11436    21935\n[6,]    5542     1996       25800          772      4791  10689    19900\n     United Arab Emirates Vietnam Belgium & Luxembourg Finland France Germany\n[1,]                 2652   10315                 1341    1179   6918   11982\n[2,]                 2230   13415                 1449    1207   7876   13256\n[3,]                 3353   14320                 1674    1071   8066   15185\n[4,]                 3245   15413                 1426     768   8312   11604\n[5,]                 2856   14424                 1243     690   7066    9853\n[6,]                 4292   21368                 1255     624   5926    9347\n     Italy Netherlands Spain Switzerland United Kingdom Australia New Zealand\n[1,]  2953        4938  1668        4450          41934     71260        7806\n[2,]  2704        4885  1568        4381          44029     45595        4729\n[3,]  2822        5015  2254        5015          49489     53191        6106\n[4,]  3018        4902  1503        5434          35771     56514        7560\n[5,]  2165        4397  1365        4427          24464     57808        9090\n[6,]  2022        4166  1446        3359          22473     63350        9681\n\n\n\n\n\n\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)"
  },
  {
    "objectID": "In_class_Ex/In-class_Ex07/In-class_Ex07.html#getting-started",
    "href": "In_class_Ex/In-class_Ex07/In-class_Ex07.html#getting-started",
    "title": "In-class_Ex07: Visualising, Analysing and Forecasting Time-series Data: tidyverts methods",
    "section": "",
    "text": "pacman::p_load(tidyverse, tsibble, feasts, fable, seasonal)\n\n\n\n\nts_data &lt;- read_csv(\n  \"visitor_arrivals_by_air.csv\")\n\n\nts_data$`Month-Year` &lt;- dmy(\n  ts_data$`Month-Year`)\n\n\nts_data\n\n# A tibble: 144 × 34\n   `Month-Year` `Republic of South Africa` Canada   USA Bangladesh Brunei China\n   &lt;date&gt;                            &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2008-01-01                         3680   6972 31155       6786   3729 79599\n 2 2008-02-01                         1662   6056 27738       6314   3070 82074\n 3 2008-03-01                         3394   6220 31349       7502   4805 72546\n 4 2008-04-01                         3337   4764 26376       7333   3096 76112\n 5 2008-05-01                         2089   4460 26788       7988   3586 64808\n 6 2008-06-01                         2515   3888 29725       8301   5284 55238\n 7 2008-07-01                         2919   5313 33183       9004   4070 80747\n 8 2008-08-01                         2471   4519 27427       7913   4183 66625\n 9 2008-09-01                         2492   3421 21588       7549   3160 52649\n10 2008-10-01                         3023   4756 25112       7527   2983 54423\n# ℹ 134 more rows\n# ℹ 27 more variables: `Hong Kong SAR (China)` &lt;dbl&gt;, India &lt;dbl&gt;,\n#   Indonesia &lt;dbl&gt;, Japan &lt;dbl&gt;, `South Korea` &lt;dbl&gt;, Kuwait &lt;dbl&gt;,\n#   Malaysia &lt;dbl&gt;, Myanmar &lt;dbl&gt;, Pakistan &lt;dbl&gt;, Philippines &lt;dbl&gt;,\n#   `Saudi Arabia` &lt;dbl&gt;, `Sri Lanka` &lt;dbl&gt;, Taiwan &lt;dbl&gt;, Thailand &lt;dbl&gt;,\n#   `United Arab Emirates` &lt;dbl&gt;, Vietnam &lt;dbl&gt;, `Belgium & Luxembourg` &lt;dbl&gt;,\n#   Finland &lt;dbl&gt;, France &lt;dbl&gt;, Germany &lt;dbl&gt;, Italy &lt;dbl&gt;, …\n\n\n\n\n\n\nts_data_ts &lt;- ts(ts_data)       \nhead(ts_data_ts)\n\n     Month-Year Republic of South Africa Canada   USA Bangladesh Brunei China\n[1,]      13879                     3680   6972 31155       6786   3729 79599\n[2,]      13910                     1662   6056 27738       6314   3070 82074\n[3,]      13939                     3394   6220 31349       7502   4805 72546\n[4,]      13970                     3337   4764 26376       7333   3096 76112\n[5,]      14000                     2089   4460 26788       7988   3586 64808\n[6,]      14031                     2515   3888 29725       8301   5284 55238\n     Hong Kong SAR (China) India Indonesia Japan South Korea Kuwait Malaysia\n[1,]                 17103 41639     62683 37673       27937    284    31352\n[2,]                 21089 37170     47834 35297       22633    241    35030\n[3,]                 23230 44815     64688 42575       22876    206    37629\n[4,]                 17688 49527     58074 26839       20634    193    37521\n[5,]                 19340 67754     57089 30814       22785    140    38044\n[6,]                 19152 57380     70118 31001       22575    354    40419\n     Myanmar Pakistan Philippines Saudi Arabia Sri Lanka Taiwan Thailand\n[1,]    5269     1395       18622          406      5289  13757    18370\n[2,]    4643     1027       21609          591      4767  13921    16400\n[3,]    6218     1635       28464          626      4988  11181    23387\n[4,]    7324     1232       30131          644      7639  11665    24469\n[5,]    5395     1306       30193          470      5125  11436    21935\n[6,]    5542     1996       25800          772      4791  10689    19900\n     United Arab Emirates Vietnam Belgium & Luxembourg Finland France Germany\n[1,]                 2652   10315                 1341    1179   6918   11982\n[2,]                 2230   13415                 1449    1207   7876   13256\n[3,]                 3353   14320                 1674    1071   8066   15185\n[4,]                 3245   15413                 1426     768   8312   11604\n[5,]                 2856   14424                 1243     690   7066    9853\n[6,]                 4292   21368                 1255     624   5926    9347\n     Italy Netherlands Spain Switzerland United Kingdom Australia New Zealand\n[1,]  2953        4938  1668        4450          41934     71260        7806\n[2,]  2704        4885  1568        4381          44029     45595        4729\n[3,]  2822        5015  2254        5015          49489     53191        6106\n[4,]  3018        4902  1503        5434          35771     56514        7560\n[5,]  2165        4397  1365        4427          24464     57808        9090\n[6,]  2022        4166  1446        3359          22473     63350        9681\n\n\n\n\n\n\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)"
  },
  {
    "objectID": "In_class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-time-series-data",
    "href": "In_class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-time-series-data",
    "title": "In-class_Ex07: Visualising, Analysing and Forecasting Time-series Data: tidyverts methods",
    "section": "7.3 Visualising Time-series Data",
    "text": "7.3 Visualising Time-series Data\n\nts_longer &lt;- ts_data %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\n7.3.1 Visualising single time-series: ggplot2 methods\n\nts_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  ggplot(aes(x = `Month-Year`, \n             y = Arrivals))+\n  geom_line(size = 0.5)\n\n\n\n\n\n\n\n\n\nts_longer %&gt;%\n  filter(Country == \"Malaysia\") %&gt;%\n  ggplot(aes(x = `Month-Year`, \n             y = Arrivals))+\n  geom_line(size = 0.5)\n\n\n\n\n\n\n\n\n\nts_longer %&gt;%\n  filter(Country == \"Myanmar\") %&gt;%\n  ggplot(aes(x = `Month-Year`, \n             y = Arrivals))+\n  geom_line(size = 0.5)\n\n\n\n\n\n\n\n\n\n\n9.3.2 Plotting multiple time-series data with ggplot2 methods\nvery hard to see\n\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals,\n           color = Country))+\n  geom_line(size = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\"))\n\n\n\n\n\n\n\n\nIn order to provide effective comparison, facet_wrap() of ggplot2 package is used to create small multiple line graph also known as trellis plot.\n\n\n\n\n\n\n\n\n\n\n\n7.4.2 Visual Analysis of Seasonality with Cycle Plot\nIn the code chunk below, cycle plots using gg_subseries() of feasts package are created. Notice that the cycle plots show not only seasonal patterns but also trend.\n\ntsibble_longer &lt;- ts_tsibble %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  gg_subseries(Arrivals)"
  },
  {
    "objectID": "In_class_Ex/In-class_Ex07/In-class_Ex07.html#time-series-decomposition",
    "href": "In_class_Ex/In-class_Ex07/In-class_Ex07.html#time-series-decomposition",
    "title": "In-class_Ex07: Visualising, Analysing and Forecasting Time-series Data: tidyverts methods",
    "section": "7.5 Time series decomposition",
    "text": "7.5 Time series decomposition\nTime series decomposition allows us to isolate structural components such as trend and seasonality from the time-series data.\n\n\n7.5.1 Single time series decomposition\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n7.5.2 Multiple time-series decomposition\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  ACF(Arrivals) %&gt;%\n  autoplot()"
  },
  {
    "objectID": "In_class_Ex/In-class_Ex07/In-class_Ex07.html#visual-forecasting",
    "href": "In_class_Ex/In-class_Ex07/In-class_Ex07.html#visual-forecasting",
    "title": "In-class_Ex07: Visualising, Analysing and Forecasting Time-series Data: tidyverts methods",
    "section": "7.7 Visual Forecasting",
    "text": "7.7 Visual Forecasting\n\n7.7.1 Time Series Data Sampling\nFirst, an extra column called Type indicating training or hold-out will be created by using mutate() of dplyr package. It will be extremely useful for subsequent data visualisation.\n\nvietnam_ts &lt;- tsibble_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;% \n  mutate(Type = if_else(\n    `Month-Year` &gt;= \"2019-01-01\", \n    \"Hold-out\", \"Training\"))\n\n\nvietnam_train &lt;- vietnam_ts %&gt;%\n  filter(`Month-Year` &lt; \"2019-01-01\")\n\n\n\n7.7.2 Exploratory Data Analysis (EDA): Time Series Data\n\nvietnam_train %&gt;%\n  model(stl = STL(Arrivals)) %&gt;%\n  components() %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n7.7.8 Step 5: Forecasting future values\n\nfit_ETS &lt;- vietnam_train %&gt;%\n  model(`SES` = ETS(Arrivals ~ error(\"A\") + \n                      trend(\"N\") + \n                      season(\"N\")),\n        `Holt`= ETS(Arrivals ~ error(\"A\") +\n                      trend(\"A\") +\n                      season(\"N\")),\n        `damped Holt` = \n          ETS(Arrivals ~ error(\"A\") +\n                trend(\"Ad\") + \n                season(\"N\")),\n        `WH_A` = ETS(\n          Arrivals ~ error(\"A\") + \n            trend(\"A\") + \n            season(\"A\")),\n        `WH_M` = ETS(Arrivals ~ error(\"M\") \n                         + trend(\"A\") \n                         + season(\"M\"))\n  )\n\n\nfit_ETS %&gt;%\n  tidy()\n\n# A tibble: 45 × 4\n   Country .model      term      estimate\n   &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;        &lt;dbl&gt;\n 1 Vietnam SES         alpha     1.00    \n 2 Vietnam SES         l[0]  10313.      \n 3 Vietnam Holt        alpha     1.00    \n 4 Vietnam Holt        beta      0.000100\n 5 Vietnam Holt        l[0]  13673.      \n 6 Vietnam Holt        b[0]    526.      \n 7 Vietnam damped Holt alpha     1.00    \n 8 Vietnam damped Holt beta      0.000110\n 9 Vietnam damped Holt phi       0.978   \n10 Vietnam damped Holt l[0]  13257.      \n# ℹ 35 more rows\n\n\n\nfit_ETS %&gt;%\n  report()\n\n# A tibble: 5 × 10\n  Country .model       sigma2 log_lik   AIC  AICc   BIC       MSE   AMSE     MAE\n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 Vietnam SES         2.79e+7  -1453. 2912. 2912. 2920. 27515844. 5.99e7 3.91e+3\n2 Vietnam Holt        2.86e+7  -1453. 2917. 2917. 2931. 27718599. 6.03e7 3.92e+3\n3 Vietnam damped Holt 2.86e+7  -1453. 2918. 2919. 2935. 27556629. 5.97e7 3.92e+3\n4 Vietnam WH_A        5.33e+6  -1336. 2706. 2711. 2755.  4684271. 8.56e6 1.72e+3\n5 Vietnam WH_M        4.55e-3  -1300. 2635. 2640. 2684.  3046059. 3.42e6 5.20e-2\n\n\n\nfit_ETS %&gt;%\n  forecast(h = \"12 months\") %&gt;%\n  autoplot(vietnam_ts, \n           level = NULL)\n\n\n\n\n\n\n\n\n\n\n7.7.9 Fitting ETS Automatically\n\nfit_autoETS &lt;- vietnam_train %&gt;%\n  model(ETS(Arrivals))\nfit_autoETS %&gt;% report()\n\nSeries: Arrivals \nModel: ETS(M,A,M) \n  Smoothing parameters:\n    alpha = 0.1613503 \n    beta  = 0.0001021811 \n    gamma = 0.0001030996 \n\n  Initial states:\n     l[0]     b[0]      s[0]     s[-1]     s[-2]     s[-3]    s[-4]    s[-5]\n 15001.12 212.3552 0.9167302 0.8311728 0.8739287 0.8690543 1.104668 1.485584\n    s[-6]     s[-7]    s[-8]     s[-9]    s[-10]    s[-11]\n 1.311207 0.9917759 1.014187 0.8973028 0.8816768 0.8227129\n\n  sigma^2:  0.0046\n\n     AIC     AICc      BIC \n2634.751 2640.119 2683.759 \n\n\n\n\n7.7.10 Fitting Fitting ETS Automatically\n\ngg_tsresiduals(fit_autoETS)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html",
    "title": "Take_Home Exercise 2",
    "section": "",
    "text": "Since Mr. Donald Trump took office as the President of the United States on January 20, 2025, one of the most closely watched topics has been global trade. As a visual analytics novice,I am eager to apply newly acquired techniques to explore and analyze the changing trends and patterns of Singapore’s international trade since 2015.\n\n\n\nIn Take-home Exercise 2, the focus is on redesigning and enhancing an existing data visualization created by a peer, with a particular emphasis on Singapore’s merchandise trade by region/market from the Department of Statistics Singapore (DOS). The task involves analyzing and critiquing the original visualization based on clarity and aesthetics, identifying areas for improvement.\nUsing data visualization design principles, we will consider both clarity and aesthetic aspects. The goal is to transform the original visualization into a more effective, engaging, and insightful representation of the data, enhancing clarity, insightfulness, and user engagement.\nAll the visualizations for this exercise will be sourced from SingStat’s Merchandise Trade data.\n\n\n\n\n\n\n\ntidyverse: (i.e. readr, tidyr, dplyr, ggplot2) for performing data science tasks such as importing, tidying, and wrangling data, as well as creating graphics based on The Grammar of Graphics,\nreshape2 for transforming data between wide and long formats\nggthemes: provides some extra themes, geoms, and scales for ‘ggplot2’.\nggdist: a ggplot2 extension specially designed for visualising distribution and uncertainty\npatchwork: an R package for preparing composite figure created using ggplot2.\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots.\nggrepel: an R package which provides geoms for ggplot2 to repel overlapping text labels.\ntsibble: for building static html table to aid us in having a better view of tables\nlubridate: R package that makes it easier to work with dates and times.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nThe following code chunk utilizes the p_load() function from the pacman package to verify whether the specified packages are already installed on the system. If the packages are detected, they will be loaded into the R environment. Otherwise, the function will automatically install them before proceeding with the loading process.\n\npacman::p_load(readxl,tidyverse, reshape2, ggthemes,\n               ggdist, patchwork, ggridges,\n               ggrepel, knitr, scales, lubridate,\n               patchwork,ggplot2,plotly,dplyr,tsibble)\n\n\n\n\n\n\n\nThe dataset used in the exercise is in Excel format, retrieved from the Department of Statistics Singapore website.\nThe code chunk below import the dataset using read_excel() function of the haven package.\n\nlibrary(readxl) \nTrade1 &lt;- read_excel(\"data/OutputFile.xlsx\", sheet = 'T1')\n\n\nTrade1 &lt;- read_excel(\"data/OutputFile.xlsx\", sheet='T1',col_types=\"text\")\nRegion1 &lt;- read_excel(\"data/Region.xlsx\", sheet = 'T1')\nRegion2 &lt;- read_excel(\"data/Region.xlsx\", sheet = 'T2')\nRegion3 &lt;- read_excel(\"data/Region.xlsx\", sheet = 'T3')\nNonOil &lt;- read_excel(\"data/OutputFile.xlsx\", sheet='T1',col_types=\"text\")\n\n\n\n\n\n\n\n\nThe “Total Merchandise Trade at Current Prices” visualization on Singapore’s Department of Statistics website provides a snapshot of the country’s trade performance. Here’s an analysis of its strengths and areas for improvement:​\nPros:\n\nClear Representation of Trade Values: The visualization effectively displays total trade figures, offering a straightforward understanding of Singapore’s merchandise trade volume.​\nUse of Current Prices: Presenting data at current prices reflects the actual trade values during the reported period, incorporating the effects of inflation and providing a realistic economic picture.​\n\nCons:\n\nLack of Historical Context:The visualization focuses on a single time point without showing trends over time, making it challenging to assess growth patterns or identify cyclical behaviors.​\nHeavily Text Based: The visualization is heavily text-based, making it hard to grasp trends at a glance.\n\n\n\n\nhead(Trade1)\n\n# A tibble: 6 × 734\n  `Data Series`           `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                   &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     \n1 Total Merchandise Trad… 114153979… 116278793… 110132324… 107525959… 103512459…\n2 Oil                     19490289.… 18488973.… 18061885.… 17510049.… 15686653.5\n3 Petroleum               16418934.4 15564654.… 14910685.5 14804333.5 12611958.1\n4 Oil Bunkers             3071355.5  2924319.4  3151199.6  2705716.2  3074695.3 \n5 Non-Oil                 94663689.… 97789819.… 92070439.… 90015910.… 87825806.…\n6 Food & Live Animals     2460910.6  2704578.8  2237326.1  2344744.7… 2235004.6 \n# ℹ 728 more variables: `2024 Aug` &lt;chr&gt;, `2024 Jul` &lt;chr&gt;, `2024 Jun` &lt;chr&gt;,\n#   `2024 May` &lt;chr&gt;, `2024 Apr` &lt;chr&gt;, `2024 Mar` &lt;chr&gt;, `2024 Feb` &lt;chr&gt;,\n#   `2024 Jan` &lt;chr&gt;, `2023 Dec` &lt;chr&gt;, `2023 Nov` &lt;chr&gt;, `2023 Oct` &lt;chr&gt;,\n#   `2023 Sep` &lt;chr&gt;, `2023 Aug` &lt;chr&gt;, `2023 Jul` &lt;chr&gt;, `2023 Jun` &lt;chr&gt;,\n#   `2023 May` &lt;chr&gt;, `2023 Apr` &lt;chr&gt;, `2023 Mar` &lt;chr&gt;, `2023 Feb` &lt;chr&gt;,\n#   `2023 Jan` &lt;chr&gt;, `2022 Dec` &lt;chr&gt;, `2022 Nov` &lt;chr&gt;, `2022 Oct` &lt;chr&gt;,\n#   `2022 Sep` &lt;chr&gt;, `2022 Aug` &lt;chr&gt;, `2022 Jul` &lt;chr&gt;, `2022 Jun` &lt;chr&gt;, …\n\n\nii. Checking Missing Values\n\ncolSums(is.na(Trade1))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan    2002 Dec    2002 Nov    2002 Oct    2002 Sep \n          0           0           0           0           0           0 \n   2002 Aug    2002 Jul    2002 Jun    2002 May    2002 Apr    2002 Mar \n          0           0           0           0           0           0 \n   2002 Feb    2002 Jan    2001 Dec    2001 Nov    2001 Oct    2001 Sep \n          0           0           0           0           0           0 \n   2001 Aug    2001 Jul    2001 Jun    2001 May    2001 Apr    2001 Mar \n          0           0           0           0           0           0 \n   2001 Feb    2001 Jan    2000 Dec    2000 Nov    2000 Oct    2000 Sep \n          0           0           0           0           0           0 \n   2000 Aug    2000 Jul    2000 Jun    2000 May    2000 Apr    2000 Mar \n          0           0           0           0           0           0 \n   2000 Feb    2000 Jan    1999 Dec    1999 Nov    1999 Oct    1999 Sep \n          0           0           0           0           0           0 \n   1999 Aug    1999 Jul    1999 Jun    1999 May    1999 Apr    1999 Mar \n          0           0           0           0           0           0 \n   1999 Feb    1999 Jan    1998 Dec    1998 Nov    1998 Oct    1998 Sep \n          0           0           0           0           0           0 \n   1998 Aug    1998 Jul    1998 Jun    1998 May    1998 Apr    1998 Mar \n          0           0           0           0           0           0 \n   1998 Feb    1998 Jan    1997 Dec    1997 Nov    1997 Oct    1997 Sep \n          0           0           0           0           0           0 \n   1997 Aug    1997 Jul    1997 Jun    1997 May    1997 Apr    1997 Mar \n          0           0           0           0           0           0 \n   1997 Feb    1997 Jan    1996 Dec    1996 Nov    1996 Oct    1996 Sep \n          0           0           0           0           0           0 \n   1996 Aug    1996 Jul    1996 Jun    1996 May    1996 Apr    1996 Mar \n          0           0           0           0           0           0 \n   1996 Feb    1996 Jan    1995 Dec    1995 Nov    1995 Oct    1995 Sep \n          0           0           0           0           0           0 \n   1995 Aug    1995 Jul    1995 Jun    1995 May    1995 Apr    1995 Mar \n          0           0           0           0           0           0 \n   1995 Feb    1995 Jan    1994 Dec    1994 Nov    1994 Oct    1994 Sep \n          0           0           0           0           0           0 \n   1994 Aug    1994 Jul    1994 Jun    1994 May    1994 Apr    1994 Mar \n          0           0           0           0           0           0 \n   1994 Feb    1994 Jan    1993 Dec    1993 Nov    1993 Oct    1993 Sep \n          0           0           0           0           0           0 \n   1993 Aug    1993 Jul    1993 Jun    1993 May    1993 Apr    1993 Mar \n          0           0           0           0           0           0 \n   1993 Feb    1993 Jan    1992 Dec    1992 Nov    1992 Oct    1992 Sep \n          0           0           0           0           0           0 \n   1992 Aug    1992 Jul    1992 Jun    1992 May    1992 Apr    1992 Mar \n          0           0           0           0           0           0 \n   1992 Feb    1992 Jan    1991 Dec    1991 Nov    1991 Oct    1991 Sep \n          0           0           0           0           0           0 \n   1991 Aug    1991 Jul    1991 Jun    1991 May    1991 Apr    1991 Mar \n          0           0           0           0           0           0 \n   1991 Feb    1991 Jan    1990 Dec    1990 Nov    1990 Oct    1990 Sep \n          0           0           0           0           0           0 \n   1990 Aug    1990 Jul    1990 Jun    1990 May    1990 Apr    1990 Mar \n          0           0           0           0           0           0 \n   1990 Feb    1990 Jan    1989 Dec    1989 Nov    1989 Oct    1989 Sep \n          0           0           0           0           0           0 \n   1989 Aug    1989 Jul    1989 Jun    1989 May    1989 Apr    1989 Mar \n          0           0           0           0           0           0 \n   1989 Feb    1989 Jan    1988 Dec    1988 Nov    1988 Oct    1988 Sep \n          0           0           0           0           0           0 \n   1988 Aug    1988 Jul    1988 Jun    1988 May    1988 Apr    1988 Mar \n          0           0           0           0           0           0 \n   1988 Feb    1988 Jan    1987 Dec    1987 Nov    1987 Oct    1987 Sep \n          0           0           0           0           0           0 \n   1987 Aug    1987 Jul    1987 Jun    1987 May    1987 Apr    1987 Mar \n          0           0           0           0           0           0 \n   1987 Feb    1987 Jan    1986 Dec    1986 Nov    1986 Oct    1986 Sep \n          0           0           0           0           0           0 \n   1986 Aug    1986 Jul    1986 Jun    1986 May    1986 Apr    1986 Mar \n          0           0           0           0           0           0 \n   1986 Feb    1986 Jan    1985 Dec    1985 Nov    1985 Oct    1985 Sep \n          0           0           0           0           0           0 \n   1985 Aug    1985 Jul    1985 Jun    1985 May    1985 Apr    1985 Mar \n          0           0           0           0           0           0 \n   1985 Feb    1985 Jan    1984 Dec    1984 Nov    1984 Oct    1984 Sep \n          0           0           0           0           0           0 \n   1984 Aug    1984 Jul    1984 Jun    1984 May    1984 Apr    1984 Mar \n          0           0           0           0           0           0 \n   1984 Feb    1984 Jan    1983 Dec    1983 Nov    1983 Oct    1983 Sep \n          0           0           0           0           0           0 \n   1983 Aug    1983 Jul    1983 Jun    1983 May    1983 Apr    1983 Mar \n          0           0           0           0           0           0 \n   1983 Feb    1983 Jan    1982 Dec    1982 Nov    1982 Oct    1982 Sep \n          0           0           0           0           0           0 \n   1982 Aug    1982 Jul    1982 Jun    1982 May    1982 Apr    1982 Mar \n          0           0           0           0           0           0 \n   1982 Feb    1982 Jan    1981 Dec    1981 Nov    1981 Oct    1981 Sep \n          0           0           0           0           0           0 \n   1981 Aug    1981 Jul    1981 Jun    1981 May    1981 Apr    1981 Mar \n          0           0           0           0           0           0 \n   1981 Feb    1981 Jan    1980 Dec    1980 Nov    1980 Oct    1980 Sep \n          0           0           0           0           0           0 \n   1980 Aug    1980 Jul    1980 Jun    1980 May    1980 Apr    1980 Mar \n          0           0           0           0           0           0 \n   1980 Feb    1980 Jan    1979 Dec    1979 Nov    1979 Oct    1979 Sep \n          0           0           0           0           0           0 \n   1979 Aug    1979 Jul    1979 Jun    1979 May    1979 Apr    1979 Mar \n          0           0           0           0           0           0 \n   1979 Feb    1979 Jan    1978 Dec    1978 Nov    1978 Oct    1978 Sep \n          0           0           0           0           0           0 \n   1978 Aug    1978 Jul    1978 Jun    1978 May    1978 Apr    1978 Mar \n          0           0           0           0           0           0 \n   1978 Feb    1978 Jan    1977 Dec    1977 Nov    1977 Oct    1977 Sep \n          0           0           0           0           0           0 \n   1977 Aug    1977 Jul    1977 Jun    1977 May    1977 Apr    1977 Mar \n          0           0           0           0           0           0 \n   1977 Feb    1977 Jan    1976 Dec    1976 Nov    1976 Oct    1976 Sep \n          0           0           0           0           0           0 \n   1976 Aug    1976 Jul    1976 Jun    1976 May    1976 Apr    1976 Mar \n          0           0           0           0           0           0 \n   1976 Feb    1976 Jan    1975 Dec    1975 Nov    1975 Oct    1975 Sep \n          0           0           0           0           0           0 \n   1975 Aug    1975 Jul    1975 Jun    1975 May    1975 Apr    1975 Mar \n          0           0           0           0           0           0 \n   1975 Feb    1975 Jan    1974 Dec    1974 Nov    1974 Oct    1974 Sep \n          0           0           0           0           0           0 \n   1974 Aug    1974 Jul    1974 Jun    1974 May    1974 Apr    1974 Mar \n          0           0           0           0           0           0 \n   1974 Feb    1974 Jan    1973 Dec    1973 Nov    1973 Oct    1973 Sep \n          0           0           0           0           0           0 \n   1973 Aug    1973 Jul    1973 Jun    1973 May    1973 Apr    1973 Mar \n          0           0           0           0           0           0 \n   1973 Feb    1973 Jan    1972 Dec    1972 Nov    1972 Oct    1972 Sep \n          0           0           0           0           0           0 \n   1972 Aug    1972 Jul    1972 Jun    1972 May    1972 Apr    1972 Mar \n          0           0           0           0           0           0 \n   1972 Feb    1972 Jan    1971 Dec    1971 Nov    1971 Oct    1971 Sep \n          0           0           0           0           0           0 \n   1971 Aug    1971 Jul    1971 Jun    1971 May    1971 Apr    1971 Mar \n          0           0           0           0           0           0 \n   1971 Feb    1971 Jan    1970 Dec    1970 Nov    1970 Oct    1970 Sep \n          0           0           0           0           0           0 \n   1970 Aug    1970 Jul    1970 Jun    1970 May    1970 Apr    1970 Mar \n          0           0           0           0           0           0 \n   1970 Feb    1970 Jan    1969 Dec    1969 Nov    1969 Oct    1969 Sep \n          0           0           0           0           0           0 \n   1969 Aug    1969 Jul    1969 Jun    1969 May    1969 Apr    1969 Mar \n          0           0           0           0           0           0 \n   1969 Feb    1969 Jan    1968 Dec    1968 Nov    1968 Oct    1968 Sep \n          0           0           0           0           0           0 \n   1968 Aug    1968 Jul    1968 Jun    1968 May    1968 Apr    1968 Mar \n          0           0           0           0           0           0 \n   1968 Feb    1968 Jan    1967 Dec    1967 Nov    1967 Oct    1967 Sep \n          0           0           0           0           0           0 \n   1967 Aug    1967 Jul    1967 Jun    1967 May    1967 Apr    1967 Mar \n          0           0           0           0           0           0 \n   1967 Feb    1967 Jan    1966 Dec    1966 Nov    1966 Oct    1966 Sep \n          0           0           0           0           0           0 \n   1966 Aug    1966 Jul    1966 Jun    1966 May    1966 Apr    1966 Mar \n          0           0           0           0           0           0 \n   1966 Feb    1966 Jan    1965 Dec    1965 Nov    1965 Oct    1965 Sep \n          0           0           0           0           0           0 \n   1965 Aug    1965 Jul    1965 Jun    1965 May    1965 Apr    1965 Mar \n          0           0           0           0           0           0 \n   1965 Feb    1965 Jan    1964 Dec    1964 Nov    1964 Oct    1964 Sep \n          0           0           0           0           0           0 \n   1964 Aug    1964 Jul    1964 Jun    1964 May    1964 Apr    1964 Mar \n          0           0           0           0           0           0 \n   1964 Feb    1964 Jan \n          0           0 \n\n\n\n\n\n\ncolnames(Trade1) &lt;- as.character(colnames(Trade1))\n\nCommodityCurrent &lt;- Trade1 %&gt;%\n  pivot_longer(cols = -`Data Series`, names_to = \"Year_Month\", values_to = \"Trade_Value\") %&gt;%\n  mutate(Trade_Value = suppressWarnings(as.numeric(Trade_Value))) \n\n\nhead(CommodityCurrent)\n\n# A tibble: 6 × 3\n  `Data Series`                                Year_Month Trade_Value\n  &lt;chr&gt;                                        &lt;chr&gt;            &lt;dbl&gt;\n1 Total Merchandise Trade, (At Current Prices) 2025 Jan    114153980.\n2 Total Merchandise Trade, (At Current Prices) 2024 Dec    116278793.\n3 Total Merchandise Trade, (At Current Prices) 2024 Nov    110132324.\n4 Total Merchandise Trade, (At Current Prices) 2024 Oct    107525960.\n5 Total Merchandise Trade, (At Current Prices) 2024 Sep    103512460.\n6 Total Merchandise Trade, (At Current Prices) 2024 Aug    105709528.\n\n\niv. Filtering the year 2020-2024\n\nCommodity_C_Total &lt;- CommodityCurrent %&gt;%\n  filter(`Data Series` %in% c(\"Total Merchandise Imports, (At Current Prices)\", \"Total Merchandise Exports, (At Current Prices)\", \"Total Merchandise Trade, (At Current Prices)\"))\n\n\nCommodity_C_Total &lt;- Commodity_C_Total %&gt;%\n  mutate(Year = year(parse_date_time(Year_Month, orders = \"ym\"))) %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%\n  group_by(Year, `Data Series`) %&gt;%\n  summarise(Total_Trade_Value = sum(Trade_Value, na.rm = TRUE), .groups = \"drop\")  \n\n\nhead(Commodity_C_Total)\n\n# A tibble: 6 × 3\n   Year `Data Series`                                  Total_Trade_Value\n  &lt;dbl&gt; &lt;chr&gt;                                                      &lt;dbl&gt;\n1  2020 Total Merchandise Exports, (At Current Prices)        515644539 \n2  2020 Total Merchandise Imports, (At Current Prices)        453467444.\n3  2020 Total Merchandise Trade, (At Current Prices)          969111983.\n4  2021 Total Merchandise Exports, (At Current Prices)        614081094.\n5  2021 Total Merchandise Imports, (At Current Prices)        545881937.\n6  2021 Total Merchandise Trade, (At Current Prices)         1159963031.\n\n\n\n\n\n\nlibrary(ggplot2) \nlibrary(plotly)\nlibrary(scales)\n\np &lt;- ggplot(Commodity_C_Total, aes(x = Year, y = Total_Trade_Value / 1e6, color = `Data Series`, group = `Data Series`, text = paste(\"Year:\", Year, \"&lt;br&gt;\", \"Trade Type:\", `Data Series`, \"&lt;br&gt;\", \"Trade Value: S$\", scales::comma(Total_Trade_Value / 1e6), \"B\"))) + \n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  theme_minimal() +\n  labs(title = \"Yearly Trend of Merchandise Trade (2020-2024)\",\n       x = \"Year\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Trade Type\") +\n  scale_x_continuous(breaks = seq(2020, 2024, 1)) +\n  scale_y_continuous(labels = label_number(scale = 1))  \n\nggplotly(p, tooltip = \"text\") \n\n\n\n\n\n\n\n\n\n\nPros:\n\nEfficient Space Utilization: The compact nature of a bubble chart allows multiple data points to be displayed in a small area without requiring an extensive table.\nQuickly Highlights Key Trade Partners: The bubble chart makes it easy to identify which countries have the largest trade volumes with Singapore at a glance. Larger bubbles automatically draw attention to major trading partners, emphasizing total trade activity.\nIntuitive Representation of Trade Imbalance: The position of bubbles in different regions visually distinguishes between partners with a trade surplus (more exports) and those with a trade deficit (more imports).\n\nCons:\n\nOvercrowding with Multiple Data Points: If there are too many trading partners displayed, the bubbles can overlap excessively, making it difficult to differentiate individual partners.\nPotential for Misleading Perceptions: If not scaled correctly, the difference between bubble sizes may exaggerate or understate actual trade disparities.\nNot Suitable for Precise Numerical Analysis: Unlike bar charts or tables, bubble charts do not provide precise export/import values, which may be necessary for detailed analysis.\n\ni. Data(Preparation)\n\nhead(Region1)\n\n# A tibble: 6 × 266\n  `Data Series`       `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Total All Markets       54746.    56136.      51802.    51416.     49068. \n2 America                  6923.     7874.       7880.     8078.      9112  \n3 Antigua And Barbuda         0         0           0         0          0  \n4 Argentina                   4        12.5       116.        4.1        8.1\n5 Bahamas                     0         8.1         0         0          0  \n6 Bermuda                     0         0           0         0          0  \n# ℹ 260 more variables: `2024 Aug` &lt;dbl&gt;, `2024 Jul` &lt;dbl&gt;, `2024 Jun` &lt;dbl&gt;,\n#   `2024 May` &lt;dbl&gt;, `2024 Apr` &lt;dbl&gt;, `2024 Mar` &lt;dbl&gt;, `2024 Feb` &lt;dbl&gt;,\n#   `2024 Jan` &lt;dbl&gt;, `2023 Dec` &lt;dbl&gt;, `2023 Nov` &lt;dbl&gt;, `2023 Oct` &lt;dbl&gt;,\n#   `2023 Sep` &lt;dbl&gt;, `2023 Aug` &lt;dbl&gt;, `2023 Jul` &lt;dbl&gt;, `2023 Jun` &lt;dbl&gt;,\n#   `2023 May` &lt;dbl&gt;, `2023 Apr` &lt;dbl&gt;, `2023 Mar` &lt;dbl&gt;, `2023 Feb` &lt;dbl&gt;,\n#   `2023 Jan` &lt;dbl&gt;, `2022 Dec` &lt;dbl&gt;, `2022 Nov` &lt;dbl&gt;, `2022 Oct` &lt;dbl&gt;,\n#   `2022 Sep` &lt;dbl&gt;, `2022 Aug` &lt;dbl&gt;, `2022 Jul` &lt;dbl&gt;, `2022 Jun` &lt;dbl&gt;, …\n\n\n\nhead(Region2)\n\n# A tibble: 6 × 266\n  `Data Series`       `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Total All Markets      24672      23685.     23439.     22148.     21967. \n2 America                 4263.      3608.      3129.      2936.      3294. \n3 Antigua And Barbuda        8.8        7.1        8.3        7.7        8.2\n4 Argentina                  5.3        6          3.9        6.4        3  \n5 Bahamas                   51.4       48.1       60.5       36.1       59.3\n6 Bermuda                    2.7        7.7        0.5        5.4        0.7\n# ℹ 260 more variables: `2024 Aug` &lt;dbl&gt;, `2024 Jul` &lt;dbl&gt;, `2024 Jun` &lt;dbl&gt;,\n#   `2024 May` &lt;dbl&gt;, `2024 Apr` &lt;dbl&gt;, `2024 Mar` &lt;dbl&gt;, `2024 Feb` &lt;dbl&gt;,\n#   `2024 Jan` &lt;dbl&gt;, `2023 Dec` &lt;dbl&gt;, `2023 Nov` &lt;dbl&gt;, `2023 Oct` &lt;dbl&gt;,\n#   `2023 Sep` &lt;dbl&gt;, `2023 Aug` &lt;dbl&gt;, `2023 Jul` &lt;dbl&gt;, `2023 Jun` &lt;dbl&gt;,\n#   `2023 May` &lt;dbl&gt;, `2023 Apr` &lt;dbl&gt;, `2023 Mar` &lt;dbl&gt;, `2023 Feb` &lt;dbl&gt;,\n#   `2023 Jan` &lt;dbl&gt;, `2022 Dec` &lt;dbl&gt;, `2022 Nov` &lt;dbl&gt;, `2022 Oct` &lt;dbl&gt;,\n#   `2022 Sep` &lt;dbl&gt;, `2022 Aug` &lt;dbl&gt;, `2022 Jul` &lt;dbl&gt;, `2022 Jun` &lt;dbl&gt;, …\n\n\n\nhead(Region3)\n\n# A tibble: 6 × 266\n  `Data Series`       `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Total All Markets      34736.     36458.     34892.     33963.     32477. \n2 America                 3110.      3893.      3528.      3389.      3197. \n3 Antigua And Barbuda        1.9        0.1        0          0.2        0  \n4 Argentina                 25.7       22.3       19.4       23.8       27.1\n5 Bahamas                    9.8        1.3        3.7        4.3        8.1\n6 Bermuda                    0.1        0          0          0.1        0  \n# ℹ 260 more variables: `2024 Aug` &lt;dbl&gt;, `2024 Jul` &lt;dbl&gt;, `2024 Jun` &lt;dbl&gt;,\n#   `2024 May` &lt;dbl&gt;, `2024 Apr` &lt;dbl&gt;, `2024 Mar` &lt;dbl&gt;, `2024 Feb` &lt;dbl&gt;,\n#   `2024 Jan` &lt;dbl&gt;, `2023 Dec` &lt;dbl&gt;, `2023 Nov` &lt;dbl&gt;, `2023 Oct` &lt;dbl&gt;,\n#   `2023 Sep` &lt;dbl&gt;, `2023 Aug` &lt;dbl&gt;, `2023 Jul` &lt;dbl&gt;, `2023 Jun` &lt;dbl&gt;,\n#   `2023 May` &lt;dbl&gt;, `2023 Apr` &lt;dbl&gt;, `2023 Mar` &lt;dbl&gt;, `2023 Feb` &lt;dbl&gt;,\n#   `2023 Jan` &lt;dbl&gt;, `2022 Dec` &lt;dbl&gt;, `2022 Nov` &lt;dbl&gt;, `2022 Oct` &lt;dbl&gt;,\n#   `2022 Sep` &lt;dbl&gt;, `2022 Aug` &lt;dbl&gt;, `2022 Jul` &lt;dbl&gt;, `2022 Jun` &lt;dbl&gt;, …\n\n\nii. Checking Missing Values\n\ncolSums(is.na(Region1))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan \n          0           0 \n\n\n\ncolSums(is.na(Region2))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan \n          0           0 \n\n\n\ncolSums(is.na(Region3))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan \n          0           0 \n\n\niii. Filtering for 2024 and Selected Trading Partners\n\nTrading_Partners &lt;- c(\"China\", \"Malaysia\", \"United States\", \n                      \"Taiwan\", \"Europe\", \"Indonesia\", \"Hong Kong\", \n                      \"Korea, Rep Of\", \"Japan\", \"Thailand\")\n\n\nImports &lt;- Region1 %&gt;%\n  filter(`Data Series` %in% Trading_Partners) %&gt;%   \n  pivot_longer(cols = -`Data Series`,               \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  filter(grepl(\"^2024\", Date)) %&gt;%   \n  mutate(Trade_Type = \"Imports\") \n\n\nExports &lt;- bind_rows(Region2, Region3) %&gt;%  \n  filter(`Data Series` %in% Trading_Partners) %&gt;%\n  pivot_longer(cols = -`Data Series`, \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  filter(grepl(\"^2024\", Date)) %&gt;%   \n  mutate(Trade_Type = \"Exports\") \n\n# Combine Imports and Exports into a single dataset\nTrade_Data &lt;- bind_rows(Imports, Exports)\n\n\nhead(Trade_Data)\n\n# A tibble: 6 × 4\n  `Data Series` Date     Trade_Value Trade_Type\n  &lt;chr&gt;         &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;     \n1 United States 2024 Dec       6652. Imports   \n2 United States 2024 Nov       5989. Imports   \n3 United States 2024 Oct       6093. Imports   \n4 United States 2024 Sep       6449. Imports   \n5 United States 2024 Aug       7258. Imports   \n6 United States 2024 Jul       6190. Imports   \n\n\n\n# Summarize Total Trade by Country\nTrade_Summary &lt;- Trade_Data %&gt;%\n  group_by(`Data Series`, Trade_Type) %&gt;%\n  summarise(Total_Trade_Value = sum(Trade_Value, na.rm = TRUE)) %&gt;%\n  pivot_wider(names_from = Trade_Type, values_from = Total_Trade_Value) %&gt;%\n  mutate(Total_Trade = Exports + Imports,  \n         Trade_Balance = Exports - Imports)  # Surplus (+) or Deficit (-)\n\n\ncolnames(Trade_Summary) &lt;- c(\"Country\", \"Exports\", \"Imports\", \"Total_Trade\", \"Trade_Balance\")\n\n\nhead(Trade_Summary)\n\n# A tibble: 6 × 5\n# Groups:   Country [6]\n  Country       Exports Imports Total_Trade Trade_Balance\n  &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;\n1 China          94443.  75740.     170182.        18703.\n2 Europe         52417.  89635.     142052.       -37218.\n3 Hong Kong      73879.   4744.      78622.        69135 \n4 Indonesia      53216.  20938.      74155.        32278.\n5 Japan          23707.  29696.      53402.        -5989.\n6 Korea, Rep Of  28423.  38395.      66818.        -9973.\n\n\n\np &lt;- ggplot(Trade_Summary, aes(x = Imports, y = Exports, size = Total_Trade, fill = Trade_Balance)) +\n \n  geom_point(shape = 21, alpha = 0.7, color = \"black\") +  \n  geom_text(aes(label = Country), size = 3.5, fontface = \"bold\", color = \"black\") +\n\n  scale_x_continuous(labels = scales::comma_format(), limits = c(0, max(Trade_Summary$Imports) * 1.1)) +  \n  scale_y_continuous(labels = scales::comma_format()) +  \n\n  scale_size_continuous(range = c(6, 25), guide = \"legend\") +  \n  scale_fill_gradient2(low = \"red\", mid = \"white\", high = \"blue\", midpoint = 0, name = \"Trade Balance\") + \n  \n\n  labs(title = \"Merchandise Trade Performance with Major Trading Partners (2024)\",\n       subtitle = \"Bubble size represents total trade volume. Color indicates trade balance.\",\n       x = \"Imports (S$ Billion)\", y = \"Exports (S$ Billion)\",\n       size = \"Total Trade (S$ Billion)\") +\n  \n   theme_minimal() +\n  theme(legend.position = \"bottom\",\n        panel.grid.major = element_line(color = \"gray85\", linetype = \"dashed\"),\n        panel.grid.minor = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14, face = \"bold\"))\n\nggplotly(p, tooltip = c(\"Country\", \"Exports\", \"Imports\", \"Total_Trade\", \"Trade_Balance\"))\n\n\n\n\n\n\n\n\n\nPros:\n\nBreaks down trade data by commodity sections, providing insights into the composition of trade.​\nUses color coding to differentiate between exports and imports.​\n\nCons:\n\nThe side-by-side bar arrangement can make it challenging to compare the export and import values of each commodity directly.​\nThe legend placement might require viewers to move back and forth between the chart and the legend, hindering quick comprehension.​\nAfter exceeding 60 Billion, the bar represented by a segmented bar as can be seen on Machinery and Transport Equipment.\n\ni. Filtering out Non-Oil Merchandise Trade\n\ncolnames(NonOil) &lt;- as.character(colnames(NonOil))\n\ncommodity_mod &lt;- NonOil %&gt;%\n  pivot_longer(cols = -`Data Series`, names_to = \"Year_Month\", values_to = \"Trade_Value\") %&gt;%\n  mutate(Trade_Value = suppressWarnings(as.numeric(Trade_Value))) \n\n\ncategories &lt;- c(\n  \"Food & Live Animals [Imports]\", \"Beverages & Tobacco [Imports]\", \n  \"Crude Materials (Excl Fuels) [Imports]\", \"Animal & Vegetable Oils Fats & Waxes [Imports]\", \n  \"Chemicals & Chemical Products [Imports]\", \"Manufactured Goods [Imports]\", \n  \"Machinery & Transport Equipment [Imports]\", \"Miscellaneous Manufactured Articles [Imports]\", \n  \"Miscellaneous (Excluding Oil Bunkers) [Imports]\", \"Food & Live Animals [Exports]\", \n  \"Beverages & Tobacco [Exports]\", \"Crude Materials (Excl Fuels) [Exports]\", \n  \"Animal & Vegetable Oils Fats & Waxes [Exports]\", \"Chemicals & Chemical Products [Exports]\", \n  \"Manufactured Goods [Exports]\", \"Machinery & Transport Equipment [Exports]\", \n  \"Miscellaneous Manufactured Articles [Exports]\", \"Miscellaneous (Excluding Oil Bunkers) [Exports]\"\n)\n\ncommodity_category &lt;- commodity_mod %&gt;%\n  filter(`Data Series` %in% categories)\n\n\nlibrary(dplyr)\nlibrary(lubridate)\n\ncommodity_category &lt;- commodity_category %&gt;%\n  mutate(\n    Year_Month = as.character(Year_Month),  # Ensure it's a character\n    Year = year(parse_date_time(Year_Month, orders = \"Y b\"))  # \"Y b\" means \"2024 Jan\"\n  ) %&gt;%\n  filter(Year == 2024) %&gt;%\n  group_by(Year, `Data Series`) %&gt;%\n  summarise(Total_Trade_Value = sum(Trade_Value, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\nSeparating Trade type and Commodity\n\n\ncommodity_category &lt;- commodity_category %&gt;%\n  separate(`Data Series`, into = c(\"Commodity\", \"Trade_Type\"), sep = \" \\\\[\", remove = TRUE) %&gt;%\n  mutate(Trade_Type = gsub(\"\\\\]\", \"\", Trade_Type))\n\n\nkable(head(commodity_category))\n\n\n\n\nYear\nCommodity\nTrade_Type\nTotal_Trade_Value\n\n\n\n\n\n\n\nMakeover\n\n\n\n\n\nimports_v4 &lt;- Region1 %&gt;%\n  filter(`Data Series` %in% Trading_Partners) %&gt;%   \n  pivot_longer(cols = -`Data Series`,               \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  mutate(Date = ym(Date)) %&gt;%  \n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\ndomestic_ex_v4 &lt;- Region2 %&gt;%\n  filter(`Data Series` %in% Trading_Partners) %&gt;%   \n  pivot_longer(cols = -`Data Series`,               \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  mutate(Date = ym(Date)) %&gt;%  \n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\nre_ex_v4 &lt;- Region2 %&gt;%\n  filter(`Data Series` %in% Trading_Partners) %&gt;%   \n  pivot_longer(cols = -`Data Series`,               \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  mutate(Date = ym(Date)) %&gt;%  \n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\n\n\n\nimport1 &lt;- as.data.frame(t(Region1))\ndom_ex1 &lt;- as.data.frame(t(Region2))\nre_ex1 &lt;- as.data.frame(t(Region3))\n\ncolnames(import1) &lt;- import1[1, ]\ncolnames(dom_ex1) &lt;- dom_ex1[1, ]\ncolnames(re_ex1) &lt;- re_ex1[1, ]\n\nimport_tp &lt;- import1[-1, ]\ndom_ex_tp &lt;- dom_ex1[-1, ]\nre_ex_tp &lt;- re_ex1[-1, ]\n\nimport_tp &lt;- import_tp %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.character(Date),   \n         Date = ym(Date)) %&gt;%         \n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)  \n\ndom_ex_tp &lt;- dom_ex_tp %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.character(Date), \n         Date = ym(Date)) %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\nre_ex_tp &lt;- re_ex_tp %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.character(Date), \n         Date = ym(Date)) %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\n\nimport_tsibble &lt;- import_tp %&gt;%\n  mutate(Month = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Month`)\n\ndom_ex_tsibble &lt;- dom_ex_tp %&gt;%\n  mutate(Month = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Month`)\n\nre_ex_tsibble &lt;- re_ex_tp %&gt;%\n  mutate(Month = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Month`)\n\n\nimport_longer &lt;- import_tsibble %&gt;%\n  pivot_longer(cols = all_of(Trading_Partners),  \n               names_to = \"Country\",\n               values_to = \"Trade_Value\")\n\ndom_ex_longer &lt;- dom_ex_tsibble %&gt;%\n  pivot_longer(cols = all_of(Trading_Partners),  \n               names_to = \"Country\",\n               values_to = \"Trade_Value\")\n\nre_ex_longer &lt;- re_ex_tsibble %&gt;%\n  pivot_longer(cols = all_of(Trading_Partners),  \n               names_to = \"Country\",\n               values_to = \"Trade_Value\")\n\n\n\n\n\nggplot(data = imports_v4, \n       aes(x = Date, \n           y = Trade_Value/1e3,\n           color = `Data Series`))+\n  geom_line(linewidth = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\")) +\n  labs(title = \"Major Import Partners\",\n       x = \"\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Country\")\n\n\n\n\n\n\n\n\n\nggplot(data = domestic_ex_v4, \n       aes(x = Date, \n           y = Trade_Value/1e3,\n           color = `Data Series`))+\n  geom_line(linewidth = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\")) +\n  labs(title = \"Major Domestic Export Partners\",\n       x = \"\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Country\")\n\n\n\n\n\n\n\n\n\nggplot(data = re_ex_v4, \n       aes(x = Date, \n           y = Trade_Value/1e3,\n           color = `Data Series`))+\n  geom_line(linewidth = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\")) +\n  labs(title = \"Major Re-Export Partners\",\n       x = \"\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Country\")\n\n\n\n\n\n\n\n\n\n\n\n\nhttps://ggplot2.tidyverse.org/reference/geom_boxplot.html\nhttps://ggplot2.tidyverse.org/reference/position_dodge.html"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#overview",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#overview",
    "title": "Take_Home Exercise 2",
    "section": "",
    "text": "Since Mr. Donald Trump took office as the President of the United States on January 20, 2025, one of the most closely watched topics has been global trade. As a visual analytics novice,I am eager to apply newly acquired techniques to explore and analyze the changing trends and patterns of Singapore’s international trade since 2015.\n\n\n\nIn Take-home Exercise 2, the focus is on redesigning and enhancing an existing data visualization created by a peer, with a particular emphasis on Singapore’s merchandise trade by region/market from the Department of Statistics Singapore (DOS). The task involves analyzing and critiquing the original visualization based on clarity and aesthetics, identifying areas for improvement.\nUsing data visualization design principles, we will consider both clarity and aesthetic aspects. The goal is to transform the original visualization into a more effective, engaging, and insightful representation of the data, enhancing clarity, insightfulness, and user engagement.\nAll the visualizations for this exercise will be sourced from SingStat’s Merchandise Trade data."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#getting-started",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#getting-started",
    "title": "Take_Home Exercise 2",
    "section": "",
    "text": "tidyverse: (i.e. readr, tidyr, dplyr, ggplot2) for performing data science tasks such as importing, tidying, and wrangling data, as well as creating graphics based on The Grammar of Graphics,\nreshape2 for transforming data between wide and long formats\nggthemes: provides some extra themes, geoms, and scales for ‘ggplot2’.\nggdist: a ggplot2 extension specially designed for visualising distribution and uncertainty\npatchwork: an R package for preparing composite figure created using ggplot2.\nggridges: a ggplot2 extension specially designed for plotting ridgeline plots.\nggrepel: an R package which provides geoms for ggplot2 to repel overlapping text labels.\ntsibble: for building static html table to aid us in having a better view of tables\nlubridate: R package that makes it easier to work with dates and times.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nThe following code chunk utilizes the p_load() function from the pacman package to verify whether the specified packages are already installed on the system. If the packages are detected, they will be loaded into the R environment. Otherwise, the function will automatically install them before proceeding with the loading process.\n\npacman::p_load(readxl,tidyverse, reshape2, ggthemes,\n               ggdist, patchwork, ggridges,\n               ggrepel, knitr, scales, lubridate,\n               patchwork,ggplot2,plotly,dplyr,tsibble)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#data-wrangling",
    "title": "Take_Home Exercise 2",
    "section": "",
    "text": "The dataset used in the exercise is in Excel format, retrieved from the Department of Statistics Singapore website.\nThe code chunk below import the dataset using read_excel() function of the haven package.\n\nlibrary(readxl) \nTrade1 &lt;- read_excel(\"data/OutputFile.xlsx\", sheet = 'T1')\n\n\nTrade1 &lt;- read_excel(\"data/OutputFile.xlsx\", sheet='T1',col_types=\"text\")\nRegion1 &lt;- read_excel(\"data/Region.xlsx\", sheet = 'T1')\nRegion2 &lt;- read_excel(\"data/Region.xlsx\", sheet = 'T2')\nRegion3 &lt;- read_excel(\"data/Region.xlsx\", sheet = 'T3')\nNonOil &lt;- read_excel(\"data/OutputFile.xlsx\", sheet='T1',col_types=\"text\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#data-visualization-makeover",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#data-visualization-makeover",
    "title": "Take_Home Exercise 2",
    "section": "",
    "text": "The “Total Merchandise Trade at Current Prices” visualization on Singapore’s Department of Statistics website provides a snapshot of the country’s trade performance. Here’s an analysis of its strengths and areas for improvement:​\nPros:\n\nClear Representation of Trade Values: The visualization effectively displays total trade figures, offering a straightforward understanding of Singapore’s merchandise trade volume.​\nUse of Current Prices: Presenting data at current prices reflects the actual trade values during the reported period, incorporating the effects of inflation and providing a realistic economic picture.​\n\nCons:\n\nLack of Historical Context:The visualization focuses on a single time point without showing trends over time, making it challenging to assess growth patterns or identify cyclical behaviors.​\nHeavily Text Based: The visualization is heavily text-based, making it hard to grasp trends at a glance.\n\n\n\n\nhead(Trade1)\n\n# A tibble: 6 × 734\n  `Data Series`           `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                   &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     \n1 Total Merchandise Trad… 114153979… 116278793… 110132324… 107525959… 103512459…\n2 Oil                     19490289.… 18488973.… 18061885.… 17510049.… 15686653.5\n3 Petroleum               16418934.4 15564654.… 14910685.5 14804333.5 12611958.1\n4 Oil Bunkers             3071355.5  2924319.4  3151199.6  2705716.2  3074695.3 \n5 Non-Oil                 94663689.… 97789819.… 92070439.… 90015910.… 87825806.…\n6 Food & Live Animals     2460910.6  2704578.8  2237326.1  2344744.7… 2235004.6 \n# ℹ 728 more variables: `2024 Aug` &lt;chr&gt;, `2024 Jul` &lt;chr&gt;, `2024 Jun` &lt;chr&gt;,\n#   `2024 May` &lt;chr&gt;, `2024 Apr` &lt;chr&gt;, `2024 Mar` &lt;chr&gt;, `2024 Feb` &lt;chr&gt;,\n#   `2024 Jan` &lt;chr&gt;, `2023 Dec` &lt;chr&gt;, `2023 Nov` &lt;chr&gt;, `2023 Oct` &lt;chr&gt;,\n#   `2023 Sep` &lt;chr&gt;, `2023 Aug` &lt;chr&gt;, `2023 Jul` &lt;chr&gt;, `2023 Jun` &lt;chr&gt;,\n#   `2023 May` &lt;chr&gt;, `2023 Apr` &lt;chr&gt;, `2023 Mar` &lt;chr&gt;, `2023 Feb` &lt;chr&gt;,\n#   `2023 Jan` &lt;chr&gt;, `2022 Dec` &lt;chr&gt;, `2022 Nov` &lt;chr&gt;, `2022 Oct` &lt;chr&gt;,\n#   `2022 Sep` &lt;chr&gt;, `2022 Aug` &lt;chr&gt;, `2022 Jul` &lt;chr&gt;, `2022 Jun` &lt;chr&gt;, …\n\n\nii. Checking Missing Values\n\ncolSums(is.na(Trade1))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan    2002 Dec    2002 Nov    2002 Oct    2002 Sep \n          0           0           0           0           0           0 \n   2002 Aug    2002 Jul    2002 Jun    2002 May    2002 Apr    2002 Mar \n          0           0           0           0           0           0 \n   2002 Feb    2002 Jan    2001 Dec    2001 Nov    2001 Oct    2001 Sep \n          0           0           0           0           0           0 \n   2001 Aug    2001 Jul    2001 Jun    2001 May    2001 Apr    2001 Mar \n          0           0           0           0           0           0 \n   2001 Feb    2001 Jan    2000 Dec    2000 Nov    2000 Oct    2000 Sep \n          0           0           0           0           0           0 \n   2000 Aug    2000 Jul    2000 Jun    2000 May    2000 Apr    2000 Mar \n          0           0           0           0           0           0 \n   2000 Feb    2000 Jan    1999 Dec    1999 Nov    1999 Oct    1999 Sep \n          0           0           0           0           0           0 \n   1999 Aug    1999 Jul    1999 Jun    1999 May    1999 Apr    1999 Mar \n          0           0           0           0           0           0 \n   1999 Feb    1999 Jan    1998 Dec    1998 Nov    1998 Oct    1998 Sep \n          0           0           0           0           0           0 \n   1998 Aug    1998 Jul    1998 Jun    1998 May    1998 Apr    1998 Mar \n          0           0           0           0           0           0 \n   1998 Feb    1998 Jan    1997 Dec    1997 Nov    1997 Oct    1997 Sep \n          0           0           0           0           0           0 \n   1997 Aug    1997 Jul    1997 Jun    1997 May    1997 Apr    1997 Mar \n          0           0           0           0           0           0 \n   1997 Feb    1997 Jan    1996 Dec    1996 Nov    1996 Oct    1996 Sep \n          0           0           0           0           0           0 \n   1996 Aug    1996 Jul    1996 Jun    1996 May    1996 Apr    1996 Mar \n          0           0           0           0           0           0 \n   1996 Feb    1996 Jan    1995 Dec    1995 Nov    1995 Oct    1995 Sep \n          0           0           0           0           0           0 \n   1995 Aug    1995 Jul    1995 Jun    1995 May    1995 Apr    1995 Mar \n          0           0           0           0           0           0 \n   1995 Feb    1995 Jan    1994 Dec    1994 Nov    1994 Oct    1994 Sep \n          0           0           0           0           0           0 \n   1994 Aug    1994 Jul    1994 Jun    1994 May    1994 Apr    1994 Mar \n          0           0           0           0           0           0 \n   1994 Feb    1994 Jan    1993 Dec    1993 Nov    1993 Oct    1993 Sep \n          0           0           0           0           0           0 \n   1993 Aug    1993 Jul    1993 Jun    1993 May    1993 Apr    1993 Mar \n          0           0           0           0           0           0 \n   1993 Feb    1993 Jan    1992 Dec    1992 Nov    1992 Oct    1992 Sep \n          0           0           0           0           0           0 \n   1992 Aug    1992 Jul    1992 Jun    1992 May    1992 Apr    1992 Mar \n          0           0           0           0           0           0 \n   1992 Feb    1992 Jan    1991 Dec    1991 Nov    1991 Oct    1991 Sep \n          0           0           0           0           0           0 \n   1991 Aug    1991 Jul    1991 Jun    1991 May    1991 Apr    1991 Mar \n          0           0           0           0           0           0 \n   1991 Feb    1991 Jan    1990 Dec    1990 Nov    1990 Oct    1990 Sep \n          0           0           0           0           0           0 \n   1990 Aug    1990 Jul    1990 Jun    1990 May    1990 Apr    1990 Mar \n          0           0           0           0           0           0 \n   1990 Feb    1990 Jan    1989 Dec    1989 Nov    1989 Oct    1989 Sep \n          0           0           0           0           0           0 \n   1989 Aug    1989 Jul    1989 Jun    1989 May    1989 Apr    1989 Mar \n          0           0           0           0           0           0 \n   1989 Feb    1989 Jan    1988 Dec    1988 Nov    1988 Oct    1988 Sep \n          0           0           0           0           0           0 \n   1988 Aug    1988 Jul    1988 Jun    1988 May    1988 Apr    1988 Mar \n          0           0           0           0           0           0 \n   1988 Feb    1988 Jan    1987 Dec    1987 Nov    1987 Oct    1987 Sep \n          0           0           0           0           0           0 \n   1987 Aug    1987 Jul    1987 Jun    1987 May    1987 Apr    1987 Mar \n          0           0           0           0           0           0 \n   1987 Feb    1987 Jan    1986 Dec    1986 Nov    1986 Oct    1986 Sep \n          0           0           0           0           0           0 \n   1986 Aug    1986 Jul    1986 Jun    1986 May    1986 Apr    1986 Mar \n          0           0           0           0           0           0 \n   1986 Feb    1986 Jan    1985 Dec    1985 Nov    1985 Oct    1985 Sep \n          0           0           0           0           0           0 \n   1985 Aug    1985 Jul    1985 Jun    1985 May    1985 Apr    1985 Mar \n          0           0           0           0           0           0 \n   1985 Feb    1985 Jan    1984 Dec    1984 Nov    1984 Oct    1984 Sep \n          0           0           0           0           0           0 \n   1984 Aug    1984 Jul    1984 Jun    1984 May    1984 Apr    1984 Mar \n          0           0           0           0           0           0 \n   1984 Feb    1984 Jan    1983 Dec    1983 Nov    1983 Oct    1983 Sep \n          0           0           0           0           0           0 \n   1983 Aug    1983 Jul    1983 Jun    1983 May    1983 Apr    1983 Mar \n          0           0           0           0           0           0 \n   1983 Feb    1983 Jan    1982 Dec    1982 Nov    1982 Oct    1982 Sep \n          0           0           0           0           0           0 \n   1982 Aug    1982 Jul    1982 Jun    1982 May    1982 Apr    1982 Mar \n          0           0           0           0           0           0 \n   1982 Feb    1982 Jan    1981 Dec    1981 Nov    1981 Oct    1981 Sep \n          0           0           0           0           0           0 \n   1981 Aug    1981 Jul    1981 Jun    1981 May    1981 Apr    1981 Mar \n          0           0           0           0           0           0 \n   1981 Feb    1981 Jan    1980 Dec    1980 Nov    1980 Oct    1980 Sep \n          0           0           0           0           0           0 \n   1980 Aug    1980 Jul    1980 Jun    1980 May    1980 Apr    1980 Mar \n          0           0           0           0           0           0 \n   1980 Feb    1980 Jan    1979 Dec    1979 Nov    1979 Oct    1979 Sep \n          0           0           0           0           0           0 \n   1979 Aug    1979 Jul    1979 Jun    1979 May    1979 Apr    1979 Mar \n          0           0           0           0           0           0 \n   1979 Feb    1979 Jan    1978 Dec    1978 Nov    1978 Oct    1978 Sep \n          0           0           0           0           0           0 \n   1978 Aug    1978 Jul    1978 Jun    1978 May    1978 Apr    1978 Mar \n          0           0           0           0           0           0 \n   1978 Feb    1978 Jan    1977 Dec    1977 Nov    1977 Oct    1977 Sep \n          0           0           0           0           0           0 \n   1977 Aug    1977 Jul    1977 Jun    1977 May    1977 Apr    1977 Mar \n          0           0           0           0           0           0 \n   1977 Feb    1977 Jan    1976 Dec    1976 Nov    1976 Oct    1976 Sep \n          0           0           0           0           0           0 \n   1976 Aug    1976 Jul    1976 Jun    1976 May    1976 Apr    1976 Mar \n          0           0           0           0           0           0 \n   1976 Feb    1976 Jan    1975 Dec    1975 Nov    1975 Oct    1975 Sep \n          0           0           0           0           0           0 \n   1975 Aug    1975 Jul    1975 Jun    1975 May    1975 Apr    1975 Mar \n          0           0           0           0           0           0 \n   1975 Feb    1975 Jan    1974 Dec    1974 Nov    1974 Oct    1974 Sep \n          0           0           0           0           0           0 \n   1974 Aug    1974 Jul    1974 Jun    1974 May    1974 Apr    1974 Mar \n          0           0           0           0           0           0 \n   1974 Feb    1974 Jan    1973 Dec    1973 Nov    1973 Oct    1973 Sep \n          0           0           0           0           0           0 \n   1973 Aug    1973 Jul    1973 Jun    1973 May    1973 Apr    1973 Mar \n          0           0           0           0           0           0 \n   1973 Feb    1973 Jan    1972 Dec    1972 Nov    1972 Oct    1972 Sep \n          0           0           0           0           0           0 \n   1972 Aug    1972 Jul    1972 Jun    1972 May    1972 Apr    1972 Mar \n          0           0           0           0           0           0 \n   1972 Feb    1972 Jan    1971 Dec    1971 Nov    1971 Oct    1971 Sep \n          0           0           0           0           0           0 \n   1971 Aug    1971 Jul    1971 Jun    1971 May    1971 Apr    1971 Mar \n          0           0           0           0           0           0 \n   1971 Feb    1971 Jan    1970 Dec    1970 Nov    1970 Oct    1970 Sep \n          0           0           0           0           0           0 \n   1970 Aug    1970 Jul    1970 Jun    1970 May    1970 Apr    1970 Mar \n          0           0           0           0           0           0 \n   1970 Feb    1970 Jan    1969 Dec    1969 Nov    1969 Oct    1969 Sep \n          0           0           0           0           0           0 \n   1969 Aug    1969 Jul    1969 Jun    1969 May    1969 Apr    1969 Mar \n          0           0           0           0           0           0 \n   1969 Feb    1969 Jan    1968 Dec    1968 Nov    1968 Oct    1968 Sep \n          0           0           0           0           0           0 \n   1968 Aug    1968 Jul    1968 Jun    1968 May    1968 Apr    1968 Mar \n          0           0           0           0           0           0 \n   1968 Feb    1968 Jan    1967 Dec    1967 Nov    1967 Oct    1967 Sep \n          0           0           0           0           0           0 \n   1967 Aug    1967 Jul    1967 Jun    1967 May    1967 Apr    1967 Mar \n          0           0           0           0           0           0 \n   1967 Feb    1967 Jan    1966 Dec    1966 Nov    1966 Oct    1966 Sep \n          0           0           0           0           0           0 \n   1966 Aug    1966 Jul    1966 Jun    1966 May    1966 Apr    1966 Mar \n          0           0           0           0           0           0 \n   1966 Feb    1966 Jan    1965 Dec    1965 Nov    1965 Oct    1965 Sep \n          0           0           0           0           0           0 \n   1965 Aug    1965 Jul    1965 Jun    1965 May    1965 Apr    1965 Mar \n          0           0           0           0           0           0 \n   1965 Feb    1965 Jan    1964 Dec    1964 Nov    1964 Oct    1964 Sep \n          0           0           0           0           0           0 \n   1964 Aug    1964 Jul    1964 Jun    1964 May    1964 Apr    1964 Mar \n          0           0           0           0           0           0 \n   1964 Feb    1964 Jan \n          0           0 \n\n\n\n\n\n\ncolnames(Trade1) &lt;- as.character(colnames(Trade1))\n\nCommodityCurrent &lt;- Trade1 %&gt;%\n  pivot_longer(cols = -`Data Series`, names_to = \"Year_Month\", values_to = \"Trade_Value\") %&gt;%\n  mutate(Trade_Value = suppressWarnings(as.numeric(Trade_Value))) \n\n\nhead(CommodityCurrent)\n\n# A tibble: 6 × 3\n  `Data Series`                                Year_Month Trade_Value\n  &lt;chr&gt;                                        &lt;chr&gt;            &lt;dbl&gt;\n1 Total Merchandise Trade, (At Current Prices) 2025 Jan    114153980.\n2 Total Merchandise Trade, (At Current Prices) 2024 Dec    116278793.\n3 Total Merchandise Trade, (At Current Prices) 2024 Nov    110132324.\n4 Total Merchandise Trade, (At Current Prices) 2024 Oct    107525960.\n5 Total Merchandise Trade, (At Current Prices) 2024 Sep    103512460.\n6 Total Merchandise Trade, (At Current Prices) 2024 Aug    105709528.\n\n\niv. Filtering the year 2020-2024\n\nCommodity_C_Total &lt;- CommodityCurrent %&gt;%\n  filter(`Data Series` %in% c(\"Total Merchandise Imports, (At Current Prices)\", \"Total Merchandise Exports, (At Current Prices)\", \"Total Merchandise Trade, (At Current Prices)\"))\n\n\nCommodity_C_Total &lt;- Commodity_C_Total %&gt;%\n  mutate(Year = year(parse_date_time(Year_Month, orders = \"ym\"))) %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%\n  group_by(Year, `Data Series`) %&gt;%\n  summarise(Total_Trade_Value = sum(Trade_Value, na.rm = TRUE), .groups = \"drop\")  \n\n\nhead(Commodity_C_Total)\n\n# A tibble: 6 × 3\n   Year `Data Series`                                  Total_Trade_Value\n  &lt;dbl&gt; &lt;chr&gt;                                                      &lt;dbl&gt;\n1  2020 Total Merchandise Exports, (At Current Prices)        515644539 \n2  2020 Total Merchandise Imports, (At Current Prices)        453467444.\n3  2020 Total Merchandise Trade, (At Current Prices)          969111983.\n4  2021 Total Merchandise Exports, (At Current Prices)        614081094.\n5  2021 Total Merchandise Imports, (At Current Prices)        545881937.\n6  2021 Total Merchandise Trade, (At Current Prices)         1159963031.\n\n\n\n\n\n\nlibrary(ggplot2) \nlibrary(plotly)\nlibrary(scales)\n\np &lt;- ggplot(Commodity_C_Total, aes(x = Year, y = Total_Trade_Value / 1e6, color = `Data Series`, group = `Data Series`, text = paste(\"Year:\", Year, \"&lt;br&gt;\", \"Trade Type:\", `Data Series`, \"&lt;br&gt;\", \"Trade Value: S$\", scales::comma(Total_Trade_Value / 1e6), \"B\"))) + \n  geom_line(linewidth = 1) +\n  geom_point(size = 2) +\n  theme_minimal() +\n  labs(title = \"Yearly Trend of Merchandise Trade (2020-2024)\",\n       x = \"Year\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Trade Type\") +\n  scale_x_continuous(breaks = seq(2020, 2024, 1)) +\n  scale_y_continuous(labels = label_number(scale = 1))  \n\nggplotly(p, tooltip = \"text\") \n\n\n\n\n\n\n\n\n\n\nPros:\n\nEfficient Space Utilization: The compact nature of a bubble chart allows multiple data points to be displayed in a small area without requiring an extensive table.\nQuickly Highlights Key Trade Partners: The bubble chart makes it easy to identify which countries have the largest trade volumes with Singapore at a glance. Larger bubbles automatically draw attention to major trading partners, emphasizing total trade activity.\nIntuitive Representation of Trade Imbalance: The position of bubbles in different regions visually distinguishes between partners with a trade surplus (more exports) and those with a trade deficit (more imports).\n\nCons:\n\nOvercrowding with Multiple Data Points: If there are too many trading partners displayed, the bubbles can overlap excessively, making it difficult to differentiate individual partners.\nPotential for Misleading Perceptions: If not scaled correctly, the difference between bubble sizes may exaggerate or understate actual trade disparities.\nNot Suitable for Precise Numerical Analysis: Unlike bar charts or tables, bubble charts do not provide precise export/import values, which may be necessary for detailed analysis.\n\ni. Data(Preparation)\n\nhead(Region1)\n\n# A tibble: 6 × 266\n  `Data Series`       `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Total All Markets       54746.    56136.      51802.    51416.     49068. \n2 America                  6923.     7874.       7880.     8078.      9112  \n3 Antigua And Barbuda         0         0           0         0          0  \n4 Argentina                   4        12.5       116.        4.1        8.1\n5 Bahamas                     0         8.1         0         0          0  \n6 Bermuda                     0         0           0         0          0  \n# ℹ 260 more variables: `2024 Aug` &lt;dbl&gt;, `2024 Jul` &lt;dbl&gt;, `2024 Jun` &lt;dbl&gt;,\n#   `2024 May` &lt;dbl&gt;, `2024 Apr` &lt;dbl&gt;, `2024 Mar` &lt;dbl&gt;, `2024 Feb` &lt;dbl&gt;,\n#   `2024 Jan` &lt;dbl&gt;, `2023 Dec` &lt;dbl&gt;, `2023 Nov` &lt;dbl&gt;, `2023 Oct` &lt;dbl&gt;,\n#   `2023 Sep` &lt;dbl&gt;, `2023 Aug` &lt;dbl&gt;, `2023 Jul` &lt;dbl&gt;, `2023 Jun` &lt;dbl&gt;,\n#   `2023 May` &lt;dbl&gt;, `2023 Apr` &lt;dbl&gt;, `2023 Mar` &lt;dbl&gt;, `2023 Feb` &lt;dbl&gt;,\n#   `2023 Jan` &lt;dbl&gt;, `2022 Dec` &lt;dbl&gt;, `2022 Nov` &lt;dbl&gt;, `2022 Oct` &lt;dbl&gt;,\n#   `2022 Sep` &lt;dbl&gt;, `2022 Aug` &lt;dbl&gt;, `2022 Jul` &lt;dbl&gt;, `2022 Jun` &lt;dbl&gt;, …\n\n\n\nhead(Region2)\n\n# A tibble: 6 × 266\n  `Data Series`       `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Total All Markets      24672      23685.     23439.     22148.     21967. \n2 America                 4263.      3608.      3129.      2936.      3294. \n3 Antigua And Barbuda        8.8        7.1        8.3        7.7        8.2\n4 Argentina                  5.3        6          3.9        6.4        3  \n5 Bahamas                   51.4       48.1       60.5       36.1       59.3\n6 Bermuda                    2.7        7.7        0.5        5.4        0.7\n# ℹ 260 more variables: `2024 Aug` &lt;dbl&gt;, `2024 Jul` &lt;dbl&gt;, `2024 Jun` &lt;dbl&gt;,\n#   `2024 May` &lt;dbl&gt;, `2024 Apr` &lt;dbl&gt;, `2024 Mar` &lt;dbl&gt;, `2024 Feb` &lt;dbl&gt;,\n#   `2024 Jan` &lt;dbl&gt;, `2023 Dec` &lt;dbl&gt;, `2023 Nov` &lt;dbl&gt;, `2023 Oct` &lt;dbl&gt;,\n#   `2023 Sep` &lt;dbl&gt;, `2023 Aug` &lt;dbl&gt;, `2023 Jul` &lt;dbl&gt;, `2023 Jun` &lt;dbl&gt;,\n#   `2023 May` &lt;dbl&gt;, `2023 Apr` &lt;dbl&gt;, `2023 Mar` &lt;dbl&gt;, `2023 Feb` &lt;dbl&gt;,\n#   `2023 Jan` &lt;dbl&gt;, `2022 Dec` &lt;dbl&gt;, `2022 Nov` &lt;dbl&gt;, `2022 Oct` &lt;dbl&gt;,\n#   `2022 Sep` &lt;dbl&gt;, `2022 Aug` &lt;dbl&gt;, `2022 Jul` &lt;dbl&gt;, `2022 Jun` &lt;dbl&gt;, …\n\n\n\nhead(Region3)\n\n# A tibble: 6 × 266\n  `Data Series`       `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Total All Markets      34736.     36458.     34892.     33963.     32477. \n2 America                 3110.      3893.      3528.      3389.      3197. \n3 Antigua And Barbuda        1.9        0.1        0          0.2        0  \n4 Argentina                 25.7       22.3       19.4       23.8       27.1\n5 Bahamas                    9.8        1.3        3.7        4.3        8.1\n6 Bermuda                    0.1        0          0          0.1        0  \n# ℹ 260 more variables: `2024 Aug` &lt;dbl&gt;, `2024 Jul` &lt;dbl&gt;, `2024 Jun` &lt;dbl&gt;,\n#   `2024 May` &lt;dbl&gt;, `2024 Apr` &lt;dbl&gt;, `2024 Mar` &lt;dbl&gt;, `2024 Feb` &lt;dbl&gt;,\n#   `2024 Jan` &lt;dbl&gt;, `2023 Dec` &lt;dbl&gt;, `2023 Nov` &lt;dbl&gt;, `2023 Oct` &lt;dbl&gt;,\n#   `2023 Sep` &lt;dbl&gt;, `2023 Aug` &lt;dbl&gt;, `2023 Jul` &lt;dbl&gt;, `2023 Jun` &lt;dbl&gt;,\n#   `2023 May` &lt;dbl&gt;, `2023 Apr` &lt;dbl&gt;, `2023 Mar` &lt;dbl&gt;, `2023 Feb` &lt;dbl&gt;,\n#   `2023 Jan` &lt;dbl&gt;, `2022 Dec` &lt;dbl&gt;, `2022 Nov` &lt;dbl&gt;, `2022 Oct` &lt;dbl&gt;,\n#   `2022 Sep` &lt;dbl&gt;, `2022 Aug` &lt;dbl&gt;, `2022 Jul` &lt;dbl&gt;, `2022 Jun` &lt;dbl&gt;, …\n\n\nii. Checking Missing Values\n\ncolSums(is.na(Region1))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan \n          0           0 \n\n\n\ncolSums(is.na(Region2))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan \n          0           0 \n\n\n\ncolSums(is.na(Region3))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan \n          0           0 \n\n\niii. Filtering for 2024 and Selected Trading Partners\n\nTrading_Partners &lt;- c(\"China\", \"Malaysia\", \"United States\", \n                      \"Taiwan\", \"Europe\", \"Indonesia\", \"Hong Kong\", \n                      \"Korea, Rep Of\", \"Japan\", \"Thailand\")\n\n\nImports &lt;- Region1 %&gt;%\n  filter(`Data Series` %in% Trading_Partners) %&gt;%   \n  pivot_longer(cols = -`Data Series`,               \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  filter(grepl(\"^2024\", Date)) %&gt;%   \n  mutate(Trade_Type = \"Imports\") \n\n\nExports &lt;- bind_rows(Region2, Region3) %&gt;%  \n  filter(`Data Series` %in% Trading_Partners) %&gt;%\n  pivot_longer(cols = -`Data Series`, \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  filter(grepl(\"^2024\", Date)) %&gt;%   \n  mutate(Trade_Type = \"Exports\") \n\n# Combine Imports and Exports into a single dataset\nTrade_Data &lt;- bind_rows(Imports, Exports)\n\n\nhead(Trade_Data)\n\n# A tibble: 6 × 4\n  `Data Series` Date     Trade_Value Trade_Type\n  &lt;chr&gt;         &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;     \n1 United States 2024 Dec       6652. Imports   \n2 United States 2024 Nov       5989. Imports   \n3 United States 2024 Oct       6093. Imports   \n4 United States 2024 Sep       6449. Imports   \n5 United States 2024 Aug       7258. Imports   \n6 United States 2024 Jul       6190. Imports   \n\n\n\n# Summarize Total Trade by Country\nTrade_Summary &lt;- Trade_Data %&gt;%\n  group_by(`Data Series`, Trade_Type) %&gt;%\n  summarise(Total_Trade_Value = sum(Trade_Value, na.rm = TRUE)) %&gt;%\n  pivot_wider(names_from = Trade_Type, values_from = Total_Trade_Value) %&gt;%\n  mutate(Total_Trade = Exports + Imports,  \n         Trade_Balance = Exports - Imports)  # Surplus (+) or Deficit (-)\n\n\ncolnames(Trade_Summary) &lt;- c(\"Country\", \"Exports\", \"Imports\", \"Total_Trade\", \"Trade_Balance\")\n\n\nhead(Trade_Summary)\n\n# A tibble: 6 × 5\n# Groups:   Country [6]\n  Country       Exports Imports Total_Trade Trade_Balance\n  &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;\n1 China          94443.  75740.     170182.        18703.\n2 Europe         52417.  89635.     142052.       -37218.\n3 Hong Kong      73879.   4744.      78622.        69135 \n4 Indonesia      53216.  20938.      74155.        32278.\n5 Japan          23707.  29696.      53402.        -5989.\n6 Korea, Rep Of  28423.  38395.      66818.        -9973.\n\n\n\np &lt;- ggplot(Trade_Summary, aes(x = Imports, y = Exports, size = Total_Trade, fill = Trade_Balance)) +\n \n  geom_point(shape = 21, alpha = 0.7, color = \"black\") +  \n  geom_text(aes(label = Country), size = 3.5, fontface = \"bold\", color = \"black\") +\n\n  scale_x_continuous(labels = scales::comma_format(), limits = c(0, max(Trade_Summary$Imports) * 1.1)) +  \n  scale_y_continuous(labels = scales::comma_format()) +  \n\n  scale_size_continuous(range = c(6, 25), guide = \"legend\") +  \n  scale_fill_gradient2(low = \"red\", mid = \"white\", high = \"blue\", midpoint = 0, name = \"Trade Balance\") + \n  \n\n  labs(title = \"Merchandise Trade Performance with Major Trading Partners (2024)\",\n       subtitle = \"Bubble size represents total trade volume. Color indicates trade balance.\",\n       x = \"Imports (S$ Billion)\", y = \"Exports (S$ Billion)\",\n       size = \"Total Trade (S$ Billion)\") +\n  \n   theme_minimal() +\n  theme(legend.position = \"bottom\",\n        panel.grid.major = element_line(color = \"gray85\", linetype = \"dashed\"),\n        panel.grid.minor = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14, face = \"bold\"))\n\nggplotly(p, tooltip = c(\"Country\", \"Exports\", \"Imports\", \"Total_Trade\", \"Trade_Balance\"))\n\n\n\n\n\n\n\n\n\nPros:\n\nBreaks down trade data by commodity sections, providing insights into the composition of trade.​\nUses color coding to differentiate between exports and imports.​\n\nCons:\n\nThe side-by-side bar arrangement can make it challenging to compare the export and import values of each commodity directly.​\nThe legend placement might require viewers to move back and forth between the chart and the legend, hindering quick comprehension.​\nAfter exceeding 60 Billion, the bar represented by a segmented bar as can be seen on Machinery and Transport Equipment.\n\ni. Filtering out Non-Oil Merchandise Trade\n\ncolnames(NonOil) &lt;- as.character(colnames(NonOil))\n\ncommodity_mod &lt;- NonOil %&gt;%\n  pivot_longer(cols = -`Data Series`, names_to = \"Year_Month\", values_to = \"Trade_Value\") %&gt;%\n  mutate(Trade_Value = suppressWarnings(as.numeric(Trade_Value))) \n\n\ncategories &lt;- c(\n  \"Food & Live Animals [Imports]\", \"Beverages & Tobacco [Imports]\", \n  \"Crude Materials (Excl Fuels) [Imports]\", \"Animal & Vegetable Oils Fats & Waxes [Imports]\", \n  \"Chemicals & Chemical Products [Imports]\", \"Manufactured Goods [Imports]\", \n  \"Machinery & Transport Equipment [Imports]\", \"Miscellaneous Manufactured Articles [Imports]\", \n  \"Miscellaneous (Excluding Oil Bunkers) [Imports]\", \"Food & Live Animals [Exports]\", \n  \"Beverages & Tobacco [Exports]\", \"Crude Materials (Excl Fuels) [Exports]\", \n  \"Animal & Vegetable Oils Fats & Waxes [Exports]\", \"Chemicals & Chemical Products [Exports]\", \n  \"Manufactured Goods [Exports]\", \"Machinery & Transport Equipment [Exports]\", \n  \"Miscellaneous Manufactured Articles [Exports]\", \"Miscellaneous (Excluding Oil Bunkers) [Exports]\"\n)\n\ncommodity_category &lt;- commodity_mod %&gt;%\n  filter(`Data Series` %in% categories)\n\n\nlibrary(dplyr)\nlibrary(lubridate)\n\ncommodity_category &lt;- commodity_category %&gt;%\n  mutate(\n    Year_Month = as.character(Year_Month),  # Ensure it's a character\n    Year = year(parse_date_time(Year_Month, orders = \"Y b\"))  # \"Y b\" means \"2024 Jan\"\n  ) %&gt;%\n  filter(Year == 2024) %&gt;%\n  group_by(Year, `Data Series`) %&gt;%\n  summarise(Total_Trade_Value = sum(Trade_Value, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\nSeparating Trade type and Commodity\n\n\ncommodity_category &lt;- commodity_category %&gt;%\n  separate(`Data Series`, into = c(\"Commodity\", \"Trade_Type\"), sep = \" \\\\[\", remove = TRUE) %&gt;%\n  mutate(Trade_Type = gsub(\"\\\\]\", \"\", Trade_Type))\n\n\nkable(head(commodity_category))\n\n\n\n\nYear\nCommodity\nTrade_Type\nTotal_Trade_Value\n\n\n\n\n\n\n\nMakeover"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#reference",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#reference",
    "title": "Take_Home Exercise 2",
    "section": "",
    "text": "https://ggplot2.tidyverse.org/reference/geom_boxplot.html\nhttps://ggplot2.tidyverse.org/reference/position_dodge.html"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#merchandise-trade-performance-with-major-trading-partners-2024",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#merchandise-trade-performance-with-major-trading-partners-2024",
    "title": "Take_Home Exercise 2",
    "section": "",
    "text": "Pros:\n\nEfficient Space Utilization: The compact nature of a bubble chart allows multiple data points to be displayed in a small area without requiring an extensive table.\nQuickly Highlights Key Trade Partners: The bubble chart makes it easy to identify which countries have the largest trade volumes with Singapore at a glance. Larger bubbles automatically draw attention to major trading partners, emphasizing total trade activity.\nIntuitive Representation of Trade Imbalance: The position of bubbles in different regions visually distinguishes between partners with a trade surplus (more exports) and those with a trade deficit (more imports).\n\nCons:\n\nOvercrowding with Multiple Data Points: If there are too many trading partners displayed, the bubbles can overlap excessively, making it difficult to differentiate individual partners.\nPotential for Misleading Perceptions: If not scaled correctly, the difference between bubble sizes may exaggerate or understate actual trade disparities.\nNot Suitable for Precise Numerical Analysis: Unlike bar charts or tables, bubble charts do not provide precise export/import values, which may be necessary for detailed analysis.\n\ni. Data(Preparation)\n\nhead(Region1)\n\n# A tibble: 6 × 266\n  `Data Series`       `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Total All Markets       54746.    56136.      51802.    51416.     49068. \n2 America                  6923.     7874.       7880.     8078.      9112  \n3 Antigua And Barbuda         0         0           0         0          0  \n4 Argentina                   4        12.5       116.        4.1        8.1\n5 Bahamas                     0         8.1         0         0          0  \n6 Bermuda                     0         0           0         0          0  \n# ℹ 260 more variables: `2024 Aug` &lt;dbl&gt;, `2024 Jul` &lt;dbl&gt;, `2024 Jun` &lt;dbl&gt;,\n#   `2024 May` &lt;dbl&gt;, `2024 Apr` &lt;dbl&gt;, `2024 Mar` &lt;dbl&gt;, `2024 Feb` &lt;dbl&gt;,\n#   `2024 Jan` &lt;dbl&gt;, `2023 Dec` &lt;dbl&gt;, `2023 Nov` &lt;dbl&gt;, `2023 Oct` &lt;dbl&gt;,\n#   `2023 Sep` &lt;dbl&gt;, `2023 Aug` &lt;dbl&gt;, `2023 Jul` &lt;dbl&gt;, `2023 Jun` &lt;dbl&gt;,\n#   `2023 May` &lt;dbl&gt;, `2023 Apr` &lt;dbl&gt;, `2023 Mar` &lt;dbl&gt;, `2023 Feb` &lt;dbl&gt;,\n#   `2023 Jan` &lt;dbl&gt;, `2022 Dec` &lt;dbl&gt;, `2022 Nov` &lt;dbl&gt;, `2022 Oct` &lt;dbl&gt;,\n#   `2022 Sep` &lt;dbl&gt;, `2022 Aug` &lt;dbl&gt;, `2022 Jul` &lt;dbl&gt;, `2022 Jun` &lt;dbl&gt;, …\n\n\n\nhead(Region2)\n\n# A tibble: 6 × 266\n  `Data Series`       `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Total All Markets      24672      23685.     23439.     22148.     21967. \n2 America                 4263.      3608.      3129.      2936.      3294. \n3 Antigua And Barbuda        8.8        7.1        8.3        7.7        8.2\n4 Argentina                  5.3        6          3.9        6.4        3  \n5 Bahamas                   51.4       48.1       60.5       36.1       59.3\n6 Bermuda                    2.7        7.7        0.5        5.4        0.7\n# ℹ 260 more variables: `2024 Aug` &lt;dbl&gt;, `2024 Jul` &lt;dbl&gt;, `2024 Jun` &lt;dbl&gt;,\n#   `2024 May` &lt;dbl&gt;, `2024 Apr` &lt;dbl&gt;, `2024 Mar` &lt;dbl&gt;, `2024 Feb` &lt;dbl&gt;,\n#   `2024 Jan` &lt;dbl&gt;, `2023 Dec` &lt;dbl&gt;, `2023 Nov` &lt;dbl&gt;, `2023 Oct` &lt;dbl&gt;,\n#   `2023 Sep` &lt;dbl&gt;, `2023 Aug` &lt;dbl&gt;, `2023 Jul` &lt;dbl&gt;, `2023 Jun` &lt;dbl&gt;,\n#   `2023 May` &lt;dbl&gt;, `2023 Apr` &lt;dbl&gt;, `2023 Mar` &lt;dbl&gt;, `2023 Feb` &lt;dbl&gt;,\n#   `2023 Jan` &lt;dbl&gt;, `2022 Dec` &lt;dbl&gt;, `2022 Nov` &lt;dbl&gt;, `2022 Oct` &lt;dbl&gt;,\n#   `2022 Sep` &lt;dbl&gt;, `2022 Aug` &lt;dbl&gt;, `2022 Jul` &lt;dbl&gt;, `2022 Jun` &lt;dbl&gt;, …\n\n\n\nhead(Region3)\n\n# A tibble: 6 × 266\n  `Data Series`       `2025 Jan` `2024 Dec` `2024 Nov` `2024 Oct` `2024 Sep`\n  &lt;chr&gt;                    &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Total All Markets      34736.     36458.     34892.     33963.     32477. \n2 America                 3110.      3893.      3528.      3389.      3197. \n3 Antigua And Barbuda        1.9        0.1        0          0.2        0  \n4 Argentina                 25.7       22.3       19.4       23.8       27.1\n5 Bahamas                    9.8        1.3        3.7        4.3        8.1\n6 Bermuda                    0.1        0          0          0.1        0  \n# ℹ 260 more variables: `2024 Aug` &lt;dbl&gt;, `2024 Jul` &lt;dbl&gt;, `2024 Jun` &lt;dbl&gt;,\n#   `2024 May` &lt;dbl&gt;, `2024 Apr` &lt;dbl&gt;, `2024 Mar` &lt;dbl&gt;, `2024 Feb` &lt;dbl&gt;,\n#   `2024 Jan` &lt;dbl&gt;, `2023 Dec` &lt;dbl&gt;, `2023 Nov` &lt;dbl&gt;, `2023 Oct` &lt;dbl&gt;,\n#   `2023 Sep` &lt;dbl&gt;, `2023 Aug` &lt;dbl&gt;, `2023 Jul` &lt;dbl&gt;, `2023 Jun` &lt;dbl&gt;,\n#   `2023 May` &lt;dbl&gt;, `2023 Apr` &lt;dbl&gt;, `2023 Mar` &lt;dbl&gt;, `2023 Feb` &lt;dbl&gt;,\n#   `2023 Jan` &lt;dbl&gt;, `2022 Dec` &lt;dbl&gt;, `2022 Nov` &lt;dbl&gt;, `2022 Oct` &lt;dbl&gt;,\n#   `2022 Sep` &lt;dbl&gt;, `2022 Aug` &lt;dbl&gt;, `2022 Jul` &lt;dbl&gt;, `2022 Jun` &lt;dbl&gt;, …\n\n\nii. Checking Missing Values\n\ncolSums(is.na(Region1))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan \n          0           0 \n\n\n\ncolSums(is.na(Region2))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan \n          0           0 \n\n\n\ncolSums(is.na(Region3))\n\nData Series    2025 Jan    2024 Dec    2024 Nov    2024 Oct    2024 Sep \n          0           0           0           0           0           0 \n   2024 Aug    2024 Jul    2024 Jun    2024 May    2024 Apr    2024 Mar \n          0           0           0           0           0           0 \n   2024 Feb    2024 Jan    2023 Dec    2023 Nov    2023 Oct    2023 Sep \n          0           0           0           0           0           0 \n   2023 Aug    2023 Jul    2023 Jun    2023 May    2023 Apr    2023 Mar \n          0           0           0           0           0           0 \n   2023 Feb    2023 Jan    2022 Dec    2022 Nov    2022 Oct    2022 Sep \n          0           0           0           0           0           0 \n   2022 Aug    2022 Jul    2022 Jun    2022 May    2022 Apr    2022 Mar \n          0           0           0           0           0           0 \n   2022 Feb    2022 Jan    2021 Dec    2021 Nov    2021 Oct    2021 Sep \n          0           0           0           0           0           0 \n   2021 Aug    2021 Jul    2021 Jun    2021 May    2021 Apr    2021 Mar \n          0           0           0           0           0           0 \n   2021 Feb    2021 Jan    2020 Dec    2020 Nov    2020 Oct    2020 Sep \n          0           0           0           0           0           0 \n   2020 Aug    2020 Jul    2020 Jun    2020 May    2020 Apr    2020 Mar \n          0           0           0           0           0           0 \n   2020 Feb    2020 Jan    2019 Dec    2019 Nov    2019 Oct    2019 Sep \n          0           0           0           0           0           0 \n   2019 Aug    2019 Jul    2019 Jun    2019 May    2019 Apr    2019 Mar \n          0           0           0           0           0           0 \n   2019 Feb    2019 Jan    2018 Dec    2018 Nov    2018 Oct    2018 Sep \n          0           0           0           0           0           0 \n   2018 Aug    2018 Jul    2018 Jun    2018 May    2018 Apr    2018 Mar \n          0           0           0           0           0           0 \n   2018 Feb    2018 Jan    2017 Dec    2017 Nov    2017 Oct    2017 Sep \n          0           0           0           0           0           0 \n   2017 Aug    2017 Jul    2017 Jun    2017 May    2017 Apr    2017 Mar \n          0           0           0           0           0           0 \n   2017 Feb    2017 Jan    2016 Dec    2016 Nov    2016 Oct    2016 Sep \n          0           0           0           0           0           0 \n   2016 Aug    2016 Jul    2016 Jun    2016 May    2016 Apr    2016 Mar \n          0           0           0           0           0           0 \n   2016 Feb    2016 Jan    2015 Dec    2015 Nov    2015 Oct    2015 Sep \n          0           0           0           0           0           0 \n   2015 Aug    2015 Jul    2015 Jun    2015 May    2015 Apr    2015 Mar \n          0           0           0           0           0           0 \n   2015 Feb    2015 Jan    2014 Dec    2014 Nov    2014 Oct    2014 Sep \n          0           0           0           0           0           0 \n   2014 Aug    2014 Jul    2014 Jun    2014 May    2014 Apr    2014 Mar \n          0           0           0           0           0           0 \n   2014 Feb    2014 Jan    2013 Dec    2013 Nov    2013 Oct    2013 Sep \n          0           0           0           0           0           0 \n   2013 Aug    2013 Jul    2013 Jun    2013 May    2013 Apr    2013 Mar \n          0           0           0           0           0           0 \n   2013 Feb    2013 Jan    2012 Dec    2012 Nov    2012 Oct    2012 Sep \n          0           0           0           0           0           0 \n   2012 Aug    2012 Jul    2012 Jun    2012 May    2012 Apr    2012 Mar \n          0           0           0           0           0           0 \n   2012 Feb    2012 Jan    2011 Dec    2011 Nov    2011 Oct    2011 Sep \n          0           0           0           0           0           0 \n   2011 Aug    2011 Jul    2011 Jun    2011 May    2011 Apr    2011 Mar \n          0           0           0           0           0           0 \n   2011 Feb    2011 Jan    2010 Dec    2010 Nov    2010 Oct    2010 Sep \n          0           0           0           0           0           0 \n   2010 Aug    2010 Jul    2010 Jun    2010 May    2010 Apr    2010 Mar \n          0           0           0           0           0           0 \n   2010 Feb    2010 Jan    2009 Dec    2009 Nov    2009 Oct    2009 Sep \n          0           0           0           0           0           0 \n   2009 Aug    2009 Jul    2009 Jun    2009 May    2009 Apr    2009 Mar \n          0           0           0           0           0           0 \n   2009 Feb    2009 Jan    2008 Dec    2008 Nov    2008 Oct    2008 Sep \n          0           0           0           0           0           0 \n   2008 Aug    2008 Jul    2008 Jun    2008 May    2008 Apr    2008 Mar \n          0           0           0           0           0           0 \n   2008 Feb    2008 Jan    2007 Dec    2007 Nov    2007 Oct    2007 Sep \n          0           0           0           0           0           0 \n   2007 Aug    2007 Jul    2007 Jun    2007 May    2007 Apr    2007 Mar \n          0           0           0           0           0           0 \n   2007 Feb    2007 Jan    2006 Dec    2006 Nov    2006 Oct    2006 Sep \n          0           0           0           0           0           0 \n   2006 Aug    2006 Jul    2006 Jun    2006 May    2006 Apr    2006 Mar \n          0           0           0           0           0           0 \n   2006 Feb    2006 Jan    2005 Dec    2005 Nov    2005 Oct    2005 Sep \n          0           0           0           0           0           0 \n   2005 Aug    2005 Jul    2005 Jun    2005 May    2005 Apr    2005 Mar \n          0           0           0           0           0           0 \n   2005 Feb    2005 Jan    2004 Dec    2004 Nov    2004 Oct    2004 Sep \n          0           0           0           0           0           0 \n   2004 Aug    2004 Jul    2004 Jun    2004 May    2004 Apr    2004 Mar \n          0           0           0           0           0           0 \n   2004 Feb    2004 Jan    2003 Dec    2003 Nov    2003 Oct    2003 Sep \n          0           0           0           0           0           0 \n   2003 Aug    2003 Jul    2003 Jun    2003 May    2003 Apr    2003 Mar \n          0           0           0           0           0           0 \n   2003 Feb    2003 Jan \n          0           0 \n\n\niii. Filtering for 2024 and Selected Trading Partners\n\nTrading_Partners &lt;- c(\"China\", \"Malaysia\", \"United States\", \n                      \"Taiwan\", \"Europe\", \"Indonesia\", \"Hong Kong\", \n                      \"Korea, Rep Of\", \"Japan\", \"Thailand\")\n\n\nImports &lt;- Region1 %&gt;%\n  filter(`Data Series` %in% Trading_Partners) %&gt;%   \n  pivot_longer(cols = -`Data Series`,               \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  filter(grepl(\"^2024\", Date)) %&gt;%   \n  mutate(Trade_Type = \"Imports\") \n\n\nExports &lt;- bind_rows(Region2, Region3) %&gt;%  \n  filter(`Data Series` %in% Trading_Partners) %&gt;%\n  pivot_longer(cols = -`Data Series`, \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  filter(grepl(\"^2024\", Date)) %&gt;%   \n  mutate(Trade_Type = \"Exports\") \n\n# Combine Imports and Exports into a single dataset\nTrade_Data &lt;- bind_rows(Imports, Exports)\n\n\nhead(Trade_Data)\n\n# A tibble: 6 × 4\n  `Data Series` Date     Trade_Value Trade_Type\n  &lt;chr&gt;         &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;     \n1 United States 2024 Dec       6652. Imports   \n2 United States 2024 Nov       5989. Imports   \n3 United States 2024 Oct       6093. Imports   \n4 United States 2024 Sep       6449. Imports   \n5 United States 2024 Aug       7258. Imports   \n6 United States 2024 Jul       6190. Imports   \n\n\n\n# Summarize Total Trade by Country\nTrade_Summary &lt;- Trade_Data %&gt;%\n  group_by(`Data Series`, Trade_Type) %&gt;%\n  summarise(Total_Trade_Value = sum(Trade_Value, na.rm = TRUE)) %&gt;%\n  pivot_wider(names_from = Trade_Type, values_from = Total_Trade_Value) %&gt;%\n  mutate(Total_Trade = Exports + Imports,  \n         Trade_Balance = Exports - Imports)  # Surplus (+) or Deficit (-)\n\n\ncolnames(Trade_Summary) &lt;- c(\"Country\", \"Exports\", \"Imports\", \"Total_Trade\", \"Trade_Balance\")\n\n\nhead(Trade_Summary)\n\n# A tibble: 6 × 5\n# Groups:   Country [6]\n  Country       Exports Imports Total_Trade Trade_Balance\n  &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;\n1 China          94443.  75740.     170182.        18703.\n2 Europe         52417.  89635.     142052.       -37218.\n3 Hong Kong      73879.   4744.      78622.        69135 \n4 Indonesia      53216.  20938.      74155.        32278.\n5 Japan          23707.  29696.      53402.        -5989.\n6 Korea, Rep Of  28423.  38395.      66818.        -9973.\n\n\n\n# Create Bubble Plot\np &lt;- ggplot(Trade_Summary, aes(x = Imports, y = Exports, size = Total_Trade, fill = Trade_Balance)) +\n  geom_point(shape = 21, alpha = 0.7, color = \"black\") +  # Black border for better visibility\n  geom_text(aes(label = Country), vjust = -1, size = 4) +  # Add country labels\n  scale_size_continuous(range = c(3, 20), guide = \"legend\") +  # Scale bubble sizes proportionally\n  scale_fill_gradient2(low = \"red\", mid = \"white\", high = \"blue\", midpoint = 0, name = \"Trade Balance\") + \n  scale_x_continuous(labels = scales::comma_format()) +  # Format numbers with commas\n  scale_y_continuous(labels = scales::comma_format()) +\n  labs(title = \"Merchandise Trade Performance with Major Trading Partners (2024)\",\n       subtitle = \"Bubble size represents total trade volume. Color indicates trade balance.\",\n       x = \"Imports (S$ Billion)\", y = \"Exports (S$ Billion)\",\n       size = \"Total Trade (S$ Billion)\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")  # Move legend to bottom for clarity\n\n# Convert to Interactive Plot\nggplotly(p, tooltip = c(\"Country\", \"Exports\", \"Imports\", \"Total_Trade\", \"Trade_Balance\"))\n\n\n\n\n\n\n# Adjusted Bubble Plot\np &lt;- ggplot(Trade_Summary, aes(x = Imports, y = Exports, size = Total_Trade, fill = Trade_Balance)) +\n  geom_point(shape = 21, alpha = 0.7, color = \"black\") +  # Black border for visibility\n  \n  # Place country names inside bubbles with smaller font size\n  geom_text(aes(label = Country), size = 3.5, fontface = \"bold\", color = \"black\") +\n\n  # Ensure proportional bubble scaling and readable labels\n  scale_size_continuous(range = c(6, 25), guide = \"legend\") +  \n\n  # Improve color scale clarity\n  scale_fill_gradient2(low = \"red\", mid = \"white\", high = \"blue\", midpoint = 0, name = \"Trade Balance\") + \n  \n  # Ensure proper axis formatting with adjusted limits\n  scale_x_continuous(labels = scales::comma_format(), limits = c(0, max(Trade_Summary$Imports) * 1.1)) +  \n  scale_y_continuous(labels = scales::comma_format(), limits = c(0, max(Trade_Summary$Exports) * 1.1)) +\n\n  # Titles and labels\n  labs(title = \"Merchandise Trade Performance with Major Trading Partners (2024)\",\n       subtitle = \"Bubble size represents total trade volume. Color indicates trade balance.\",\n       x = \"Imports (S$ Billion)\", y = \"Exports (S$ Billion)\",\n       size = \"Total Trade (S$ Billion)\") +\n  \n  # Improve readability with clean theme\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        panel.grid.major = element_line(color = \"gray85\", linetype = \"dashed\"),\n        panel.grid.minor = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14, face = \"bold\"))\n\n# Convert to Interactive Plot\nggplotly(p, tooltip = c(\"Country\", \"Exports\", \"Imports\", \"Total_Trade\", \"Trade_Balance\"))\n\n\n\n\n\n\n# Adjusted Bubble Plot with Country Labels Inside Bubbles\np &lt;- ggplot(Trade_Summary, aes(x = Imports, y = Exports, size = Total_Trade, fill = Trade_Balance)) +\n  \n  # Plot Bubbles\n  geom_point(shape = 21, alpha = 0.7, color = \"black\") +  \n  \n  # Place country names inside bubbles with smaller font\n  geom_text(aes(label = Country), size = 3.5, fontface = \"bold\", color = \"black\") +\n\n  # Keep Y-axis scale unchanged & Adjust X-axis scale dynamically\n  scale_x_continuous(labels = scales::comma_format(), limits = c(0, max(Trade_Summary$Imports) * 1.1)) +  \n  scale_y_continuous(labels = scales::comma_format()) +  # Y-axis remains unchanged\n\n  # Ensure proportional bubble scaling\n  scale_size_continuous(range = c(6, 25), guide = \"legend\") +  \n\n  # Improve color scale clarity\n  scale_fill_gradient2(low = \"red\", mid = \"white\", high = \"blue\", midpoint = 0, name = \"Trade Balance\") + \n  \n  # Titles and labels\n  labs(title = \"Merchandise Trade Performance with Major Trading Partners (2024)\",\n       subtitle = \"Bubble size represents total trade volume. Color indicates trade balance.\",\n       x = \"Imports (S$ Billion)\", y = \"Exports (S$ Billion)\",\n       size = \"Total Trade (S$ Billion)\") +\n  \n  # Improve readability with a clean theme\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        panel.grid.major = element_line(color = \"gray85\", linetype = \"dashed\"),\n        panel.grid.minor = element_blank(),\n        axis.text = element_text(size = 12),\n        axis.title = element_text(size = 14, face = \"bold\"))\n\n# Convert to Interactive Plot\nggplotly(p, tooltip = c(\"Country\", \"Exports\", \"Imports\", \"Total_Trade\", \"Trade_Balance\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#time-series-analysis-from-2015-to-2024",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex2.html#time-series-analysis-from-2015-to-2024",
    "title": "Take_Home Exercise 2",
    "section": "",
    "text": "imports_v4 &lt;- Region1 %&gt;%\n  filter(`Data Series` %in% Trading_Partners) %&gt;%   \n  pivot_longer(cols = -`Data Series`,               \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  mutate(Date = ym(Date)) %&gt;%  \n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\ndomestic_ex_v4 &lt;- Region2 %&gt;%\n  filter(`Data Series` %in% Trading_Partners) %&gt;%   \n  pivot_longer(cols = -`Data Series`,               \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  mutate(Date = ym(Date)) %&gt;%  \n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\nre_ex_v4 &lt;- Region2 %&gt;%\n  filter(`Data Series` %in% Trading_Partners) %&gt;%   \n  pivot_longer(cols = -`Data Series`,               \n               names_to = \"Date\", \n               values_to = \"Trade_Value\") %&gt;%\n  mutate(Date = ym(Date)) %&gt;%  \n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\n\n\n\nimport1 &lt;- as.data.frame(t(Region1))\ndom_ex1 &lt;- as.data.frame(t(Region2))\nre_ex1 &lt;- as.data.frame(t(Region3))\n\ncolnames(import1) &lt;- import1[1, ]\ncolnames(dom_ex1) &lt;- dom_ex1[1, ]\ncolnames(re_ex1) &lt;- re_ex1[1, ]\n\nimport_tp &lt;- import1[-1, ]\ndom_ex_tp &lt;- dom_ex1[-1, ]\nre_ex_tp &lt;- re_ex1[-1, ]\n\nimport_tp &lt;- import_tp %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.character(Date),   \n         Date = ym(Date)) %&gt;%         \n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)  \n\ndom_ex_tp &lt;- dom_ex_tp %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.character(Date), \n         Date = ym(Date)) %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\nre_ex_tp &lt;- re_ex_tp %&gt;%\n  rownames_to_column(var = \"Date\") %&gt;%\n  mutate(Date = as.character(Date), \n         Date = ym(Date)) %&gt;%\n  filter(year(Date) &gt;= 2015 & year(Date) &lt;= 2024)\n\n\nimport_tsibble &lt;- import_tp %&gt;%\n  mutate(Month = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Month`)\n\ndom_ex_tsibble &lt;- dom_ex_tp %&gt;%\n  mutate(Month = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Month`)\n\nre_ex_tsibble &lt;- re_ex_tp %&gt;%\n  mutate(Month = yearmonth(Date)) %&gt;%\n  as_tsibble(index = `Month`)\n\n\nimport_longer &lt;- import_tsibble %&gt;%\n  pivot_longer(cols = all_of(Trading_Partners),  \n               names_to = \"Country\",\n               values_to = \"Trade_Value\")\n\ndom_ex_longer &lt;- dom_ex_tsibble %&gt;%\n  pivot_longer(cols = all_of(Trading_Partners),  \n               names_to = \"Country\",\n               values_to = \"Trade_Value\")\n\nre_ex_longer &lt;- re_ex_tsibble %&gt;%\n  pivot_longer(cols = all_of(Trading_Partners),  \n               names_to = \"Country\",\n               values_to = \"Trade_Value\")\n\n\n\n\n\nggplot(data = imports_v4, \n       aes(x = Date, \n           y = Trade_Value/1e3,\n           color = `Data Series`))+\n  geom_line(linewidth = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\")) +\n  labs(title = \"Major Import Partners\",\n       x = \"\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Country\")\n\n\n\n\n\n\n\n\n\nggplot(data = domestic_ex_v4, \n       aes(x = Date, \n           y = Trade_Value/1e3,\n           color = `Data Series`))+\n  geom_line(linewidth = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\")) +\n  labs(title = \"Major Domestic Export Partners\",\n       x = \"\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Country\")\n\n\n\n\n\n\n\n\n\nggplot(data = re_ex_v4, \n       aes(x = Date, \n           y = Trade_Value/1e3,\n           color = `Data Series`))+\n  geom_line(linewidth = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\")) +\n  labs(title = \"Major Re-Export Partners\",\n       x = \"\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Country\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",                  \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ppthaw2024\\ISSS608\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\n    popdata2020 &lt;- popdata %&gt;%\n      filter(Time == 2020) %&gt;%\n      group_by(PA, SZ, AG) %&gt;%\n      summarise(`POP` = sum(`Pop`)) %&gt;%\n      ungroup() %&gt;%\n      pivot_wider(names_from=AG, \n                  values_from=POP) %&gt;%\n      mutate(YOUNG = rowSums(.[3:6])\n             +rowSums(.[12])) %&gt;%\n    mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\n    rowSums(.[13:15]))%&gt;%\n    mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n    mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \n    mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n    /`ECONOMY ACTIVE`) %&gt;%\n      select(`PA`, `SZ`, `YOUNG`, \n           `ECONOMY ACTIVE`, `AGED`, \n           `TOTAL`, `DEPENDENCY`)\n\n#### 8.3.4.2 Joining the attribute data and geospatial data\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. \n\n    popdata2020 &lt;- popdata2020 %&gt;%\n      mutate(across(c(PA, SZ), toupper)) %&gt;%  # Convert PA and SZ to uppercase\n      filter(`ECONOMY ACTIVE` &gt; 0)  # Keep only rows where ECONOMY ACTIVE &gt; 0\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nTo draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") + tm_borders(lwd = 0.1,  alpha = 1,lty ='solid')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nHigher n (more bins) → More detailed visualization, but might introduce unnecessary complexity.\nLower n (fewer bins) → Simpler visualization, but may hide finer variations in data.\n\n\n\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios.\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar(breaks = c(0, 5, 10)) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"-Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data-into-r",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "",
    "text": "Two data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",                  \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ppthaw2024\\ISSS608\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\n    popdata2020 &lt;- popdata %&gt;%\n      filter(Time == 2020) %&gt;%\n      group_by(PA, SZ, AG) %&gt;%\n      summarise(`POP` = sum(`Pop`)) %&gt;%\n      ungroup() %&gt;%\n      pivot_wider(names_from=AG, \n                  values_from=POP) %&gt;%\n      mutate(YOUNG = rowSums(.[3:6])\n             +rowSums(.[12])) %&gt;%\n    mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\n    rowSums(.[13:15]))%&gt;%\n    mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n    mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \n    mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n    /`ECONOMY ACTIVE`) %&gt;%\n      select(`PA`, `SZ`, `YOUNG`, \n           `ECONOMY ACTIVE`, `AGED`, \n           `TOTAL`, `DEPENDENCY`)\n\n#### 8.3.4.2 Joining the attribute data and geospatial data\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. \n\n    popdata2020 &lt;- popdata2020 %&gt;%\n      mutate(across(c(PA, SZ), toupper)) %&gt;%  # Convert PA and SZ to uppercase\n      filter(`ECONOMY ACTIVE` &gt; 0)  # Keep only rows where ECONOMY ACTIVE &gt; 0\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "",
    "text": "tmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nTo draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") + tm_borders(lwd = 0.1,  alpha = 1,lty ='solid')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nHigher n (more bins) → More detailed visualization, but might introduce unnecessary complexity.\nLower n (fewer bins) → Simpler visualization, but may hide finer variations in data.\n\n\n\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios.\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar(breaks = c(0, 5, 10)) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"-Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-1",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8 Overview",
    "text": "8 Overview\nProportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.1 The data",
    "text": "8.1 The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n8.1.1 Data Import and Preparation\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\n\n\n8.1.2 Creating a sf data frame from an aspatial data frame\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-proportional-symbol-map",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.2 Drawing Proportional Symbol Map",
    "text": "8.2 Drawing Proportional Symbol Map\n\ntmap_mode(\"view\")\n\n\n8.2.1 all started with an interactive point symbol map\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#lets-make-it-proportional",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#lets-make-it-proportional",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.3 Lets make it proportional",
    "text": "8.3 Lets make it proportional\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#lets-give-it-a-different-colour",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#lets-give-it-a-different-colour",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.4 Lets give it a different colour",
    "text": "8.4 Lets give it a different colour\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#i-have-a-twin-brothers",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#i-have-a-twin-brothers",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.5 I have a twin brothers :)",
    "text": "8.5 I have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-2",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.1 Overview",
    "text": "8.1 Overview\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-1",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.2 Getting Started",
    "text": "8.2 Getting Started\n\n8.2.2 Importing data\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#basic-choropleth-mapping",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.3 Basic Choropleth Mapping",
    "text": "8.3 Basic Choropleth Mapping\n\n8.3.1 Visualising distribution of non-functional water point\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-map-for-rates",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.4 Choropleth Map for Rates",
    "text": "8.4 Choropleth Map for Rates\n\n8.4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n8.4.2 Plotting map of rate\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extreme-value-maps",
    "title": "Hands-on_Ex08: Visualising and Analysing Geographic Data",
    "section": "8.5 Extreme Value Maps",
    "text": "8.5 Extreme Value Maps\n\n8.5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1).\n\n8.5.1.1 Data Preparation\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n8.5.1.3 Creating the get.var function\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n8.5.1.4 A percentile mapping function\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n8.5.1.5 Test drive the percentile mapping function\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\n\n\n\n8.5.2 Box map\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n8.5.2.1 Creating the boxbreaks function\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n8.5.2.2 Creating the get.var function\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n8.5.2.3 Test drive the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n8.5.2.4 Boxmap function\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  }
]